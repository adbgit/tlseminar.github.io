<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Post-rsses on TLSeminar</title>
    <link>https://tlseminar.github.io/post/index.xml</link>
    <description>Recent content in Post-rsses on TLSeminar</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 26 Apr 2017 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://tlseminar.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Project Presentations Schedule</title>
      <link>https://tlseminar.github.io/project-presentations-schedule/</link>
      <pubDate>Wed, 26 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://tlseminar.github.io/project-presentations-schedule/</guid>
      <description>&lt;p&gt;Here is the schedule for the project presentations for Friday, 28
April.  Each multi-person team will have up to 20 minutes to present
(which should include at least 5 minutes for questions, so plan on a
15-minute or shorter presentation), and each single-person team will
have up to 15 minutes to present (which should include at least 3
minutes for questions, so plan on a 12-minute or shorter
presentation).&lt;/p&gt;

&lt;table&gt;
&lt;tr bgcolor=&#34;#90EE90&#34;&gt;
&lt;td width=20%&gt;&lt;b&gt;9:20-9:30am&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;a href=&#34;https://www.chick-fil-a.com/#breakfast&#34;&gt;Breakfast&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr bgcolor=&#34;#FFFACD&#34;&gt;&lt;td&gt;&lt;b&gt;9:30-9:50am&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;a href=&#34;https://lineoftrust.github.io/&#34;&gt;Line Of Trust&lt;/a&gt; &amp;mdash; Anant Kharkar, Sam Havron, Bill Young, Joshua Holtzman&lt;/td&gt;&lt;/tr&gt;
&lt;tr bgcolor=&#34;#FFEBCD&#34;&gt;&lt;td&gt;&lt;b&gt;9:50-10:05am&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;a href=&#34;https://darioncassel.github.io/sok-tls-testing/&#34;&gt;SoK: Software Testing Methods Applied to SSL/TLS: Lessons in Discovering Implementation Bugs&lt;/a&gt; (Darion Cassel)&lt;/td&gt;&lt;/tr&gt;
&lt;tr  bgcolor=&#34;#FFEBCD&#34;&gt;&lt;td&gt;&lt;b&gt;10:05-10:20am&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;a href=&#34;https://github.com/yuchi1989/ssltimer&#34;&gt;SSLTimer: Testing an SSL Implementation with respect to Timing Attack Vulnerability&lt;/a&gt; (Yuchi Tian)&lt;/td&gt;&lt;/tr&gt;
&lt;tr  bgcolor=&#34;#FFFACD&#34;&gt;&lt;td&gt;&lt;b&gt;10:20-10:40am&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;a href=&#34;https://github.com/cmalekpour/minimal-tls&#34;&gt;Minimal TLS&lt;/a&gt; (&lt;a href=&#34;https://github.com/FreddieJin&#34;&gt;Tianyi Jin&lt;/a&gt;, &lt;a href=&#34;https://github.com/cmalekpour&#34;&gt;Cyrus Malekpour&lt;/a&gt;, &lt;a href=&#34;https://github.com/bhuvanesh8&#34;&gt;Bhuvanesh Murali&lt;/a&gt;, &lt;a href=&#34;https://github.com/drs5ma&#34;&gt;Daniel Saha&lt;/a&gt;)&lt;/td&gt;&lt;/tr&gt;
&lt;tr bgcolor=&#34;#90EE90&#34;&gt;&lt;td&gt;&lt;b&gt;10:40-10:50am&lt;/b&gt;&lt;/td&gt;&lt;td&gt;Break&lt;/td&gt;&lt;/tr&gt;
&lt;tr  bgcolor=&#34;#FFFACD&#34;&gt;&lt;td&gt;&lt;b&gt;10:50-11:10am&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;a href=&#34;https://reidbix.github.io/QuantumMenace/&#34;&gt;Quantum Menace&lt;/a&gt; (Reid Bixler, Collin Berman)&lt;/td&gt;&lt;/tr&gt;
&lt;tr  bgcolor=&#34;#FFEBCD&#34;&gt;&lt;td&gt;&lt;b&gt;11:10-11:25am&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;a href=&#34;http://adamimeson.tech/sslskimmer/&#34;&gt;SSL Skimmer&lt;/a&gt; (Adam Imeson)&lt;/td&gt;&lt;/tr&gt;
&lt;tr  bgcolor=&#34;#FFEBCD&#34;&gt;&lt;td&gt;&lt;b&gt;11:25-11:40am&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;a href=&#34;https://lowmanb94.github.io/tie/&#34;&gt;TIE: TLS Invariants Exploration&lt;/a&gt; (Ben Lowman)&lt;/td&gt;&lt;/tr&gt;
&lt;tr  bgcolor=&#34;#FFFACD&#34;&gt;&lt;td&gt;&lt;b&gt;11:40am-noon&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;a href=&#34;https://hainali.github.io/DecentralizedCA/&#34;&gt;DecentralizedCA&lt;/a&gt; (&lt;a href=&#34;https://github.com/bargavjayaraman&#34;&gt;Bargav Jayaraman&lt;/a&gt;, &lt;a href=&#34;https://github.com/HainaLi/&#34;&gt;Hannah Li&lt;/a&gt;)
&lt;/tr&gt;
&lt;/table&gt;
</description>
    </item>
    
    <item>
      <title>TLS Outside The Web</title>
      <link>https://tlseminar.github.io/tls-outside-the-web/</link>
      <pubDate>Sun, 23 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://tlseminar.github.io/tls-outside-the-web/</guid>
      <description>

&lt;p&gt;As the web evolves, taking on physical form with embedded devices, or
becoming more abstracted with cloud computing, the question of how to
secure these new kinds of connections becomes paramount. Can TLS work
for non-web scenarios?&lt;/p&gt;

&lt;p&gt;Sizzle and DTLS improve TLS performance in an attempt to make the
protocol feasible on embedded devices with limited power and bandwidth
- but sacrifice some security in the process. Developers of
non-browser software like Cloud services, mobile apps, and payment
transfer services misunderstand or intentionally disable vital
security measures - and SSL APIs fail to communicate how to secure
connections and implement authentication. Meanwhile, Amazon Web
Services offers a heavily centralized alternative to securing the
Cloud and IoT devices - but potentially at a high privacy cost.&lt;/p&gt;

&lt;h2 id=&#34;sizzle-tls-for-embedded-devices&#34;&gt;Sizzle: TLS For Embedded Devices&lt;/h2&gt;

&lt;p&gt;Vipul Gupta, Matthew Millard, Stephen Fung, Yu Zhu, Nils Gura, Hans Eberle, Sheueling Chang Shantz. &lt;a href=&#34;https://tlseminar.github.io/docs/sizzle.pdf&#34;&gt;&lt;em&gt;Sizzle: A Standards-based end-to-end Security Architecture for the Embedded Internet&lt;/em&gt;&lt;/a&gt;. Pervasive and Mobile Computing, 2005.&lt;/p&gt;

&lt;p&gt;Sizzle is an end-to-end security architecture for embedded devices that is fully implemented on the 8-bit Berkeley/Crossbow Mica2 “mote” platform. Capable of completing an abbreviated SSL (TLS 1.0)  handshake in less than 4 seconds, this mote devices were envisioned to function as sensors/actuators connected to the wireless network. When this paper was published (2005), Sizzle on “mote” was the world’s smallest and least resource-intensive secure web server.&lt;/p&gt;

&lt;p&gt;With the goal of allowing highly constrained embedded devices to offer secure connections, the authors of this paper uses 160-bit elliptic curve cryptography (ECC) to reduce computation for the system. When using ECC over RSA, there is a 4x speedup (or 5x speed up with session reuse) in computation speed of public/key cryptography. The figures 1 (full handshake) and 2 (abbreviated handshake) below show the comparison of the amount of time it took to transfer 450 bytes of data over HTTPS.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;https://tlseminar.github.io/images/tls-outside-the-web/sizzle1.png&#34;/&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;https://tlseminar.github.io/images/tls-outside-the-web/sizzle2.png&#34;/&gt;&lt;/center&gt;&lt;/p&gt;

&lt;h2 id=&#34;authentication-for-the-internet-of-things&#34;&gt;Authentication for the Internet of Things&lt;/h2&gt;

&lt;p&gt;Thomas Kothmayr, Corinna Schmitt, Wen Hu, Michael Brünig, Georg Carle. &lt;a href=&#34;https://tlseminar.github.io/docs/dtls.pdf&#34;&gt;&lt;em&gt;DTLS based security and two-way authentication
for the Internet of Things&lt;/em&gt;&lt;/a&gt;. Ad Hoc Networks. May 2013.&lt;/p&gt;

&lt;p&gt;Datagram TLS, also known as DTLS, is for all intents and purposes a “lightweight” version of TLS that can operate on devices that aren’t as powerful as traditional computers. Hence, it was a great addition for the internet of things devices as that revolution took off. According to its specification, it provides the same security guarantees as TLS except it is a stream-oriented service. It, however, does come with a downside. Namely, there is an overhead: tolerance for packet reordering and datagram loss. The former is pretty self explanatory, the latter is essentially stating that if the data is larger than the size of the datagram, it is possible that there be a data loss. Unlike, TLS, there are much fewer libraries that support this protocol, as can be seen in the graphic below:&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;https://tlseminar.github.io/images/tls-outside-the-web/dtls1.png&#34;/ width=&#34;50%&#34;&gt;&lt;/center&gt;
&lt;center&gt;&lt;span class=&#34;caption&#34;&gt;Source: &lt;a href=&#34;https://en.wikipedia.org/wiki/Datagram_Transport_Layer_Security&#34;&gt;https://en.wikipedia.org/wiki/Datagram_Transport_Layer_Security&lt;/a&gt;&lt;/span&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;So, we know of the following encryption techniques. When you have an access point and say a printer, that have a pre-shared key, we use WPA as a communication medium. Similarly, when we need secure connection between a sensor and a security end-point we use VPN, but what about a secure connection using TLS among the internet of things. That is the primary problem that DTLS seeks to solve. Since TCP and TLS incurs an overhead small, battery-starved, low-bandwidth devices, we choose to look at DTLS which uses a less strenuous UDP protocol and a lighter version of TLS, but still maintains the security guarantees.&lt;/p&gt;

&lt;p&gt;Earlier, we discussed Sizzle, but it was important to notice that sizzle only provides one-way authentication between the client and the node. That is say you have a thermostat, this would allow someone to change your thermostat, but wouldn’t allow them to read the information. This is not exactly the security that we want.&lt;/p&gt;

&lt;p&gt;Let’s take a closer look at DTLS. The image below depicts a DTLS record. This looks similar to the record that we have seen with TLS and so there doesn’t seem to be too many causes for concern or intrigue about this structure. To its right, we have the handshake protocol. The main thing to notice here is that we have an extra, optional ClientHello and ClientHelloVerify before the rest of the protocol, which matches with what we’ve seen all semseter with TLS.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;https://tlseminar.github.io/images/tls-outside-the-web/dtls2.png&#34;/ width=&#34;60%&#34;&gt;&lt;/center&gt;
&lt;center&gt;&lt;img src=&#34;https://tlseminar.github.io/images/tls-outside-the-web/dtls3.png&#34;/ width=&#34;60%&#34;&gt;&lt;/center&gt;
&lt;center&gt;
&lt;span class=&#34;caption&#34;&gt;Source:
&lt;a href=&#34;https://tlseminar.github.io/docs/dtls.pdf&#34;&gt;&lt;em&gt;DTLS based security and two-way authentication
for the Internet of Things&lt;/em&gt;&lt;/a&gt;&lt;/span&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;This security protocol is an application-layer security protocol. The reasons for using this are that lower-layer security protocols do not provide end-to-end encryption and the secure connections must be established to form a mesh network. This is better than routing algorithms that are agnostic of the payload protection, which means that you may have data sent over a non-secured connection or node.&lt;/p&gt;

&lt;p&gt;Finally, we can see how the proposed system actually works. This system uses a system of publishers and subscribers. Each of these can be considered the entities in the secured network. There is an access control server which stores teh access rights for all teh publishers (or motes). To intiialize any connection, the subscriber is verified by access control and is granted a ticket. The subscriber then presents this ticket to the publisher and the publisher verifies its legitimacy setting up the connection. In the larger scheme of things, the connection may look like:&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;https://tlseminar.github.io/images/tls-outside-the-web/dtls4.png&#34;/&gt;&lt;Br&gt;
&lt;span class=&#34;caption&#34;&gt;Source:
&lt;a href=&#34;https://tlseminar.github.io/docs/dtls.pdf&#34;&gt;&lt;em&gt;DTLS based security and two-way authentication
for the Internet of Things&lt;/em&gt;&lt;/a&gt;&lt;/span&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;So overall, when looking at the internet of things, we need to be wary of achieving performance, energy consumption, memory and other limiting factors that the hardware has in order to achieve some level of security. Through DTLS, the researchers presented they were able to create a system that was fairly secure and was able to experience speedups of up to 163 milliseconds based on the protocol and encryption being used. Overall, we are able to see that creating a secure network for the internet of things is slowly manifesting into a reality.&lt;/p&gt;

&lt;h2 id=&#34;the-most-dangerous-code-in-the-world&#34;&gt;The Most Dangerous Code In The World&lt;/h2&gt;

&lt;p&gt;Martin Georgiev, Subodh Iyengar, Suman Jana, Rishita Anubhai, Dan Boneh, Vitaly Shmatikov.
&lt;a href=&#34;https://tlseminar.github.io/docs/mostdangerous.pdf&#34;&gt;&lt;em&gt;The Most Dangerous Code in the World: Validating SSL Certificates in Non-Browser Software&lt;/em&gt;&lt;/a&gt;. ACM CCS 2012.&lt;/p&gt;

&lt;p&gt;SSL verification for non-browser applications is nearly always compromised. These applications don’t implement SSL directly, but rather use libraries or wrappers which can have various flaws and vulnerabilities. These added vulnerabilities exist for a variety of reasons, but many of them are introduced because of a lack of security understanding in app developers and poor APIs. Rather than high-level security properties of network tunnels, many APIs divulge low-level details of SSL protocol to app developers. In many cases, options values associated with API functions are misinterpreted by app developers, leading to security risks. In other cases, attempts to fix certificate validation bugs can lead to further insecurity, potentially leading the app developer to accidentally break or disable the certificate validation entirely.&lt;/p&gt;

&lt;p&gt;While most apps should do chain-of-trust and hostname verification, few do either. Chain-of-trust is often bypassed altogether, and hostname verification is often done via Common Name instead of SubjectAltName as is recommended by RFC 2818. Many applications also do not have a robust system for checking certificate revocation or allowing the user to do so. OpenSSL provides chain-of-trust verification, but requires that applications do their own hostname verification, while JSSE may or may not do either. This dependency on app developers to understand and implement potentially complex verification is unreasonable and leads to security vulnerabilities.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;https://tlseminar.github.io/images/tls-outside-the-web/dangerous1.png&#34;/&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;To avoid shop-for-free attacks, many vendor websites use SSL tunnels to communicate sensitive payment information, and these tunnels are often not set up securely. Attacks were attempted in a controlled environment on these tunnels using self-signed certificates and incorrect Common Name certificates. In Amazon’s flexible payment service, false was sent to cURL in a parameter instead of 2. In a bug fix, this parameter was changed to true, which also bypasses Common Name checks and causes vulnerability to MitM attacks.&lt;/p&gt;

&lt;p&gt;One issue for app developers is needing to test their applications before making them live, and for those tests they either need to get valid localHost certificates (which aren’t given out) or they have to disable their certificate validation. Developers often do not enable the validation afterward and “disabling proper certificate validation appears to be the developers’ preferred solution to any problem with SSL libraries.”&lt;/p&gt;

&lt;p&gt;App developers should attempt testing using abnormal and invalid certificates. They should also protect themselves by not relying on libraries and not disabling certificate validation during testing. SSL library developers should also attempt to be more explicit about their functionality and should avoid giving responsibility for validation to app developers.&lt;/p&gt;

&lt;h2 id=&#34;aws-iot-security-overview&#34;&gt;AWS IoT Security Overview&lt;/h2&gt;

&lt;p&gt;Amazon Web Services (AWS) is the largest cloud service provider in the world, offering a wide range of products from computing and network resources to game development services. One of their newer offerings, AWS IoT, enables developers to link internet-connected devices to the cloud.&lt;/p&gt;

&lt;p&gt;The use case for this service is the Internet of Things. Physical sensors in our homes, offices, and cities collect data from their surroundings. Software can then analyze this data and leverage actuators to effect changes in the environment. For example, smart thermostats use temperature sensors to decide whether to heat or cool our houses. These thermostats can learn our daily routines, allowing them to control the temperature more efficiently than classical programmable thermostats. Furthermore, since the thermostats are connected to the internet, homeowners are able to remotely control their home temperature from their mobile phone.&lt;/p&gt;

&lt;p&gt;AWS IoT provides application developers a protocol, Message Queue Telemetry Transport (MQTT), for communication between Internet-connected things and the cloud. Sensors use MQTT to publish data to a message broker, which passes on the sensor readings to subscribing smart appliances and other devices. These messages are also processed by a rules engine, allowing developers to interface with other AWS services, such as their storage and data processing solutions.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;https://tlseminar.github.io/images/tls-outside-the-web/aws1.png&#34;/&gt;&lt;br&gt;
&lt;span class=&#34;caption&#34;&gt;Source: &lt;a href=&#34;http://docs.aws.amazon.com/iot/latest/developerguide/images/thunderball-overview.png&#34;&gt;Amazon&lt;/a&gt;&lt;/span&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;All these messages to and from AWS IoT need to be secured. To ensure privacy, TLS is used to encrypt all MQTT traffic between devices and the message broker. Devices are authenticated using one of three identity types. First, clients can use the standard X.509 certificates used in HTTPS, which are authenticated using challenge-response TLS Client Authentication. AWS IoT also allows clients to use two AWS-specific identity types: IAM roles, and Amazon Cognito Federated Identities.&lt;/p&gt;

&lt;p&gt;Even after a device has authenticated itself to the message broker, it is only allowed to execute an operation if it has been given the appropriate permission. An entity’s permissions are specified by AWS IoT policies, which are attached to the entity’s identity (certificate, IAM role, or Cognito identity). If an entity needs access to AWS services outside of IoT, IAM policies are used instead of IoT policies. These policies provide developers fine-grained control of authorization.&lt;/p&gt;

&lt;h2 id=&#34;aws-end-to-end-hardware-security&#34;&gt;AWS End-To-End Hardware Security&lt;/h2&gt;

&lt;p&gt;Brandom Lewis. &lt;a href=&#34;http://embedded-computing.com/articles/aws-microchip-deliver-trust-anchor-for-end-to-end-iot-security/&#34;&gt;&lt;em&gt;AWS, Microchip deliver trust anchor for end-to-end IoT security&lt;/em&gt;&lt;/a&gt;. Embedded Computing Design, 7 October, 2016.&lt;/p&gt;

&lt;p&gt;Digital certificates are ingrained in almost every aspect of our digital lives. Signed by Certificate authorities (CAs), they help authenticate the identity of parties involved in the electronic exchange of information, preventing potential threats such as MITM attacks. With the Internet of Things (IoT) introducing billions of clients that communicate with the cloud in a two-way fashion, the requirement for mutual authentication of both clients and servers has steadily increased nowadays.&lt;/p&gt;

&lt;p&gt;To solve the problems related to certificate provisioning for client-side devices, Amazon Web Services (AWS) released “Use Your Own Certificate” feature this April. It allows original equipment manufacturers (OEMs) to register digital certificates signed by a third-party CA with the AWS IoT platform using an API, which, could happen even before the devices come online. This provides a new possibility for OEMs to generate cryptographic keys for device during its production period. The latest capability in the AWS IoT portfolio, Just-In-Time Registration (JITR), is also partly based on such process. As the term implies, devices can automatically connect to and be recognized by the AWS IoT cloud the first time they request service from the platform. By ensuring them being pre-equipped with unique, trusted private keys and correct server configurations and policies, such immediate, autonomous onboarding of devices with cloud services can maintain secure despite the large numbers of connections.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;https://tlseminar.github.io/images/tls-outside-the-web/aws2.png&#34;/&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;Fortunately, good news have arrived from hardware side of IoT spectrum as well. One example is ECC508A, a 2 mm x 3 mm tamper-resistant CryptoAuthentication device based on elliptic curve Diffie-Hellman (ECDH) algorithms. The architectural features of the chip include internally encrypted memory, isolated power rails, a memory and logic shield, internal clock generation, and a lack of probe points to protect against different kinds of real-world threats. It also improves overall system performance when TLS transaction runs on hardware-based crypto accelerator. With the ECC508A acting as the root of trust, Microchip can act as a third-party CA, signing device certificates in an offline verification process. Then OEMs are able to access robust security and automatic cloud authentication by adding a single component to their bill of materials (BoM).&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;https://tlseminar.github.io/images/tls-outside-the-web/aws3.png&#34;/&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;Security is still essential to the continued rollout of IoT in every market. Device makers now can separate security from business functions and continue to work upon that. The ECC508A evaluation kit has been available on the market, which must excite those who deeply concern and care about the future of cyber security.&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;As we have seen, TLS is being widely used outside of the web in embedded devices, the Internet of Things, Amazon Web Services, and many others. The problem, however, is how these devices choose to implement their own versions of TLS and the problems that ensue. We have seen interesting applications of TLS that seem to also fundamentally break the intended security inherent in the protocol. Many of the problems are actually just based on laziness in the production of these devices, such as pinning a single certificate to every type of a device.&lt;/p&gt;

&lt;p&gt;Besides TLS, alternative protocols have been designed for minimal data use and enhanced security throughout all communication between these devices. Because of the limited resources provided by embedded devices and IoT devices, many of the protocols must consider how much CPU, battery, and memory will be used at a time.&lt;/p&gt;

&lt;p&gt;As time goes on, more and more of these embedded devices will be in our homes and cities, and there is the very real possibility of our own physical safety being in harm’s way due to a compromised device. Internet enabled doors, heating systems, windows, safes, and more could hold the potential of being locked, overused, and unlocked to cause danger to their owner. While TLS never was designed with the idea outside of web use, we must begin to consider alternative protocols or improve current ones to ensure the security of our technology outside of our browsers.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>TLS 1.3</title>
      <link>https://tlseminar.github.io/tls-13/</link>
      <pubDate>Fri, 24 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://tlseminar.github.io/tls-13/</guid>
      <description>

&lt;h2 id=&#34;tls-evolves-version-1-3&#34;&gt;TLS Evolves: Version 1.3&lt;/h2&gt;

&lt;p&gt;TLS v1.3 is a major revision to TLS to simplify the protocol, and improve its security and performance. In order to get a good understanding of TLS v1.3 and where it is heading in the future, we will first look at where TLS has been.&lt;/p&gt;

&lt;h3 id=&#34;looking-backward-retro-tls&#34;&gt;Looking Backward: Retro TLS&lt;/h3&gt;

&lt;p&gt;SSL/TLS has a storied past. SSL v1.0 was never released. Netscape, the company that originally developed SSL, circulated it internally but decided not to release it to the public because it had several flaws including a lack of data integrity protection.&lt;/p&gt;

&lt;p&gt;After that non-starter, the timeline looks like this:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1994: Netscape develops SSL v2.0 which is shipped with the Netscape Navigator 1.1&lt;/li&gt;
&lt;li&gt;1995: SSL v2.0 has serious security issues; Netscape releases SSL v3.&lt;/li&gt;
&lt;li&gt;1999: TLS v1.0 released; standardizing and upgrading SSL v3.0&lt;/li&gt;
&lt;li&gt;2006: TLS v1.1 released; address the BEAST attack, which will come in 5 years&lt;/li&gt;
&lt;li&gt;2008: TLS v1.2 released with Authenticated Encryption&lt;/li&gt;
&lt;li&gt;2011: Google deploys public key pinning and forward secrecy&lt;/li&gt;
&lt;li&gt;2013: Work on TLS v1.3 begins&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A more thorough timeline can be found at &lt;a href=&#34;https://www.feistyduck.com/ssl-tls-and-pki-history/&#34;&gt;&lt;em&gt;SSL/TLS and PKI History&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;So what does TLS v1.3 bring to the table? Let&amp;rsquo;s take a look&amp;hellip;&lt;/p&gt;

&lt;h2 id=&#34;faster-handshake&#34;&gt;Faster Handshake&lt;/h2&gt;

&lt;p&gt;TLS 1.3 introduces a significantly slimmer Handshake Protocol than previous versions. In order to understand the implications of these changes, we first review the Handshake Protocol used in TLS 1.2.&lt;/p&gt;

&lt;p&gt;In TLS 1.2, the client begins the handshake with a &lt;code&gt;Client Hello&lt;/code&gt;,
followed by a &lt;code&gt;Server Hello&lt;/code&gt; response from the server. The client then
proceeds with a &lt;code&gt;Client Key Exchange&lt;/code&gt; and &lt;code&gt;Client Finished&lt;/code&gt;; the
server responds with its own versions of these messages.&lt;/p&gt;

&lt;p&gt;In contrast, TLS 1.3 incorporates the key share messages with the
&lt;code&gt;Client/Server Hello&lt;/code&gt;, meaning that each side of the connection has to
send one less message (and only send one message total to initiate the
connection).&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;https://tlseminar.github.io/images/tls-13/handshake1.2.png&#34; alt=&#34;TLS 1.2 Handshake&#34; style=&#34;width:500px;&#34;/&gt;&lt;br&gt;
&lt;sup&gt;TLS 1.2 Handshake&lt;/sup&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;https://tlseminar.github.io/images/tls-13/handshake1.3.png&#34; alt=&#34;TLS 1.3 Handshake&#34; style=&#34;width:500px;&#34;/&gt;&lt;br&gt;
&lt;sup&gt;TLS 1.3 Handshake&lt;/sup&gt;&lt;/center&gt;&lt;/p&gt;

&lt;h3 id=&#34;sidebar-authloop&#34;&gt;Sidebar: AuthLoop&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://tlseminar.github.io/docs/authloop.pdf&#34;&gt;&lt;em&gt;AuthLoop: End-to-End Cryptographic Authentication for Telephony over Voice Channels&lt;/em&gt;&lt;/a&gt;, Bradley Reaves, Logan Blue, and Patrick Traynor. USENIX Security Symposium. August 2016.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;On the subject of modification and adaptations to the typical TLS 1.2 system of encryption and authentication, we explore AuthLoop: a TLS-style authentication protocol specifically designed for telephony networks. In this domain, the system must connect three different types of telephony networks: cellular, VoIP, and PSTN. However, the TLS Handshake transmission speeds for such a system were extremely slow - averaging 98 seconds per handshake - which is completely infeasible for most phone calls. AuthLoop keeps the authentication and shared secret elements of TLS and a freshness/liveness component analogous to the Heartbeat Protocol. On the other hand, AuthLoop removes RSA and the cipher agreement messages. Furthermore, AuthLoop does not encrypt messages and therefore has no Record Protocol. After slimming down, the average transmission time reduced drastically to 4.8 seconds.&lt;/p&gt;

&lt;h2 id=&#34;0-rtt-resumption&#34;&gt;0-RTT Resumption&lt;/h2&gt;

&lt;p&gt;A major new feature in the TLS 1.3 draft is support for 0-RTT session resumption. In TLS 1.2, establishing a connection to a new server required at least 4 trips between the server and client to make an HTTP request and receive a response. With a session-ID or session ticket, that could be reduced to 3 trips per connection. TLS 1.3 by default reduces the number for new connections to only 3 trips per connection, but also adds support for a new mode termed &lt;em&gt;0-RTT&lt;/em&gt;. In this mode, resumed HTTPS connections require only 2 trips, which is the bare minimum required for a full HTTP query and response. In this mode, TLS 1.3 adds barely any additional latency cost over a plain HTTP request!&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://tlseminar.github.io/images/tls-13/tls1_3_0rtt.jpg&#34; alt=&#34;0-RTT&#34; width=&#34;65%&#34;&gt;&lt;br&gt;
&lt;span class=&#34;caption&#34;&gt;TLS 1.3 0-RTT (Source: &lt;a href=&#34;https://blog.cloudflare.com/tls-1-3-overview-and-q-and-a/&#34;&gt;https://blog.cloudflare.com/tls-1-3-overview-and-q-and-a/&lt;/a&gt;)&lt;/span&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;However, the addition of 0-RTT resumption to the protocol has an
important implication for the security features provided by the
protocol. Because TLS 1.3 session tickets, which enable 0-RTT
resumption, are stateless on the server, such requests from the client
are trivially vulnerable to &lt;strong&gt;replay attacks&lt;/strong&gt;. An attacker who can
intercept an encrypted client message can re-send it to the server,
tricking the server into processing the same request twice (which
could be serious, for example, if the request is &amp;ldquo;transfer $x to
Bob&amp;rdquo;).&lt;/p&gt;

&lt;p&gt;To remedy this, the protocol authors recommend that initial requests from the client be &lt;em&gt;idempotent&lt;/em&gt;, or non-state-changing. Servers should not allow the first request to be idempotent in 0-RTT mode. This has been arguably the most controversial part of the new standard, as it puts the onus on some higher level protocol to solve a problem that TLS has historically been responsible for. Even worse, it is not solved directly by HTTP but rather must be specifically kept in mind by web developers.&lt;/p&gt;

&lt;h2 id=&#34;deployment&#34;&gt;Deployment&lt;/h2&gt;

&lt;p&gt;Deployment of TLS 1.3 remains loosely in the future as the protocol specification
finishes its final draft. Current TLS 1.3 drafts include 0-RTT by requiring servers to set up
a profile that defines its use. However, as with many other features in earlier
TLS protocols, 0-RTT data is not compatible with older servers.
A server using TLS 1.3 has the option to limit what early data to use in a 0-RTT and what to buffer.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://tools.ietf.org/html/draft-green-tls-static-dh-in-tls13-00&#34;&gt;Data Center use of Static Diffie-Hellman&lt;/a&gt;:
While ephemeral (EC) Diffie-Hellman is in nearly all ways an improvement over
the TLS RSA handshake, it has a limitation in certain enterprise settings.
Specifically, the use of ephemeral (PFS) ciphersuites is not compatible with
enterprise network monitoring tools such as Intrusion Detection Systems (IDS)
that must passively monitor intranet TLS connections made to endpoints under the
enterprise&amp;rsquo;s control. Such monitoring is ubiquitous and indispensable in some industries, and loss of
this capability may slow adoption of TLS 1.3.&lt;/p&gt;

&lt;p&gt;Deployment of TLS 1.3 across the web faces several industry concerns, most notably regarding Static RSA (no forward secrecy),
as posted from an email exchange
between Andrew Kennedy, an employee at BITS (the technology policy division of the Financial
Services Roundtable &lt;a href=&#34;http://www.fsroundtable.org/bits&#34;&gt;http://www.fsroundtable.org/bits&lt;/a&gt;), and Kenny Paterson.&lt;/p&gt;

&lt;p&gt;Andrew Kennedy writes,&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&amp;hellip;
While I am aware and on the whole supportive of the significant contributions to
internet security this important working group has made in the last few years I
recently learned of a proposed change that would affect many of my
organization&amp;rsquo;s member institutions:  the deprecation of RSA key exchange.&lt;/p&gt;

&lt;p&gt;Deprecation of the RSA key exchange in TLS 1.3 will cause significant problems
for financial institutions, almost all of whom are running TLS internally and
have significant, security-critical investments in out-of-band TLS decryption.&lt;/p&gt;

&lt;p&gt;Like many enterprises, financial institutions depend upon the ability to
decrypt TLS traffic to implement data loss protection, intrusion detection and
prevention, malware detection, packet capture and analysis, and DDoS
mitigation.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Kenny&amp;rsquo;s response: (excerpted from &lt;a href=&#34;https://www.ietf.org/mail-archive/web/tls/current/msg21278.html&#34;&gt;https://www.ietf.org/mail-archive/web/tls/current/msg21278.html&lt;/a&gt;)&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Hi Andrew,&lt;/p&gt;

&lt;p&gt;My view concerning your request: no.&lt;/p&gt;

&lt;p&gt;Rationale: We&amp;rsquo;re trying to build a more secure internet.&lt;/p&gt;

&lt;p&gt;Meta-level comment:&lt;/p&gt;

&lt;p&gt;You&amp;rsquo;re a bit late to the party. We&amp;rsquo;re metaphorically speaking at the stage of
emptying the ash trays and hunting for the not quite empty beer cans.&lt;/p&gt;

&lt;p&gt;More exactly, we are at draft 15 and RSA key transport disappeared from the spec
about a dozen drafts ago. I know the banking industry is usually a bit slow off
the mark, but this takes the biscuit.&lt;/p&gt;

&lt;p&gt;Cheers,&lt;/p&gt;

&lt;p&gt;Kenny&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;anti-downgrade-prevention-and-detection&#34;&gt;Anti-Downgrade Prevention and Detection&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://eprint.iacr.org/2016/072.pdf&#34;&gt;Downgrade resilience in key-exchange protocols&lt;/a&gt; by Karthikeyan Bhargavan, Christina Brzuska, Cédric Fournet, Markulf Kohlweiss, Santiago Zanella-Béguelin and Matthew Green in IEEE Symposium on Security and Privacy (SP), 2016.&lt;/p&gt;

&lt;p&gt;TLS 1.2 suffers from various &lt;a href=&#34;https://tlseminar.github.io/downgrade-attacks/&#34;&gt;downgrade&lt;/a&gt; and &lt;a href=&#34;https://en.wikipedia.org/wiki/Man-in-the-middle_attack&#34;&gt;man-in-the-middle attacks&lt;/a&gt; like Logjam, FREAK and POODLE.
Logjam exploits the option of using legacy &amp;ldquo;export-grade&amp;rdquo; 512-bit Diffie–Hellman groups in TLS 1.2. It forces susceptible servers to downgrade to cryptographically weak 512 bit Diffie-Hellman groups, which could then be compromised.
FREAK is a man-in-the-middle attack that affects the OpenSSL stack, the default Android web browser, and some Safari browsers. It tricks servers into negotiating a TLS connection using cryptographically weak 512 bit encryption keys.
POODLE exploits vulnerability in SSL 3.0 but is applicable to TLS 1.2 once the attacker performs version rollback to SSL 3.0 through a man-in-the-middle attack.&lt;/p&gt;

&lt;p&gt;The above problems can be countered using correct downgrade protection. While TLS 1.2 does implement downgrade protection, it fails to do so correctly. Downgrade protection requires sending MAC of finished messages between client and server to ensure that the negotiated parameters have not be modified by a MITM attacker. TLS 1.2 does not hash all the negotiated parameters in its MAC allowing the attacker to alter the non-hashed parameters and launch downgrade attacks. TLS 1.3 fixes this issue by hashing all the parameters and also isolates TLS 1.2 or lower version messages (which have downgrade resilience issues) by requiring the TLS 1.3 server to set first &lt;code&gt;N&lt;/code&gt; bits of its ServerRandom nonce to a fixed value on recieving ClientHello message from a TLS 1.2 or below client. This signals the TLS 1.3 clients and they reject any packet that has the fixed value sequence.&lt;/p&gt;

&lt;h3 id=&#34;downgrade-resilience-in-key-exchange-protocols&#34;&gt;Downgrade Resilience in Key-Exchange Protocols&lt;/h3&gt;

&lt;p&gt;Downgrade protection primarily relies on the MACs in the finished messages, which in turn rely on the strength of the group and the negotiated algorithms and hash.
If a client and server support a weak group, then an attacker can downgrade the group and break the master secret to forget the MACs, as in Logjam.&lt;/p&gt;

&lt;p&gt;The figure below shows the faulty downgrade resilience of TLS 1.2, where the TLS 1.2 server fails to hash  the negotiated parameters like protocol version (&lt;code&gt;v&lt;/code&gt;), chosen parameters (&lt;code&gt;a_R&lt;/code&gt;) and server identity (&lt;code&gt;pk_R&lt;/code&gt;) in its hash message &lt;code&gt;hash_1(.)&lt;/code&gt; (see subfigure (b) of the below figure).
&lt;center&gt;&lt;img src=&#34;https://tlseminar.github.io/images/tls-13/tls1_2.png&#34; alt=&#34;Downgrade Protection in TLS 1.2&#34; style=&#34;width:1000px;&#34;/&gt;&lt;br&gt;
&lt;sup&gt;TLS 1.0 - 1.2 with (EC)DHE key exchange (a), where messages labeled with * occur only when client authentication is enabled, and (b) its downgrade protection sub-protocol&lt;/sup&gt;&lt;br&gt;&lt;sup&gt;Source: &lt;a href=&#34;https://eprint.iacr.org/2016/072.pdf&#34;&gt;https://eprint.iacr.org/2016/072.pdf&lt;/a&gt;&lt;/sup&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;Draft 10 of TLS 1.3 implements the following downgrade protection mechanism which rectifies the above mistake and consequently hashes all the negotiated parameters. Notice the &lt;code&gt;hash_1(H(m_1, m_2, -))&lt;/code&gt; in the message sent by server (subfigure (b) in the figure below), which hashes all the negotiated parameters in &lt;code&gt;m_2&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;https://tlseminar.github.io/images/tls-13/tls1_3_draft10.png&#34; alt=&#34;Downgrade Protection in TLS 1.3 Draft 10&#34; style=&#34;width:1000px;&#34;/&gt;&lt;br&gt;
&lt;sup&gt;TLS 1.3 1-RTT mode with server-only authentication (a) and its downgrade protection sub-protocol (b) &lt;/sup&gt;&lt;br&gt;&lt;sup&gt;Source: &lt;a href=&#34;https://eprint.iacr.org/2016/072.pdf&#34;&gt;https://eprint.iacr.org/2016/072.pdf&lt;/a&gt;&lt;/sup&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;However, there are three downgrade attacks possible on TLS 1.3 as described in Draft 10.
One, an attacker downgrades the connection to TLS 1.2 or lower and mounts any of the downgrade attacks mentioned before. This will succeed as long as the attacker can forge the finished MACs.
Second, an attacker uses the TLS fallback mechanism to stop TLS 1.3 connections and allows only TLS 1.2 connections to go through. Even if the end points implement the fallback protection mechanism, the attacker can use one of the downgrade attacks in TLS 1.2 to break the connection.
Third, in Draft 10 of the TLS1.3 protocol, the handshake hashes restart upon receiving a Retry message and hence, the attacker can downgrade the Diffie-Hellman group for some classes of negotiation functions.&lt;/p&gt;

&lt;p&gt;TLS 1.3 draft 11 counters the above three attacks by incorporating two countermeasures.
First, TLS 1.3 protocol continues the handshake hashes over retries (subfigure (a) of the figure below).
Second, TLS 1.3 servers always include their highest supported version number in the server nonce, even when they choose a lower version such as TLS 1.0.
Draft 11 of TLS 1.3 &lt;a href=&#34;https://github.com/tlswg/tls13-spec/pull/284&#34;&gt;fixed&lt;/a&gt; the issue by requiring TLS 1.3 server to set top N bits of the ServerRandom to be a specific fixed value on receiving ClientHello message from a TLS 1.2 or below client. TLS 1.3 clients which receive a TLS 1.2 or below ServerHello check for this value and abort if they receive it. The figure below shows the client check using &lt;code&gt;verifyVersion&lt;/code&gt; functionality.
This allows for detection of downgrade attacks over and above the Finished handshake as long as ephemeral cipher suites are used. This prevents attacks targeted at (EC)DHE.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;https://tlseminar.github.io/images/tls-13/tls1_3_draft11.png&#34; alt=&#34;Downgrade Protection in TLS 1.3 Draft 11&#34; style=&#34;width:1000px;&#34;/&gt;&lt;br&gt;
&lt;sup&gt;TLS 1.3 Draft 11 Update on Downgrade Resilience in Key-Exchange Protocols&lt;/sup&gt;&lt;br&gt;&lt;sup&gt;Source: &lt;a href=&#34;https://eprint.iacr.org/2016/072.pdf&#34;&gt;https://eprint.iacr.org/2016/072.pdf&lt;/a&gt;&lt;/sup&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;The TLS 1.3 server will send a &lt;a href=&#34;https://tools.ietf.org/html/draft-ietf-tls-tls13-18#section-4.1.3&#34;&gt;&lt;code&gt;ServerHello&lt;/code&gt;&lt;/a&gt; message in response to a &lt;code&gt;ClientHello&lt;/code&gt; message when it is able to find an acceptable set of algorithms and the client&amp;rsquo;s &lt;code&gt;key_share&lt;/code&gt; extension is acceptable.  If it is not able to find an acceptable set of parameters, the server will respond with a &lt;code&gt;handshake_failure&lt;/code&gt; fatal alert. The &lt;code&gt;ServerHello&lt;/code&gt; message contains server&amp;rsquo;s random value which incorporates downgrade protection mechanism. If a &lt;code&gt;ClientHello&lt;/code&gt; indicates only support for TLS 1.2 or below, then the last eight bytes of server&amp;rsquo;s random value MUST be set to: &lt;code&gt;44 4F 57 4E 47 52 44 01&lt;/code&gt;.
If a &lt;code&gt;ClientHello&lt;/code&gt; indicates only support for TLS 1.1 or below, then the last eight bytes of server&amp;rsquo;s random value SHOULD be set to: &lt;code&gt;44 4F 57 4E 47 52 44 00&lt;/code&gt;.
TLS 1.3 clients are required to check the above values in the random field of server responses.&lt;/p&gt;

&lt;h2 id=&#34;authenticated-encryption&#34;&gt;Authenticated Encryption&lt;/h2&gt;

&lt;p&gt;Up until now, we&amp;rsquo;ve mostly concerned ourselves with the &amp;ldquo;MAC-Encode-Encrypt&amp;rdquo; (MEE) packet construction method.  In a nutshell, MEE follows three steps:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Calculate a MAC over the payload&lt;/li&gt;
&lt;li&gt;Append the MAC and an appropriate amount of padding to the payload&lt;/li&gt;
&lt;li&gt;Encrypt the modified payload to generate a ciphertext&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;As we&amp;rsquo;ve discussed in previous classes, the CBC mode of operation has its downsides; adversaries can break encryption by utilizing padding oracle attacks, since padding can only exist in a handful of values and lengths.  Moreover, it&amp;rsquo;s impossible to actually verify the integrity of the ciphertext &lt;em&gt;until the MAC has been revealed by decrypting the ciphertext&lt;/em&gt;.  The duration required to decrypt the tampered ciphertext and validate the MAC leaks sensitive (and potentially useful) timing information to adversaries.&lt;/p&gt;

&lt;h4 id=&#34;encrypt-then-mac&#34;&gt;Encrypt-then-MAC&lt;/h4&gt;

&lt;p&gt;In general, MEE is inferior to its cousin, &amp;ldquo;Encrypt-then-MAC&amp;rdquo;  (ETM).  In ETM, as opposed to MEE, the plaintext is encrypted &lt;em&gt;before&lt;/em&gt; the MAC is calculated.  Intuitively, it makes sense that ETM is more secure&amp;mdash;any tampering of the ciphertext is immediately evident when the MAC is calculated, therefore no decryption takes place (and no timing information is leaked).  Additionally, assuming the ciphertext appears random, the MAC also appears random and reveals no information about the underlying ciphertext.&lt;/p&gt;

&lt;h4 id=&#34;galois-counter-mode-gcm&#34;&gt;Galois/Counter Mode (GCM)&lt;/h4&gt;

&lt;p&gt;Before we jump on the ETM bandwagon, however, let&amp;rsquo;s take a look at yet another mode of operation, &lt;em&gt;Galois/Counter Mode&lt;/em&gt; (GCM).  GCM is an authenticated encryption algorithm that provides confidentiality &lt;em&gt;and&lt;/em&gt; integrity, and does so extremely efficiently.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;https://tlseminar.github.io/images/tls-13/gcm.png&#34; alt=&#34;GCM&#34; width=500px/&gt;&lt;br&gt;
&lt;sup&gt;Galois/Counter Mode (credit:  Wikipedia)&lt;/sup&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt; GCM At-A-Glance &lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Sequentially number blocks&lt;/li&gt;
&lt;li&gt;Encrypt block numbers with block cipher E&lt;/li&gt;
&lt;li&gt;XOR result of encryption with plaintext to produce ciphertext&lt;/li&gt;
&lt;li&gt;Combine ciphertext with authentication code to produce authentication tag&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The authentication tag can be used to verify the integrity of the data upon decryption, similar to an HMAC.  If this &amp;ldquo;counter mode&amp;rdquo; of authenticated encryption seems superior, that&amp;rsquo;s because &lt;em&gt;it is&lt;/em&gt;!  TLS 1.3 only provides support for GCM, CCM, and ChaCha20-Poly1305, another authenticated encryption mode of operation.  Say goodbye to MAC-then-encrypt.&lt;/p&gt;

&lt;h2 id=&#34;tls-v1-3-removals&#34;&gt;TLS v1.3 Removals&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://blog.cloudflare.com/tls-1-3-overview-and-q-and-a/&#34;&gt;An overview of TLS 1.3 and Q&amp;amp;A&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In TLS v1.3, everything was scrutinized for being really necessary and
secure, and scrapped otherwise. In particular, the following things
are removed:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.cloudflare.com/keyless-ssl-the-nitty-gritty-technical-details/&#34;&gt;static RSA handshake&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;the &lt;a href=&#34;https://blog.cloudflare.com/padding-oracles-and-the-decline-of-cbc-mode-ciphersuites/&#34;&gt;CBC MAC-then-Encrypt&lt;/a&gt; modes, which were responsible for Vaudenay, Lucky13, POODLE, LuckyMinus20&lt;/li&gt;
&lt;li&gt;weak primitives like RC4, SHA1, MD5&lt;/li&gt;
&lt;li&gt;compression&lt;/li&gt;
&lt;li&gt;renegotiation&lt;/li&gt;
&lt;li&gt;custom FFDHE groups&lt;/li&gt;
&lt;li&gt;RSA PKCS#1v1.5&lt;/li&gt;
&lt;li&gt;explicit nonces&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;formal-verification&#34;&gt;Formal Verification&lt;/h2&gt;

&lt;p&gt;TLS 1.3 is the first revision of the TLS protocol to incorporate formal verification during development.
Cas Cremers, Marko Horvat, Sam Scott, and Thyla van der Merwe&amp;rsquo;s paper, &lt;a href=&#34;https://tls13tamarin.github.io/TLS13Tamarin/docs/tls13tamarin.pdf&#34;&gt;&lt;em&gt;Automated Analysis of TLS 1.3: 0-RTT, Resumption and Delayed Authentication&lt;/em&gt;&lt;/a&gt;, provides a recent (February 2016) description of the challenges and results of such an analysis. In the &lt;a href=&#34;https://tls13tamarin.github.io/TLS13Tamarin/#introduction&#34;&gt;blog post&lt;/a&gt; associated with their work, the authors contextualize their verification efforts:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;The various flaws identified in TLS 1.2 and below, be they implementation- or specification-based, have prompted the TLS Working Group to adopt an &amp;ldquo;analysis-before-deployment&amp;rdquo; design paradigm in drafting the next version of the protocol. After a development process of many months, the &lt;a href=&#34;https://github.com/tlswg/tls13-spec&#34;&gt;TLS 1.3 specification&lt;/a&gt; is nearly complete. In the spirit of contributing towards this new design philosophy, we model the TLS 1.3 specification using the Tamarin prover, a tool for the automated analysis of security protocols.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The authors are able to prove that &lt;a href=&#34;https://tools.ietf.org/html/draft-ietf-tls-tls13-10&#34;&gt;revision 10&lt;/a&gt; of the specification meets the goals of authenticated key exchange for any combination of unilaterally or mutually authenticated handshakes. Further, the authors discovered a new, unknown attack on the protocol during a PSK-resumption handshake. The &lt;a href=&#34;https://tools.ietf.org/html/draft-ietf-tls-tls13-11&#34;&gt;11th revision&lt;/a&gt; of the protocol included a fix for this attack.&lt;/p&gt;

&lt;h3 id=&#34;protocol-model&#34;&gt;Protocol Model&lt;/h3&gt;

&lt;p&gt;The authors used the &lt;a href=&#34;https://github.com/tamarin-prover/tamarin-prover&#34;&gt;Tamarin&lt;/a&gt; prover for their analysis. Tamarin is an interactive theorem proving environment (similar to &lt;a href=&#34;https://coq.inria.fr/about-co&#34;&gt;Coq&lt;/a&gt;) specially designed for the verification of protocols such as TLS. As TLS is already an abstract specification, encoding TLS 1.3 into the Tamarin specification language was relatively straightforward. &amp;ldquo;Rules&amp;rdquo; (functions) over this specification captured honest-party and adversary actions alike. The following state diagram depicts the client TLS state (as defined in Tamarin) and transitions between the states (Tamarin rules) for an entire session.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
    &lt;img src=&#34;https://tlseminar.github.io/images/tls-13/client-sm.png&#34; alt=&#34;Partial client state machines for TLS 1.3 revision 10&#34; style=&#34;width:800px;&#34;/&gt;
    &lt;br&gt;&lt;br&gt;
    &lt;sup&gt;Source: &lt;a href=&#34;http://tls13tamarin.github.io/TLS13Tamarin/#building-a-model&#34;&gt;Automated Analysis of TLS 1.3&lt;/a&gt;&lt;/sup&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;h3 id=&#34;proven-security-properties&#34;&gt;Proven Security Properties&lt;/h3&gt;

&lt;p&gt;The next step in the analysis involved encoding the desired security properties of TLS 1.3 as Tamarin lemmas. The authors encoded the following properties:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;unilateral authentication of the server (mandatory)&lt;/li&gt;
&lt;li&gt;mutual authentication (optional)&lt;/li&gt;
&lt;li&gt;confidentiality and perfect forward secrecy of session keys&lt;/li&gt;
&lt;li&gt;integrity of handshake messages&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Each lemma must hold over its respective domain of states (a subset of the nodes in the client state machine above, for example). While proof assistants like Tamarin are capable of constructing simple proofs, a significant amount of manual effort was required to prove the enumerated lemmas. As such, a notable contribution of this work is the actual Tamarin proof artifact itself, not just what was and wasn&amp;rsquo;t proven. The authors claim their Tamarin abstractions and proofs were constructed with extensibility to future TLS development in mind.&lt;/p&gt;

&lt;h3 id=&#34;discovered-attack&#34;&gt;Discovered Attack&lt;/h3&gt;

&lt;p&gt;While verifying the &lt;a href=&#34;https://www.ietf.org/proceedings/93/slides/slides-93-tls-2.pdf&#34;&gt;delayed authentication mechanism&lt;/a&gt; portion of the protocol, an attack was discovered which violated client authentication; an adversary is able to impersonate a client while communicating with the server.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Step 1.&lt;/strong&gt; The victim client, Alice, establishes a connection with the man-in-the-middle attacker, Charlie. Charlie establishes a connection with Bob, the server which which Alice wishes to connect. A PSK is established for both connections, &lt;code&gt;PSK_1&lt;/code&gt; and &lt;code&gt;PSK_2&lt;/code&gt;, respectively.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
    &lt;img src=&#34;https://tlseminar.github.io/images/tls-13/att1.png&#34; alt=&#34;Client Authentication Attack: Step 1&#34; style=&#34;width:800px;&#34;/&gt;
    &lt;br&gt;
    &lt;sup&gt;Source: &lt;a href=&#34;http://tls13tamarin.github.io/TLS13Tamarin/#attacking-client-authentication&#34;&gt;Automated Analysis of TLS 1.3&lt;/a&gt;&lt;/sup&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Step 2.&lt;/strong&gt;  Alice sends a random nonce, &lt;code&gt;nc&lt;/code&gt;, to Charlie using &lt;code&gt;PSK_1&lt;/code&gt;. Charlie reuses this nonce to initiate a PSK-resumption handshake with Bob. Bob responds with random nonce &lt;code&gt;ns&lt;/code&gt; and the server &lt;code&gt;Finished&lt;/code&gt; message using &lt;code&gt;PSK_2&lt;/code&gt;. Charlie reuses &lt;code&gt;ns&lt;/code&gt; and recomputes the &lt;code&gt;Finished&lt;/code&gt; message for Alice using &lt;code&gt;PSK_1&lt;/code&gt;.  Alice Returns her &lt;code&gt;Finished&lt;/code&gt; message to Charlie. Charlie then recomputes this &lt;code&gt;Finished&lt;/code&gt; message for Bob using &lt;code&gt;PSK_2&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
    &lt;img src=&#34;https://tlseminar.github.io/images/tls-13/att2.png&#34; alt=&#34;Client Authentication Attack: Step 2&#34; style=&#34;width:800px;&#34;/&gt;
    &lt;br&gt;&lt;br&gt;
    &lt;sup&gt;Source: &lt;a href=&#34;http://tls13tamarin.github.io/TLS13Tamarin/#attacking-client-authentication&#34;&gt;Automated Analysis of TLS 1.3&lt;/a&gt;&lt;/sup&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Step 3.&lt;/strong&gt; Charlie makes a request to Bob that requires client authentication. Charlie is thus prompted for his certificate and verification. This request is re-encrypted and forwarded to Alice. To compute the verification signature of this forwarded request, Alice uses the &lt;code&gt;session_hash&lt;/code&gt; value, which is the hash of all handshake messages excluding the &lt;code&gt;Finished&lt;/code&gt; messages. This &lt;code&gt;session_hash&lt;/code&gt; value will match that of Charlie and Bob&amp;rsquo;s, and thus Charlie can re-encrypt Alice&amp;rsquo;s signature for Bob. Bob accepts Alice&amp;rsquo;s certificate and verification as valid authentication for Charlie.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
    &lt;img src=&#34;https://tlseminar.github.io/images/tls-13/att3.png&#34; alt=&#34;Client Authentication Attack: Step 3&#34; style=&#34;width:800px;&#34;/&gt;
    &lt;br&gt;&lt;br&gt;
    &lt;sup&gt;Source: &lt;a href=&#34;http://tls13tamarin.github.io/TLS13Tamarin/#attacking-client-authentication&#34;&gt;Automated Analysis of TLS 1.3&lt;/a&gt;&lt;/sup&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;The discovery of this attack is noteworthy in that it was completely unexpected by the TLS Working Group.&lt;/p&gt;

&lt;p&gt;The fix, which forces the &lt;code&gt;session_hash&lt;/code&gt; value to include &lt;code&gt;Finished&lt;/code&gt; messages was even suggested in an official &lt;a href=&#34;https://github.com/tlswg/tls13-spec/pull/316&#34;&gt;pull request&lt;/a&gt;, but was rejected.&lt;/p&gt;

&lt;p&gt;The authors make a strong case that formal verification has been an
extremely valuable part of the design process of TLS 1.3. The speed
with which the fix was incorporated into subsequent protocol revisions
suggests that the TLS Working Group shares this sentiment.&lt;/p&gt;

&lt;p&gt;Two &lt;a href=&#34;http://www.ieee-security.org/TC/SP2017/&#34;&gt;Oakland 2017&lt;/a&gt;
papers provide more reports on formal verification efforts for TLS
1.3, up through Draft 18:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Karthikeyan Bhargavan, Bruno Blanchet, and Nadim Kobeissi. &lt;a href=&#34;http://prosecco.gforge.inria.fr/personal/bblanche/publications/BhargavanBlanchetKobeissiSP2017.pdf&#34;&gt;&lt;em&gt;Verified Models and Reference Implementations
for the TLS 1.3 Standard Candidate&lt;/em&gt;&lt;/a&gt;. &lt;a href=&#34;https://www.ieee-security.org/TC/SP2017/program.html&#34;&gt;IEEE Symposium on Security and Privacy&lt;/a&gt;, May 2017.&lt;/li&gt;
&lt;li&gt;Karthikeyan Bhargavan, Antoine Delignat-Lavaud, Cédric Fournet, Markulf Kohlweiss, Jianyang Pan, Jonathan Protzenko, Aseem Rastogi, Nikhil Swamy, Santiago Zanella-Béguelin, and Jean Karim Zinzindohoué. &lt;a href=&#34;http://www.cs.umd.edu/~aseem/record.pdf&#34;&gt;&lt;em&gt;Implementing and Proving the TLS 1.3 Record Layer&lt;/em&gt;&lt;/a&gt;. &lt;a href=&#34;https://www.ieee-security.org/TC/SP2017/program.html&#34;&gt;IEEE Symposium on Security and Privacy&lt;/a&gt;, May 2017.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Usable Security in TLS</title>
      <link>https://tlseminar.github.io/usable-security/</link>
      <pubDate>Wed, 22 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://tlseminar.github.io/usable-security/</guid>
      <description>

&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;In 1999, Alma Whitten and Doug Tygar performed a usability analysis of PGP 5.0 called &lt;a href=&#34;https://people.eecs.berkeley.edu/~tygar/papers/Why_Johnny_Cant_Encrypt/USENIX.pdf&#34;&gt;&lt;em&gt;Why Johnny Can’t Encrypt&lt;/em&gt;&lt;/a&gt;. PGP Corp claimed its product “makes complex mathematical cryptography accessible for novice computer users”.&lt;/p&gt;

&lt;p&gt;However, Whitten and Tygar’s evaluation, based on experiments with
users, argued that PGP’s user interface design made computer security
usable only for people who are “already knowledgeable in that area”.
This does not seem to be a fair expectation for users. Today, around
40% of the &lt;a href=&#34;http://www.internetlivestats.com/internet-users/&#34;&gt;entire world population use the
internet&lt;/a&gt;. When the
paper was published, that &lt;a href=&#34;http://www.internetworldstats.com/emarketing.htm&#34;&gt;percentage was
4.1%&lt;/a&gt;. Thus, as the
number of internet users has skyrocketed, the security community has
become increasingly aware of how important it is to make security understandable and accessible to typical users.&lt;/p&gt;

&lt;p&gt;Usability is, of course, important for any service that is a vital part of the lives of billions. However, for security in particular, there are higher stakes&amp;mdash; confusing user interfaces can lead to sensitive data being exposed, from financial transactions to identification information. HTTPS users are vulnerable to significant, real-life risks when technical language abounds and browsers inundate them with too many warnings (many of which are false positives).&lt;/p&gt;

&lt;p&gt;Humans are arguably the weakest link, so usability and communication must be taken into account in any model that expects the user to act safely. When a user interface fails to effectively communicate security consequences, it is unreasonable to blame an improperly informed user for exposing themselves to those dangers.&lt;/p&gt;

&lt;h3 id=&#34;users-are-not-the-enemy&#34;&gt;Users Are Not The Enemy&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://tlseminar.github.io/docs/usersnotenemy.pdf&#34;&gt;&lt;em&gt;Users Are Not The Enemy&lt;/em&gt;&lt;/a&gt;, Anne Adams and Martina Angela Sasse. Communications of the ACM. December 1999.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Even perfectly written software can become vulnerable to attacks when the user does not understand its behavior. In &lt;em&gt;Users Are Not the Enemy&lt;/em&gt;, Adams and Sasse discuss how users can both knowingly and unknowingly compromise computer security mechanisms such as password authentication. In authentication, few users knew how to or even understood the need to constitute a secure password. As a result, most of the passwords revolved around familiar and related phrases, words, or character patterns. Because the average person finds it difficult to remember passwords, most users rarely change the passwords and some prefer to record them in plaintext.&lt;/p&gt;

&lt;p&gt;Users are the reason, however, not the &lt;em&gt;true&lt;/em&gt; enemy. Without sufficient knowledge of hacking techniques, typical users understandably default to their own models of security threats and priorities. Meanwhile, security experts and developers do not always understand the users’ perceptions, tasks, or needs. Before quickly dismissing users as unknowing collaborators in cyberspace crime, we should educate them in why we are protecting their account. Consequently, they would be more motivated to practice security-conscious behaviors when they perceive a threat.&lt;/p&gt;

&lt;h3 id=&#34;the-source-awakens&#34;&gt;The Source Awakens&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://www.usenix.org/conference/enigma2016/conference-program/presentation/smith&#34;&gt;&lt;em&gt;The Source Awakens&lt;/em&gt;&lt;/a&gt;. Presentation at USENIX Enigma 2016 by Matthew Smith.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;We often see breaking news articles detailing the most recent hacking or the most recent password leak. These aren’t attacks focusing on specific users typically uneducated in cybersecurity principles but rather on firms’ products, that have been developed by computer scientists and engineers who are supposed to be experts in their fields. Now, if these developers are making mistakes, is it their lack of developing ability or is it their lack of understanding of the security issues? Considering the two, it’s best to assume the latter, as it is more likely. Therefore, developers are themselves making mistakes when they are not aware of the security issues latent in their system.&lt;/p&gt;

&lt;p&gt;A story, which probably hits home for many software developers, is trying to Google an approach or solution to their problem or feature that they want to implement. The developer clicks on the first StackOverflow link and gets a solution, implements it, and keeps it as long as it apparently works. The developer now continues and goes about completing the task with no question to the validity of the code just implemented. What the developer doesn’t realize is that the code found and used may have serious security, such as this this code for self-signed certificate validation:&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://tlseminar.github.io/images/usable-security/certvalidation.png&#34; alt=&#34;validation&#34; width=&#34;90%&#34;&gt;&lt;Br&gt;
&lt;span class=&#34;caption&#34;&gt;&lt;em&gt;Source: &lt;/em&gt;&lt;a href=&#34;https://www.usenix.org/conference/enigma2016/conference-program/presentation/smith&#34;&gt;The Source Awakens&lt;/a&gt;&lt;/span&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;The code seems to work. But, upon closer inspection, it clearly
doesn’t do anything to check certificates. When this program sees any
and all certificates, it simply approves every single one, regardless
of what is contained within. So, of course the code &amp;ldquo;works&amp;rdquo; when the
developer incorporates into their program (at least it gives no
apparent errors), but it presents a major security vulnerability.
Similarly, developers may use some dummy certificate validator or
self-signed certificates for testing, but then forget to remove them
in the release.&lt;/p&gt;

&lt;p&gt;Thus, usability is a security issue for developers using APIs and
libraries, not just for end users using graphical interfaces.&lt;/p&gt;

&lt;h4 id=&#34;malware-analysis-tools&#34;&gt;Malware Analysis Tools&lt;/h4&gt;

&lt;p&gt;There are several decompilers that take binary code and output the
decompiled code, such as HexRays (shown below). But, the generated
code isn’t very readable to the average programmer, such as this example from the Simda malware domain generation code:&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://tlseminar.github.io/images/usable-security/hexrays.jpg&#34; alt=&#34;hexrays&#34; width=&#34;90%&#34;&gt;&lt;Br&gt;
&lt;span class=&#34;caption&#34;&gt;&lt;em&gt;Source: &lt;/em&gt;&lt;a href=&#34;https://www.usenix.org/conference/enigma2016/conference-program/presentation/smith&#34;&gt;The Source Awakens&lt;/a&gt;&lt;/span&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;Smith discusses how his team created a new system called DREAM++ that
can outputs more readable decompiled code, so we may get something like:&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://tlseminar.github.io/images/usable-security/dream++.jpg&#34; alt=&#34;dream++&#34; width=&#34;60%&#34;&gt;&lt;Br&gt;
&lt;span class=&#34;caption&#34;&gt;&lt;em&gt;Source: &lt;/em&gt;&lt;a href=&#34;https://www.usenix.org/conference/enigma2016/conference-program/presentation/smith&#34;&gt;The Source Awakens&lt;/a&gt;&lt;/span&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;By producing more readable decompiled code, both security experts as
well as typical programmers were able to much more easily and quickly
understand the decompiled programs.&lt;/p&gt;

&lt;h3 id=&#34;browser-warnings&#34;&gt;Browser Warnings&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://adrifelt.github.io/sslinterstitial-chi.pdf&#34;&gt;&lt;em&gt;Improving SSL Warnings: Comprehension and Adherence&lt;/em&gt;&lt;/a&gt; by &lt;a href=&#34;http://www.adrienneporterfelt.com/&#34;&gt;Adrienne Porter Felt&lt;/a&gt;, Alex Ainslie, Robert Reeder, et Al. ACM Conference on Human Factors in Computing (CHI), 2015.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Security experts and programmers will always attempt to do what is best for their end-users, but the problem is that (very) often the end-user will circumvent any attempt at stopping whatever they intend to do. Looking at HTTPS specifically, the inherent security boils down to the end user’s choice of whether or not to proceed to a possibly unsafe webpage.&lt;/p&gt;

&lt;p&gt;Therefore, it is the web browser&amp;rsquo;s responsibility to provide adequate notice to a user when their connection is not secure. Research conducted in 2015 by Google and the University of Pennsylvania found that reducing technical jargon in Chrome browser SSL warning and focusing on brevity and simplicity, resulted in an increase in comprehension of SSL warnings. Still, only 49% of the respondent&amp;rsquo;s could answer the following question correctly:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;What might happen if you ignored this error while checking your email?&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Your computer might get malware&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A hacker might read your email&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(Technically both are true, but realistically the user is supposed to understand that invalid HTTPS results in hackers being able to read your communications in plaintext)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The researchers also found that the improved design of browser warnings could influence up to 30% more users to go &amp;ldquo;Back to Safety&amp;rdquo; rather than &amp;ldquo;Proceed to Unsafe&amp;rdquo;. The new design is shown below:&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://tlseminar.github.io/images/usable-security/chrome37.png&#34; alt=&#34;chrome37&#34; width=&#34;50%&#34;&gt;&lt;Br&gt;
&lt;span class=&#34;caption&#34;&gt;&lt;em&gt;Source: &lt;/em&gt;&lt;a href=&#34;https://adrifelt.github.io/sslinterstitial-chi.pdf&#34;&gt;Improving SSL Warnings: Comprehension and Adherence&lt;/a&gt;&lt;/span&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;If this seems familiar, it is because it was introduced in Chrome 37.
This new design requires an extra click from a user to proceed to the
potentially unsafe site. Notice that the unsafe option is a dark gray
text link contrasted with a safe blue button.&lt;/p&gt;

&lt;p&gt;Below, a blast from the past: SSL warnings from pre-2015 Chrome versions.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://tlseminar.github.io/images/usable-security/sslwarning.png&#34; width=&#34;70%&#34; alt=&#34;sslwarning&#34;&gt;&lt;Br&gt;
&lt;span class=&#34;caption&#34;&gt;&lt;em&gt;Source: &lt;/em&gt;&lt;a href=&#34;http://blog.getpostman.com/2014/01/28/using-self-signed-certificates-with-postman/&#34;&gt;Self Signed Certificates with Postman&lt;/a&gt;&lt;/span&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;Noticeably, this has ‘too much’ technical jargon and is neither short nor simple. Similarly the user can easily proceed to the site straight from the warning. Google’s research was meant to improve the user experience when seeing these warning to minimize the security risks taken by the end-user.&lt;/p&gt;

&lt;h3 id=&#34;tls-errors-on-the-web&#34;&gt;TLS Errors on the Web&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;http://devd.me/papers/trustmemaybe.pdf&#34;&gt;&lt;em&gt;Here’s My Cert, So Trust Me, Maybe? Understanding TLS Errors on the Web&lt;/em&gt;&lt;/a&gt; by Devdatta Akhawe, Bernhard Amann, Matthias Vallentin, &amp;amp; Robin Sommer. International World Wide Web Conference (WWW) 2013.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The end-user isn’t the only source of security issues when it comes to
browser usability in TLS. The behavior of web browsers may not be
studied as much as vulnerabilities in TLS, but it is almost just as
dangerous in measure. Usually when browsers report TLS errors, they
don’t offer distinguishing features between real attacks and benign
errors; hence leaving the decision to the end-user of whether
continuing is itself a security issue. On most occasions, errors will
turn out to be “false positives”, which can include errors due to
server misconfiguration, self-signed certificates (as mentioned
previously), and name validation errors. As a result, end-users
quickly train themselves to click through these warnings, regardless
of the content, making it unlikely that they will pay enough attention
when a real attack comes along.&lt;/p&gt;

&lt;p&gt;This paper reports on a large-scale measurement study of common TLS
warnings. A total of 11.5 billion SSL connections on all ports were
captured over a nine-month period in their experiment. The warnings
and errors produced were then categorized based on where they occurred
during the verification: chain building errors, chain validation
errors, and name validation errors. These correspond to the three
separate steps of certificate validation of the Network Security
Services (NSS) library, used by Firefox (and Chrome on Linux). The
following is an algorithm that can translate the NSS responses into
their categorization:&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://tlseminar.github.io/images/usable-security/nssalgorithm.jpg&#34; alt=&#34;nssalgorithm&#34; width=&#34;60%&#34;&gt;&lt;Br&gt;
&lt;span class=&#34;caption&#34;&gt;&lt;em&gt;Source: &lt;/em&gt;&lt;a href=&#34;http://devd.me/papers/trustmemaybe.pdf&#34;&gt;Here’s My Cert, So Trust Me, Maybe?&lt;/a&gt;&lt;/span&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;The results of this experiment indicate a clear opportunity, and need,
for reducing false warnings.  A 1.54% false warning rate is
unacceptable if we understand that benign scenarios are orders of
magnitude more common than actual attacks.&lt;/p&gt;

&lt;p&gt;Based on this analysis, a number of concrete recommendations are
proposed to help browser vendors lower the risk of such unwanted
habituation. For example, advocating the use of free TLS certificates
via authorities like StartCom, using a more relaxed name validation
algorithm that accepts multiple levels for an asterisk, or enabling
AIA support or preload all known intermediate authorities in the
browser cache. By implementing these changes, the complete usability
of browsers for end-users will be significantly improved, therefore
leading to a drastic decrease in attacks and security issues caused by
users.&lt;/p&gt;

&lt;h3 id=&#34;rethinking-connection-security-indicators&#34;&gt;Rethinking Connection Security Indicators&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://www.usenix.org/system/files/conference/soups2016/soups2016-paper-porter-felt.pdf&#34;&gt;&lt;em&gt;Rethinking Connection Security Indicators&lt;/em&gt;&lt;/a&gt; by Adrienne Porter Felt, Robert Reeder, Alex Ainslie, Helen Harris, Max Walker, Christopher Thompson, Mustafa Emre Acer, Elisabeth Morant, and Sunny Consolvo.
Twelfth Symposium on Usable Privacy and Security (SOUPS), July 2016.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;By seriously considering the ramifications of the symbology we use to
send messages to the users, we can work to develop more useful and
informative messages. This section focused on the findings of a study
conducted to figure out how users react to various symbols appearing
in their browsers (most often in the URL field). The study found that
a surprising number of users could identify one or more of the
significant features in a good connection, but the majority of users
could not identify issues with a bad connection or one not using
HTTPS.&lt;/p&gt;

&lt;p&gt;Only about 40% of the people in the study were able to identify an
HTTP connection as insecure or what protocol was being used; many of
the participants believed the symbol had to do with the favicon of the
page or that the symbol included general information about the page
such as permissions. A summary of the results of this research can be
seen in the table below.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://tlseminar.github.io/images/usable-security/icons.png&#34; alt=&#34;icons&#34;&gt;&lt;Br&gt;
&lt;span class=&#34;caption&#34;&gt;&lt;em&gt;Source: &lt;/em&gt;&lt;a href=&#34;https://www.usenix.org/system/files/conference/soups2016/soups2016-paper-porter-felt.pdf&#34;&gt;Rethinking Connection Security Indicators&lt;/a&gt;&lt;/span&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;The researchers attempted to identify the three symbols that would be the most effective for conveying information to the user. They then conducted more research regarding how users would interpret these symbols.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://tlseminar.github.io/images/usable-security/urls.png&#34; width=&#34;40%&#34; alt=&#34;urls&#34;&gt;&lt;Br&gt;
&lt;span class=&#34;caption&#34;&gt;&lt;em&gt;Source: &lt;/em&gt;&lt;a href=&#34;https://www.usenix.org/system/files/conference/soups2016/soups2016-paper-porter-felt.pdf&#34;&gt;Rethinking Connection Security Indicators&lt;/a&gt;&lt;/span&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://tlseminar.github.io/images/usable-security/results.png&#34; alt=&#34;results&#34;&gt;&lt;Br&gt;
&lt;span class=&#34;caption&#34;&gt;&lt;em&gt;Source: &lt;/em&gt;&lt;a href=&#34;https://www.usenix.org/system/files/conference/soups2016/soups2016-paper-porter-felt.pdf&#34;&gt;Rethinking Connection Security Indicators&lt;/a&gt;&lt;/span&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;The researchers were able to confidently determine that any sign of an
error is interpreted to be essentially the same, regardless of color
or shape. Secondly, they determined that even if users were shown to
be on https or ‘secure’ sites, they still had a ‘healthy level of
paranoia’ in only being ‘somewhat’ confident in the security of the
site that they were currently accessing.&lt;/p&gt;

&lt;p&gt;Based on these results, browsers need to start asking what dangers on
the internet are. Is it worse to have a fault in one’s implementation
of their certificates or to not have HTTPS connection at all? Browsers
can also consider blacklists of sites that are known for putting
user’s information or connections at risk. Browsers could also do more
to put security in a more central or significant location, such as
having a pop-up before every page with information on the connection
type and associated risks. We need to become more aware of what
messages we’re sending to the users via the particular symbols that we
choose for varying types of connections.&lt;/p&gt;

&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;We’ve covered several studies showing progress, and the need for more
research, in the area of usable security.  Despite the work done to
bridge the gap between experts and users, there is a still a gulf
between each group’s understanding of the other. In some cases,
browser designers assume that users know what a certificate is, while
users assume that the green lock in their URL bar indicates a website
is free of malware.&lt;/p&gt;

&lt;p&gt;The philosophical debate between informing users more effectively and
simply manipulating them to make &amp;ldquo;correct&amp;rdquo; decisions is also
unresolved. The major browsers have adopted a hybrid approach with TLS
error warnings that both provide basic information on the error and
require significant user effort to circumvent.&lt;/p&gt;

&lt;p&gt;Such error warnings are commonplace, which raises another issue. Users
tend to become accustomed to error messages (habituation), assuming
them to be false positives for genuine threats, because they actually
are false positives in the vast majority of cases.  Benign server
administration errors account for essentially all TLS warnings that
users see. Browser manufacturers are engaged in efforts to reduce the
amount of noise users experience while sifting through warnings of
potential hazards.&lt;/p&gt;

&lt;p&gt;Work at the intersection of security and human-computer interaction
continues to progress, but more needs to be done to ensure the
security of future internet users. We can’t eliminate people, the
weakest links in the chain, so we must remember design systems around
their fallibility. While security is always at the forefront of most
security researchers brains, we must also begin to consider the users
who will be interacting with these features as a part of the system
itself.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>TLS Interception and SSL Inspection</title>
      <link>https://tlseminar.github.io/tls-interception/</link>
      <pubDate>Mon, 20 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://tlseminar.github.io/tls-interception/</guid>
      <description>

&lt;blockquote&gt;
&lt;p&gt;The fact that &amp;ldquo;SSL inspection&amp;rdquo; is a phrase that exists, should be a blazing red flag that what you think SSL is doing for you is fundamentally broken. &lt;strong&gt;Compounding the problem are the mistakes that SSL inspection software authors are making&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&amp;ndash; &lt;em&gt;&lt;a href=&#34;https://insights.sei.cmu.edu/cert/2015/03/the-risks-of-ssl-inspection.html&#34; title=&#34;The Risks of SSL Inspection&#34;&gt;Will Dormann&lt;/a&gt; (2015), Carnegie Melon Software Engineering Institute CERT/CC Blog&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;recent-history&#34;&gt;Recent History&lt;/h3&gt;

&lt;p&gt;TLS Interception, also referred to as SSL Inspection, is a topic that has been in the news in recent years and months. Back in 2014, researchers from Brigham Young University published a paper titled &lt;a href=&#34;https://arxiv.org/pdf/1407.7146.pdf&#34; title=&#34;TLS Proxies: Friend or Foe?&#34;&gt;TLS Proxies: Friend or Foe?&lt;/a&gt; where they deployed a Flash application via Google Adwords campaign to identify client-server certificate mismatches across the web. They discovered a wide prevalence of adware, malware and TLS proxy products presenting certificates trusted by the client but not issued by the server &amp;ndash; and in most instances acting in a negligent manner by introducing security vulnerabilities. One parental filter they tested replaced untrusted certificates with trusted ones, bypassing browser warning screens. &lt;em&gt;This is exactly the type of passive attack HTTPS aims to prevent&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Vulnerabilities involving two advertising injectors, one of which was preinstalled on &lt;a href=&#34;https://nakedsecurity.sophos.com/2015/02/20/the-lenovo-superfish-controversy-what-you-need-to-know&#34;&gt;Lenovo PCs&lt;/a&gt;, were found to severely compromise the security of end users in February of 2015. Later that same year, German journalist &lt;a href=&#34;https://blog.hboeck.de/archives/869-How-Kaspersky-makes-you-vulnerable-to-the-FREAK-attack-and-other-ways-Antivirus-software-lowers-your-HTTPS-security.html&#34;&gt;Hanno Böck&lt;/a&gt; looked at three popular antivirus suites and found that all lowered security by either exposing end users to vulnerabilities like FREAK and CRIME or supporting less secure encrpytion algorithms.&lt;/p&gt;

&lt;p&gt;In early 2017 researchers teamed up with Google, Mozilla, and Cloudflare for an internet-wide survey - &lt;a href=&#34;https://jhalderm.com/pub/papers/interception-ndss17.pdf&#34;&gt;&lt;em&gt;The Security Impact of HTTPS Interception&lt;/em&gt;&lt;/a&gt; (
Zakir Durumeric, Zane Ma, Drew Springall, Richard Barnes, Nick Sullivan, Elie Bursztein, Michael Bailey, J. Alex Halderman, Vern Paxson; in NDSS 2017). TLS interception software was assessed based on how the TLS connection observed from the client differed from the TLS parameters advertised by the client. In all but two of the tested products, security was reduced, and in some cases serious vulnerabilities were introduced. Most recently in February of 2017, a Chrome 56 update took down almost a third of Montgomery County Public School&amp;rsquo;s 50,000 fleet of Chromebooks offline, because the school systems web filter, BlueCoat Proxy, &lt;a href=&#34;https://bugs.chromium.org/p/chromium/issues/detail?id=694593&#34;&gt;did not properly handle TLS 1.3&lt;/a&gt;. When Chrome attempted to connect via TLS 1.3, the Bluecoat software abruptly terminated the connection, rather than negotiating for TLS 1.2.&lt;/p&gt;

&lt;h3 id=&#34;how-ssl-tls-interception-works&#34;&gt;How SSL/TLS interception works&lt;/h3&gt;

&lt;p&gt;SSL/TLS interception is performed by software on &amp;ldquo;middleboxes&amp;rdquo; located in between the client and HTTPS website or on the client’s machine, in the case of malware, anti-virus software, and ad injectors.  Middlebox software has both legitimate and illegitimate use cases including proxies or content filters, antivirus suites, content cachers, advertising injectors, and malware.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://tlseminar.github.io/images/tls-interception/middlebox_proxy_setup.png&#34; alt=&#34;Middlebox framework&#34; width=650&gt;&lt;br&gt;
&lt;span class=&#34;caption&#34;&gt;Source: &lt;a href=&#34;https://zakird.com/papers/https_interception.pdf&#34;&gt;The Security Impact of HTTPS Interception (2017)&lt;/a&gt;&lt;/span&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;Middlebox proxy software relies on the client having previously installed a root certificate onto their operating system. Any outgoing SSL/TLS connections from the client are terminated and re-established by the proxy to the server, which acts as an in-the-middle attacker. In an ideal deployment, the proxy&amp;rsquo;s ClientHello mirrors the TLS parameters expressed in client&amp;rsquo;s ClientHello, to provide the same expected parameters to the client. The proxy can then inspect plaintext and establish a TLS connection back to the client using the installed certificate to circumvent browser warnings and silently intercept the connection between client and server.&lt;/p&gt;

&lt;h4 id=&#34;superfish&#34;&gt;Superfish&lt;/h4&gt;

&lt;p&gt;In 2015, there was in an incident involving Lenovo PC&amp;rsquo;s shipped with a preinstalled image advertisement optimizer developed by Superfish. Superfish used Komodia&amp;rsquo;s tool &amp;ldquo;SSL hijacker&amp;rdquo; to intercept HTTPS connections in order to gather image data for its ad optimization engine. Komodia&amp;rsquo;s tool is similar to to all SSL inspectors &amp;mdash; it first installs root certificates on the client machine and then MITMs all TLS connections to HTTPs websites, issuing the  preinstalled Komodia certificate to the client instead of the target HTTPS server&amp;rsquo;s certificate to bypass browser warnings.&lt;/p&gt;

&lt;p&gt;To enable it to generate trusted (by the browser based on the new root
CA key installed) certificates for any website the user connects to,
it needed to generate new certificated on-the-fly, so the private
signing key for the root CA needed to be stored on the user&amp;rsquo;s
device. This means that the private key for the certificate was
visible in the software and could be trivially extracted by the
end user. In addition, Komodia used the same private key for every
machine running Superfish. It didn&amp;rsquo;t take long for security researcher
&lt;a href=&#34;http://blog.erratasec.com/2015/02/extracting-superfish-certificate.html&#34;&gt;Robert
Grahm&lt;/a&gt;
to crack the password for the private key (hint: it was &amp;lsquo;komodia&amp;rsquo;). With
this key, an adversary could MITM any client running Superfish on
their laptop by using using a copy of this hardcoded certificate. To
compound this, users were not alerted to the presence of Superfish
software on their new Lenovo laptops.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.komodia.com/security-notice&#34;&gt;Komodia released a security notice&lt;/a&gt; saying they fixed the issue by updating the software to create &lt;strong&gt;unique&lt;/strong&gt; certificates per installation and &lt;strong&gt;randomly&lt;/strong&gt; generated passwords. They also addressed other potential vulnerabilities such as updating their list of supported cipher suites and verifying certificate revocation statuses (they support OCSP). The countermeasures outlined in their security notice serve as a starting point for all HTTPS interception software developers.&lt;/p&gt;

&lt;h4 id=&#34;privdog&#34;&gt;PrivDog&lt;/h4&gt;

&lt;p&gt;Shortly after the Superfish incident, another piece of TLS interception software named PrivDog made by Adtrustmedia was also &lt;a href=&#34;https://www.kb.cert.org/vuls/id/366544&#34;&gt;found to be vulnerable&lt;/a&gt;. PrivDog is an advertising program which intercepts HTTPS connections and replaces &amp;ldquo;bad&amp;rdquo; advertisements with advertisements approved by Adtrustmedia.&lt;/p&gt;

&lt;p&gt;Privdog, like the aforementioned Superfish, simply replaced certificates for a HTTPS server with new certificates signed by the root certificate they installed on the affected machine. However, the Privdog software performed no validation of the original certificate presented by the target server. Not only did it make untrusted certificates seem trusted, but legitimite websites with &lt;a href=&#34;https://en.wikipedia.org/wiki/Extended_Validation_Certificate&#34;&gt;EV Certificates&lt;/a&gt; were replaced with PrivDog&amp;rsquo;s self signed certificate removing the green browser indication. Any website an affected user visited with an invalid certificate would appear valid, without browser warnings. An adversary could easily MITM a client running PrivDog by simply advertising a self-signed certificate!&lt;/p&gt;

&lt;h3 id=&#34;the-security-impact-of-https-interception&#34;&gt;The Security Impact of HTTPS Interception&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://jhalderm.com/pub/papers/interception-ndss17.pdf&#34;&gt;&lt;em&gt;The Security Impact of HTTPS Interception&lt;/em&gt;&lt;/a&gt;. Zakir Durumeric, Zane Ma, Drew Springall, Richard Barnes, Nick Sullivan, Elie Bursztein, Michael Bailey, J. Alex Halderman, Vern Paxson. &lt;a href=&#34;http://www.internetsociety.org/events/ndss-symposium/ndss-symposium-2017&#34;&gt;Network and Distributed Systems Security Symposium&lt;/a&gt; (NDSS) 2017.&lt;/p&gt;

&lt;p&gt;In early 2017, researchers teamed up with Google, Mozilla and Cloudflare in efforts to measure TLS interception in an internet wide &lt;a href=&#34;https://zakird.com/papers/https_interception.pdf&#34;&gt;study&lt;/a&gt;. They noted that TLS interception software can be detected from the server&amp;rsquo;s point of view by identifying a mismatch between popular browsers TLS handshakes and the observed handshake. Going one step further, by observing the TLS handshakes of popular interception software they were able to construct fingerprints for some of the most widely used interception products.&lt;/p&gt;

&lt;p&gt;The study measured interception from the vantage point of the Cloudflare CDN, Firefox Update servers, and popular e-commerce sites. Important results from the study found that about 5-10% of measured HTTPS connections were intercepted, and much of the software reduced the security of the end user in one way or another, with 97%, 54%, and 32% of connections to Firefox, Cloudflare, and e-commerce sites becoming less secure respectively. Interestingly, the only middlebox software to earn a grade of ‘A’ was BlueCoat Proxy.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img width=&#34;85%&#34; alt=&#34;Grades for middlebox interception&#34; src=&#34;https://tlseminar.github.io/images/tls-interception/middlebox_interception.png&#34;&gt;&lt;br&gt;
&lt;span class=&#34;caption&#34;&gt;Source: &lt;a href=&#34;https://jhalderm.com/pub/papers/interception-ndss17.pdf&#34;&gt;&lt;em&gt;The Security Impact of HTTPS Interception&lt;/em&gt;&lt;/a&gt;&lt;/span&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;h4 id=&#34;chrome-56-update-breaks-bluecoat-proxy-v6-5&#34;&gt;Chrome 56 update breaks Bluecoat Proxy v6.5&lt;/h4&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Note these issues are always bugs in the middlebox products.&lt;/strong&gt; TLS version negotiation is backwards compatible, so a correctly-implemented TLS-terminating proxy should not require changes to work in a TLS-1.3-capable ecosystem [&amp;hellip;] That these products broke is an indication of defects in their TLS implementations&lt;br /&gt;
&amp;ndash; &lt;em&gt;&lt;a href=&#34;https://bugs.chromium.org/p/chromium/issues/detail?id=694593#c26&#34;&gt;David Benjamin&lt;/a&gt;, Chromium Bug Tracker (2017)&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;On 21 February 2017, shortly after the above paper was published, mishandling of TLS 1.3 connections by BlueCoat Proxy left thousands of clients without internet connection after an automatic Chrome 56 update. The problem wasn’t that BlueCoat Proxy didn’t implement TLS 1.3, but that it didn’t gracefully renegotiate down to TLS 1.2 which it does support. Instead, the software simply terminated the incoming connection. This left tens of thousands of Chromebooks used by Montgomery County Public Schools students temporarily unable to connect to the internet. The temporary solution was for individual users to alter Chrome&amp;rsquo;s internal settings to disable TLS 1.3 &lt;a href=&#34;chrome://flags/#ssl-version-max&#34;&gt;chrome://flags/#ssl-version-max&lt;/a&gt; until a more general solution was delivered by &lt;a href=&#34;https://bugs.chromium.org/p/chromium/issues/detail?id=694593#c12&#34;&gt;the following day&lt;/a&gt; by Chromium, which rolled-back TLS 1.3 support by default.&lt;/p&gt;

&lt;h2 id=&#34;going-forward&#34;&gt;Going Forward&lt;/h2&gt;

&lt;p&gt;Whether it be at the cost of availability or end user security, these incidents expose the fragility of TLS interception software. Google has reached out to middlebox vendors in efforts to help them resolve the issues, but system administrators should consider the risks of TLS interception seriously.  There are, however, situations where it is necessary such as when companies are legally required to monitor traffic of their employees to comply with regulations (such as in the financial industry).  Vendors should independently strive to fix their products for the security of their users at the same time. Organizations who deploy TLS interception software should choose products in an informed manner and carefully consider the risks imposed by interception software.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img alt=&#34;Grades for various clientside interception&#34; src=&#34;https://tlseminar.github.io/images/tls-interception/clientside_interception.png&#34; width=90%&gt;&lt;br&gt;
&lt;span class=&#34;caption&#34;&gt;Source: &lt;a href=&#34;https://zakird.com/papers/https_interception.pdf&#34;&gt;The Security Impact of HTTPS Interception (2017)&lt;/a&gt;&lt;/span&gt;
&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Survey and Revised Schedule</title>
      <link>https://tlseminar.github.io/update/</link>
      <pubDate>Wed, 08 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://tlseminar.github.io/update/</guid>
      <description>&lt;p&gt;I hope everyone is enjoying Spring Break!&lt;/p&gt;

&lt;p&gt;You can see the results of the survey here: &lt;a href=&#34;https://tlseminar.github.io/docs/mid-course-survey.pdf&#34;&gt;Mid-Course Survey
Results&lt;/a&gt; (I edited one response that
mentioned another student since that wasn&amp;rsquo;t intended to be public, but
otherwise it is everything that was submitted.)&lt;/p&gt;

&lt;p&gt;Based on the survey responses, and the depletion of Team Poppyseed, I
have made some adjustments to the teams and schedule.  Team Sesame,
Team Cinnamon, and Team Poppyseed have been turned into a Smoked
Salmon Shmear, and reformed as Team Pineapple (which is Team Sesame
and some additions from Poppyseed) and Team Mango.  Teams should
wrap-up their remaining blogging responsibilities as they were (that
is, Team Poppyseed is still responsible for completing the blog for
Class 7, which hopefully is well underway already).&lt;/p&gt;

&lt;table&gt;
&lt;tr bgcolor=&#34;#FFC&#34;&gt;&lt;td style=&#34;text-align:center&#34;&gt;&lt;b&gt;Team Pineapple&lt;/b&gt;&lt;/td&gt;&lt;td bgcolor=&#34;#CFF&#34; style=&#34;text-align:center&#34;&gt;&lt;b&gt;Team Mango&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
Adam Imeson (aei5uj)&lt;Br&gt;
Bethlehem Naylor (bn9eb)&lt;br&gt;
Bhuvanesh Murali (bm4cr)&lt;br&gt;
Collin Berman (cmb5nh)&lt;br&gt;
Daniel Saha (drs5ma)&lt;br&gt;
Haina Li (hl3wb)&lt;br&gt;
Joshua Holtzman (jmh2ba)&lt;br&gt;
Reid Bixler (rmb3yz)&lt;br&gt;
Tianyi Jin (tj2cw)&lt;br&gt;
&lt;/td&gt;
&lt;td&gt;
Anant Kharkar (agk7uc)&lt;br&gt;
Bargav Jayaraman (bj4nq)&lt;br&gt;
Benjamin Lowman (brl2xx)&lt;br&gt;
Bill Young (wty5dn)&lt;br&gt;
Cyrus Malekpour (cm7bv)&lt;br&gt;
Darion Cassel (dfc9ed)&lt;br&gt;
Sam Havron (sgh7cc)&lt;br&gt;
Yuchi Tian (yt8mn)&lt;br&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;I don&amp;rsquo;t want to increase the presentation and blogging workload for
the rest of the semester, though, especially since I want to ensure
everyone has time to work on your project.  So, each team will still
be leading every third week, and blogging every third week, and we
will do something else in the other classes.&lt;/p&gt;

&lt;p&gt;Team Mango is scheduled to lead the next class on March 17 (this is
what was assigned to Team Cinnamon, so not a new responsibility for
most of the team, and the new recruits from Team Poppyseed should have
limited roles expected for this first presentation since they just
joined the reformulated team).  Team Pineapple is responsible for
Blogging and Food for the class.  Note that according to the survey
results, 73.4% of the class is sick of bagels.  So, Team Pineapple is
challenged to come up with something more interesting for breakfast.&lt;/p&gt;

&lt;p&gt;The full revised schedule is below.  Note that the team that is not
leading the class is responsible for both Blogging and Food.&lt;/p&gt;

&lt;table&gt;
&lt;tr bgcolor=&#34;#CCC&#34;&gt;&lt;td width=&#34;22%&#34; style=&#34;text-align:center&#34;&gt;&lt;b&gt;Date&lt;/b&gt;&lt;/td&gt;&lt;td style=&#34;text-align:center&#34;&gt;&lt;b&gt;Topic&lt;/b&gt;&lt;/td&gt;&lt;td style=&#34;text-align:center&#34; width=20%&gt;&lt;b&gt;Team Mango&lt;/b&gt;&lt;/td&gt;&lt;td style=&#34;text-align:center&#34; width=20%&gt;&lt;b&gt;Team Pineapple&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td&gt;Class 8 (17 Mar)&lt;/td&gt;&lt;td&gt;TBD&lt;/td&gt;&lt;td bgcolor=&#34;#CCDD55&#34;&gt;Lead&lt;/td&gt;&lt;td bgcolor=&#34;#44AAEE&#34;&gt;Blog, Food&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Class 9 (24 Mar)&lt;/td&gt;&lt;td&gt;TBD&lt;/td&gt;&lt;td bgcolor=&#34;#44AAEE&#34;&gt;Blog, Food&lt;/td&gt;&lt;td bgcolor=&#34;#CCDD55&#34;&gt;Lead&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Class 10 (31 Mar)&lt;/td&gt;&lt;td&gt;TBD&lt;/td&gt;&lt;td colspan=2 bgcolor=&#34;#888888&#34;&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Class 11 (7 Apr)&lt;/td&gt;&lt;td&gt;TBD&lt;/td&gt;&lt;td bgcolor=&#34;#CCDD55&#34;&gt;Lead&lt;/td&gt;&lt;td bgcolor=&#34;#44AAEE&#34;&gt;Blog, Food&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Class 12 (14 Apr)&lt;/td&gt;&lt;td&gt;TBD&lt;/td&gt;&lt;td bgcolor=&#34;#44AAEE&#34;&gt;Blog, Food&lt;/td&gt;&lt;td bgcolor=&#34;#CCDD55&#34;&gt;Lead&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Class 13 (21 Apr)&lt;/td&gt;&lt;td&gt;TBD&lt;/td&gt;&lt;td bgcolor=&#34;#888888&#34; colspan=2&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Class 14 (28 Apr)&lt;/td&gt;&lt;td&gt;Mini-Conference&lt;/td&gt;&lt;td bgcolor=&#34;#888888&#34; colspan=2&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;
</description>
    </item>
    
    <item>
      <title>Timing Attacks</title>
      <link>https://tlseminar.github.io/timing-attacks/</link>
      <pubDate>Wed, 01 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://tlseminar.github.io/timing-attacks/</guid>
      <description>

&lt;h1 id=&#34;digression-notable-news&#34;&gt;Digression: Notable News&lt;/h1&gt;

&lt;p&gt;Two newsworthy events occurred this week that are of high importance
and relevant to TLS in general: &lt;a href=&#34;https://tlseminar.github.io/sha1-collisions&#34;&gt;SHA-1 Collisions&lt;/a&gt;
and the &lt;a href=&#34;https://tlseminar.github.io/cloudflare-leak&#34;&gt;Cloudflare Leak&lt;/a&gt;.  (Those are discussed in
the separate linked posts.)&lt;/p&gt;

&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;Timing attacks exploitd information leaked from timing side-channels to learn private data. In this threat model, an attacker is able to observe the time required for certain parts of a program at runtime and gain information about the execution path followed.&lt;/p&gt;

&lt;p&gt;Consider the following snippet of Python code as an example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def comp(a, b):
    if len(a) != len(b):
        return False
    for c1, c2 in zip (a, b):
        if c1 != c2:
            return False
    return True
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;comp()&lt;/code&gt; function performs string comparison, returning &lt;code&gt;True&lt;/code&gt; if the strings are character-wise equal and &lt;code&gt;False&lt;/code&gt; otherwise. Let us assume for the sake of simplicity that the lengths of the strings are public (we are not concerned with timing leaks from the initial length comparison).&lt;/p&gt;

&lt;p&gt;Suppose we compare the strings &lt;code&gt;&amp;quot;hello&amp;quot;&lt;/code&gt; and &lt;code&gt;&amp;quot;catch&amp;quot;&lt;/code&gt;. These words fail the string comparison immediately, since the first letters are different. Thus, the function returns &lt;code&gt;False&lt;/code&gt; after a single iteration of the loop. In contrast, comparing &lt;code&gt;&amp;quot;hello&amp;quot;&lt;/code&gt; with &lt;code&gt;&amp;quot;hella&amp;quot;&lt;/code&gt; will require 5 iterations before returning False. An attacker can use the resulting timing delay to determine that &lt;code&gt;&amp;quot;hello&amp;quot;&lt;/code&gt; and &lt;code&gt;&amp;quot;hella&amp;quot;&lt;/code&gt; share beginning characters, whereas &lt;code&gt;&amp;quot;hello&amp;quot;&lt;/code&gt; and &lt;code&gt;&amp;quot;catch&amp;quot;&lt;/code&gt; do not. If &lt;code&gt;&amp;quot;hello&amp;quot;&lt;/code&gt; was a password, an attacker who could measure the timing precisely enough to count loop iterations would be able to incrementally guess each letter of the string.&lt;/p&gt;

&lt;p&gt;One solution to this problem would be to use a Boolean flag initialized to &lt;code&gt;True&lt;/code&gt;. If the words have mismatched characters, the flag will be set to &lt;code&gt;False&lt;/code&gt;, and the flag will be returned after comparing all characters. In theory, this masks the timing leak; in practice, a compiler may optimize such code to return early, reinstating the timing leak. Furthermore, there may still be timing leaks in the execution of the code, such as variation in the instruction cache depending on which statements are entered.&lt;/p&gt;

&lt;p&gt;Thus, we see from this simple example that verifying constant-time implementation of code has many challenges, which we further discuss below.&lt;/p&gt;

&lt;h1 id=&#34;remote-timing-attacks-are-practical&#34;&gt;Remote Timing Attacks are Practical&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://tlseminar.github.io/docs/ssl-timing.pdf&#34;&gt;Remote timing attacks are practical&lt;/a&gt;. David Brumley and Dan Boneh (2005).Computer Networks, 48(5), 701-716.]&lt;/p&gt;

&lt;p&gt;At the heart of RSA decription is a modular exponentiation \( m = c^d mod~N\) where \(N = pq\) is the RSA modulus, d is the private decryption exponent, and c is the ciphertext being decrypted. OpenSSL uses the Chinese Remainder Theorem (CRT) to perform this exponentiation. With Chinese remaindering, the function \( m = c^d mod~N\) is computed in two steps:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Evaluate \( m_1 = c^{d_1} mod~p\) and \( m_2 = c^{d_2} mod~q\) (\(d_1\) and \(d_2\) are precomputed from \(d\)).&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Combine \(m_1\) and \(m_2\) using CRT to yield m.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Both steps could have timing side channels if not implemented carefully.&lt;/p&gt;

&lt;h3 id=&#34;chinese-remainder-theorem&#34;&gt;Chinese Remainder Theorem&lt;/h3&gt;

&lt;p&gt;Suppose that \(n_1,n_2,&amp;hellip;,n_r\) are pairwise relatively prime positive integers, and let \(c_1,c_2,&amp;hellip;,c_r\) be integers.&lt;/p&gt;

&lt;p&gt;Then the system of congruences,&lt;/p&gt;

&lt;p&gt;&lt;div class=&#34;indented&#34;&gt;
\(X \equiv c_1 (mod~n_1)\)&lt;br /&gt;
\(X \equiv c_2 (mod~n_2)\)&lt;br /&gt;
&amp;hellip;&lt;br /&gt;
\(X \equiv c_r (mod~n_r)\)
   &lt;/div&gt;&lt;/p&gt;

&lt;p&gt;has a unique solution modulo \(N = n_1n_2&amp;hellip;n_r\)&lt;/p&gt;

&lt;h3 id=&#34;gauss-s-algorithm&#34;&gt;Gauss’s Algorithm&lt;/h3&gt;

&lt;p&gt;\(X \equiv c_1N_1{N_1}^{-1} + c_2N_2{N_2}^{-1} + &amp;hellip; + c_rN_r{N_r}^{-1}(mod~N)\), where
   &lt;div class=&#34;indented&#34;&gt;
\(N_i = N/n_i \)&lt;br /&gt;
\(N_i{N_1}^{-1} \equiv 1 (mod~n_i)\)
   &lt;/div&gt;&lt;/p&gt;

&lt;h3 id=&#34;hasted-s-broadcast-attack&#34;&gt;Hasted’s Broadcast Attack&lt;/h3&gt;

&lt;p&gt;Hasted&amp;rsquo;s Broadcast Attack relies on cases when the public exponent \(e\) is small or when partial knowledge of the
secret key is available.
If \(e\) (public) is the same across different sites, the attacker can use Chinese Remainder Theorem and decrypt messages!&lt;/p&gt;

&lt;p&gt;Hasted’s Broadcast Attack works as follows:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Alice encrypts the same message \(M\) with three different public keys \(n_1\) \(n_2\) and \(n_3\)
, all with public exponent \(e=3\), The resulting \(C_1C_2\) and \(C_3\) are known.
&lt;div class=&#34;indented&#34;&gt;
\(M^3 \equiv C_1 (mod~n_1)\)&lt;br /&gt;
\(M^3 \equiv C_2 (mod~n_2)\)&lt;br /&gt;
\(M^3 \equiv C_3 (mod~n_3)\)
&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;An attack can then recover \(M\):
&lt;div class=&#34;indented&#34;&gt;
\(x = C_1N_1N_1^{-1} + C_2N_2N_2^{-1} + C_3N_3N_3^{-1}~mod~n_1n_2n_3 \)&lt;br /&gt;
\(M = \sqrt[3]{x}\)
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;montgomery-reduction&#34;&gt;Montgomery Reduction&lt;/h3&gt;

&lt;p&gt;Montgomery Reduction is an algorithm  that allows modular arithmetic to be performed
efficiently when the modulus is large.&lt;/p&gt;

&lt;p&gt;The reduction takes advantage of the fact that \(x~mod~2^n\)
is easier to compute than \(x~mod~q\); the reduction simply strips off all but the \(n\) least significant bytes.&lt;/p&gt;

&lt;p&gt;Steps needed for the reduction:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The Montgomery Form of \(a\) is \(aR~mod~q\), where \(R\) is some public \(2n , n\) chosen based on underlying hardware.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Multiplication of \(ab\) in Montgomery Form: \(aRbR = cR2\).&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Pre-compute \(RR^{-1}~mod~q\).&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Reduce: \(cR^{2}R^{-1}~mod~q = cR~mod~q\).&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;\(c\) can be kept in form and reused for additional multiplications during sliding windows.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;To escape Montgomery space and return to \(q\) space: multiply again by \(R^{-1}\) to arrive at solution \(c\).&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;\(c = ab~mod~q\) (performing \(mod\) by \(q\) causes successive subtractions of \(ab\) by \(q\) till result \(c\) in range \([0,q)\).  The number of &amp;ldquo;extra reductions&amp;rdquo; depends on the private data; the attack exploits these as a timing side channel.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;https://tlseminar.github.io/images/timing-attacks/gap.jpg&#34; alt=&#34;PDF Collision&#34; style=&#34;width:500px;&#34;/&gt;&lt;br&gt;
&lt;span class=&#34;caption&#34;&gt;(&lt;a href=&#34;http://slideplayer.com/slide/4519452/&#34;&gt;Image credit&lt;/a&gt;)&lt;/span&gt;&lt;/center&gt;&lt;/p&gt;

&lt;h3 id=&#34;protections-against-timing-attacks&#34;&gt;Protections against timing attacks&lt;/h3&gt;

&lt;p&gt;There are numerous defenses against timing attacks, but known defenses are either expensive or only provide partial mitigation.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Use a decryption routine with the number of operations is independent of input.  For example, simply carry out the maximum number of Montgomery extra reductions, even if they are not necessary. This might be hard to mend to existing systems without replacing their entire decryption algorithm (and it is important to be wary of &amp;ldquo;overly-optimizing&amp;rdquo; compilers that remove non-functional code that is there to mask a timing leak).&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;By quantizing all RSA computations. This decreases performance because &amp;ldquo;all decryptions must take the maximum time of any decryption&amp;rdquo;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;By blinding, which works as follows:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Calculate \(x = reg~mod~N\) before actual decryption for random \(r\) chosen each time&lt;/li&gt;
&lt;li&gt;Decrypt as normal.&lt;/li&gt;
&lt;li&gt;Unblind: divide by \(r~mod~N\) to obtain the decryption of the ciphertext
\(g\).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Since \(r\) is random, \(x\) is also random &amp;ndash; and input \(g\) should have minimal
correlation with total decryption time.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;remote-timing-attacks-are-still-practical&#34;&gt;Remote Timing Attacks are Still Practical&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://gnunet.org/sites/default/files/Brumley%20%26%20Tuveri%20-%20Timing%20Attacks.pdf&#34;&gt;Billy Bob Brumley and Nicola Tuveri. &amp;ldquo;Remote timing attacks are still practical.&amp;rdquo; European Symposium on Research in Computer Security. Springer Berlin Heidelberg, 2011.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Timing attacks target cryptosystems and protocols that do not run in constant time. &lt;a href=&#34;https://en.wikipedia.org/wiki/Elliptic_curve_cryptography&#34;&gt;Elliptic curve&lt;/a&gt; based &lt;a href=&#34;https://en.wikipedia.org/wiki/Elliptic_Curve_Digital_Signature_Algorithm&#34;&gt;signature schemes&lt;/a&gt; aim at providing side-channel resistance against timing attacks. For instance, scalar multiplication is achieved via &lt;a href=&#34;https://cr.yp.to/bib/2003/joye-ladder.pdf&#34;&gt;Montgomery&amp;rsquo;s ladder&lt;/a&gt; which performs a sequence of independent field operations on elliptic curves. &lt;a href=&#34;https://gnunet.org/sites/default/files/Brumley%20%26%20Tuveri%20-%20Timing%20Attacks.pdf&#34;&gt;Brumley and Tuveri&lt;/a&gt; reveal a timing attack vulnerability in OpenSSL&amp;rsquo;s implementation of Montgomery&amp;rsquo;s ladder that consequently leaks the server&amp;rsquo;s private key.&lt;/p&gt;

&lt;h3 id=&#34;what-is-montgomery-s-ladder&#34;&gt;What is Montgomery&amp;rsquo;s Ladder?&lt;/h3&gt;

&lt;p&gt;Consider the right-to-left square-and-multiply algorithm to compute an exponentiation operation:
&lt;center&gt;&lt;img src=&#34;https://tlseminar.github.io/images/timing-attacks/right-to-left.png&#34; alt=&#34;Montgomery ladder&#34; style=&#34;width:300px;&#34;/&gt;&lt;br&gt;
&lt;sup&gt;Right-to-Left Square-and-Multiply Algorithm&lt;/sup&gt;&lt;br&gt;&lt;sup&gt;Source: &lt;a href=&#34;https://cr.yp.to/bib/2003/joye-ladder.pdf&#34;&gt;https://cr.yp.to/bib/2003/joye-ladder.pdf&lt;/a&gt;&lt;/sup&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;The above algorithm performs more operations when the bit is set, thereby leading to a possible timing attack. Montgomery&amp;rsquo;s power ladder method, on the other hand, performs the same number of operations in both the cases. This prevents timing based side-channel attacks as well as makes the algorithm more efficient by making it parallelizable. The algorithm is as below:
&lt;center&gt;&lt;img src=&#34;https://tlseminar.github.io/images/timing-attacks/montgomery.png&#34; alt=&#34;Montgomery ladder&#34; style=&#34;width:300px;&#34;/&gt;&lt;br&gt;
&lt;sup&gt;Montgomery&amp;rsquo;s Ladder&lt;/sup&gt;&lt;br&gt;&lt;sup&gt;Source: &lt;a href=&#34;https://cr.yp.to/bib/2003/joye-ladder.pdf&#34;&gt;https://cr.yp.to/bib/2003/joye-ladder.pdf&lt;/a&gt;&lt;/sup&gt;&lt;/center&gt;&lt;/p&gt;

&lt;h3 id=&#34;openssl-s-implementation-of-montgomery-s-ladder&#34;&gt;OpenSSL&amp;rsquo;s implementation of Montgomery&amp;rsquo;s Ladder&lt;/h3&gt;

&lt;p&gt;OpenSSL uses Elliptic Curve Cryptography for generating Digital Signatures to sign a TLS server&amp;rsquo;s RSA key.
Elliptic Curve Cryptography for Digital Signature uses the following curve for binary fields:
&lt;center&gt;&lt;img src=&#34;https://tlseminar.github.io/images/timing-attacks/curve.png&#34; alt=&#34;ECC&#34; style=&#34;width:400px;&#34;/&gt;&lt;/center&gt;
NIST recommends two standard curves: 1. Set \(a_2 = 1\) and choose \(a_6\) pseudo-randomly, or 2. Choose \(a_2\) from \({0,1}\) and set \(a_6 = 1\).
Either of the two curves can be used for digital signatures.&lt;/p&gt;

&lt;p&gt;Parties select private key as \(0 &amp;lt; d &amp;lt; n\) and public key as \([d]G\) and then proceed to generate digital signatures using elliptic curves as:
&lt;center&gt;&lt;img src=&#34;https://tlseminar.github.io/images/timing-attacks/digital_signatures.png&#34; alt=&#34;digital&#34; style=&#34;width:300px;&#34;/&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;OpenSSL uses Montogmery&amp;rsquo;s ladder to compute the above digital signatures since it requires multiple exponentiation operations. However, OpenSSL&amp;rsquo;s implementation has a flaw that leads to timing attack. Below is OpenSSL&amp;rsquo;s implementation:&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;https://tlseminar.github.io/images/timing-attacks/OpenSSL_montgomery.png&#34; alt=&#34;OpenSSL&#34; style=&#34;width:700px;&#34;/&gt;&lt;br&gt;
&lt;sup&gt;OpenSSL&amp;rsquo;s implementation of Montgomery&amp;rsquo;s Ladder&lt;/sup&gt;&lt;br&gt;
&lt;sup&gt;Source: &lt;a href=&#34;https://gnunet.org/sites/default/files/Brumley%20%26%20Tuveri%20-%20Timing%20Attacks.pdf&#34;&gt;https://gnunet.org/sites/default/files/Brumley%20%26%20Tuveri%20-%20Timing%20Attacks.pdf&lt;/a&gt;&lt;/sup&gt;&lt;/center&gt;
As indicated in the third line of code, OpenSSL optimizes the number of ladder steps and therefore leaks information about the MSB of k. Since the time taken to compute the scalar multiplications is proportional to the logarithm of k, which is revealed by the MSB of k, this leads to a timing attack. The attacker collects multiple digital signatures such that the signatures are generated by random nonce k with leading zero bits; this information is revealed by the above timing attack. The attacker then launches a &lt;a href=&#34;http://www.hpl.hp.com/techreports/1999/HPL-1999-90.pdf&#34;&gt;lattice attack&lt;/a&gt; using the collected digital signatures to reveal the RSA key of the TLS server.&lt;/p&gt;

&lt;h3 id=&#34;countermeasure&#34;&gt;Countermeasure&lt;/h3&gt;

&lt;p&gt;A possible countermeasure as proposed by &lt;a href=&#34;https://gnunet.org/sites/default/files/Brumley%20%26%20Tuveri%20-%20Timing%20Attacks.pdf&#34;&gt;Brumley and Tuveri&lt;/a&gt; is to pad the scalar \(k\):
&lt;center&gt;&lt;img src=&#34;https://tlseminar.github.io/images/timing-attacks/countermeasure.png&#34; alt=&#34;counter&#34; style=&#34;width:400px;&#34;/&gt;&lt;br&gt;
&lt;sup&gt;Countermeasure to OpenSSL&amp;rsquo;s flaw&lt;/sup&gt;&lt;br&gt;
&lt;sup&gt;Source: &lt;a href=&#34;https://gnunet.org/sites/default/files/Brumley%20%26%20Tuveri%20-%20Timing%20Attacks.pdf&#34;&gt;https://gnunet.org/sites/default/files/Brumley%20%26%20Tuveri%20-%20Timing%20Attacks.pdf&lt;/a&gt;&lt;/sup&gt;&lt;/center&gt;
This ensures that the logarithm is constant and hence leaks no side-channel information. Moreover, the above modification does not cause extra computation overhead.&lt;/p&gt;

&lt;h3 id=&#34;sources&#34;&gt;Sources&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://cr.yp.to/bib/2003/joye-ladder.pdf&#34;&gt;Marc Joye and Sung-Ming Yen. &amp;ldquo;The Montgomery powering ladder.&amp;rdquo; International Workshop on Cryptographic Hardware and Embedded Systems. Springer Berlin Heidelberg, 2002.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gnunet.org/sites/default/files/Brumley%20%26%20Tuveri%20-%20Timing%20Attacks.pdf&#34;&gt;Billy Bob Brumley and Nicola Tuveri. &amp;ldquo;Remote timing attacks are still practical.&amp;rdquo; European Symposium on Research in Computer Security. Springer Berlin Heidelberg, 2011.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.hpl.hp.com/techreports/1999/HPL-1999-90.pdf&#34;&gt;Howgrave-Graham, Nick A., and Nigel P. Smart. &amp;ldquo;Lattice attacks on digital signature schemes.&amp;rdquo; Designs, Codes and Cryptography 23.3 (2001): 283-290.&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;cache-timing-attacks&#34;&gt;Cache Timing Attacks&lt;/h1&gt;

&lt;p&gt;At this point, it seems as though we&amp;rsquo;ve seen everything—there couldn&amp;rsquo;t possibly be another side-channel attack, right?&lt;/p&gt;

&lt;p&gt;Wrong.&lt;/p&gt;

&lt;p&gt;Timing attacks are capable of leveraging the &lt;strong&gt;CPU cache&lt;/strong&gt; as a side-channel in order to perform attacks.  Since the issue results from hardware design, it&amp;rsquo;s difficult for application designers to address; the behaviors that influence cache patterns are proprietary features hidden away into today&amp;rsquo;s processors.&lt;/p&gt;

&lt;h3 id=&#34;intel-cpu-cache&#34;&gt;Intel CPU Cache&lt;/h3&gt;

&lt;p&gt;In cache terminology, &lt;strong&gt;hits&lt;/strong&gt; occur when queried data is present in the cache and &lt;strong&gt;misses&lt;/strong&gt; occur when data must be fetched from main memory.  Consider the L1 and L2 caches of the Intel Sandy Bridge processor.  Both are &lt;strong&gt;8-way set associative caches&lt;/strong&gt; consisting of sets with 64-byte lines (64 sets in L1, 512 sets in L2, for a total of 32KB and 256KB in storage, respectively).&lt;/p&gt;

&lt;p&gt;For those unfamiliar with computer architecture, addresses of information in the cache are split into three components:  tag, set, and offset.  An address looks something like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1111 0000 1111 0000 1111        000011       110000
Tag                              Set         Offset
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now that we&amp;rsquo;ve reviewed the memory hierarchy, let&amp;rsquo;s take a look at some attacks that use variations in cache timing and operation to their advantage.&lt;/p&gt;

&lt;h3 id=&#34;prime-probe&#34;&gt;PRIME+PROBE&lt;/h3&gt;

&lt;p&gt;The PRIME+PROBE attack is carried out by &lt;strong&gt;filling the victim&amp;rsquo;s cache with controlled data&lt;/strong&gt;.  As the victim carries out normal tasks in their machine, some of the attack data is evicted from the cache.  All the while, the attacker monitors the cache contents, keeping careful track of which cache lines were evicted.  In doing so, this provides the attacker with intimate knowledge of the operation and nature of the victim&amp;rsquo;s activities as well as the contents replaced by the victim.&lt;/p&gt;

&lt;h3 id=&#34;evict-time&#34;&gt;EVICT+TIME&lt;/h3&gt;

&lt;p&gt;The EVICT+TIME attack is carried out by evicting a line of an AES lookup table from the cache such that all AES lookup tables are in the cache save for one.  The attacker then runs the encryption process.  As you might imagine, &lt;strong&gt;if the encryption process accesses the partially evicted lookup table, encryption will take longer to complete&lt;/strong&gt;.  By timing exactly how long encryption takes, the attackers are able to determine which indices of which tables were accessed.  Because table lookups depend on the AES encryption key, the attacker thus gains knowledge about the key.&lt;/p&gt;

&lt;h3 id=&#34;cache-games&#34;&gt;Cache Games&lt;/h3&gt;

&lt;p&gt;The Cache Games attack targets AES-128 in OpenSSL v0.9.8 and is capable of recovering the full secret key.  In the attack, a non-privileged spy process conducts a 2.8 second observation of approximately 100 AES encryptions (1.56KB of data) and then performs 3 minutes of computation on a separate machine.  The spy process is able to abuse the default Linux scheduler, unfortunately named the &lt;em&gt;Completely Fair Scheduler&lt;/em&gt;, to monitor cache offset accesses with extremely accurate precision, thus gaining information about the key.&lt;/p&gt;

&lt;p&gt;In order to abuse the CFS, the spy process creates hundreds of threads that immediately block.  After a few cycles, the first thread awakens, checks for memory accesses by the target code, and then signals for the next thread to awaken.  This continues for all threads.  To filter-out noise, Cache Games uses an ANN that takes bitmaps of activations and outputs points with high probability of access.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;https://tlseminar.github.io/images/timing-attacks/cachegames.png&#34; alt=&#34;Cache Games ANN&#34; style=&#34;width:300px;&#34;/&gt;&lt;br /&gt;&lt;sup&gt;An ANN takes bitmaps of activations and outputs &lt;br /&gt;points with high probability of access&lt;/sup&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;The nature of the AES encryption process—consisting of 10 rounds of 16 memory accesses—allows the spy process to construct a list of partial-key candidates that is continually refined as more encryptions are repeated.  The CFS maintains processes in a red-black tree and associates with each process a total runtime.  The scheduler calculates a &amp;ldquo;max execution time&amp;rdquo; for each process by dividing the total time it has been waiting by the number of processes in the tree.  Whichever process minimizes this value is selected to run next.&lt;/p&gt;

&lt;h4 id=&#34;mitigation&#34;&gt;Mitigation&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Remove or restrict access to high-resolution timers such as &lt;code&gt;rdtsc&lt;/code&gt; (unlikely; necessary to benchmark various hardware properties)&lt;/li&gt;
&lt;li&gt;Allow certain memory to be marked as &lt;em&gt;uncacheable&lt;/em&gt; (hardware challenge!)&lt;/li&gt;
&lt;li&gt;Use AES-NI instructions in Intel chips to compute AES (but what about other encryption algorithms?)&lt;/li&gt;
&lt;li&gt;Scatter-gather:  secret data should not be allowed to influence memory access at coarser-than-cache-line granularity.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;cachebleed&#34;&gt;CacheBleed&lt;/h3&gt;

&lt;p&gt;TODO: add paper link&lt;/p&gt;

&lt;p&gt;In keeping with the trend of affixing &amp;ldquo;-bleed&amp;rdquo; to various information security leakage vulnerabilities, CacheBleed is a recent (c. 2016) attack on RSA decryptions as implemented in OpenSSL v1.0.2 on Intel Sandy Bridge processors.  In the attack, the timing of operations in &lt;strong&gt;cache banks&lt;/strong&gt; is taken advantage of in order to glean information about the RSA decryption multiplier.&lt;/p&gt;

&lt;p&gt;Cache banks were a new feature in Sandy Bridge processors, designed to accommodate accessing multiple instructions in the same cache line in the same cycle.  As it turns out, cache banks can only serve one operation at a time, so if a &lt;em&gt;cache bank conflict&lt;/em&gt; is encountered, one request will be delayed!&lt;/p&gt;

&lt;p&gt;In order to carry-out the attack, the attacker and victim start out running on the same hyperthreaded core, thus sharing the L1 cache.  The attacker then issues a huge number of requests to a single cache bank.  By carefully measuring how many cycles passed in completion of the request, the attacker can discern whether the victim accessed that cache bank at some point.  After many queries, the attack is successful at extracting both 2048-bit and 4096-bit secret keys.&lt;/p&gt;

&lt;h4 id=&#34;mitigation-1&#34;&gt;Mitigation&lt;/h4&gt;

&lt;p&gt;The upside to CacheBleed is that it&amp;rsquo;s highly complicated, requiring shared access to a hyperthreaded core on which RSA decryption is taking place—certainly not a predictable scenario.  In any case, there are other pieces of &amp;ldquo;low-hanging fruit&amp;rdquo; in computer systems that attackers are more likely to target.  Nonetheless, Haswell processors implement cache banks differently such that conflicts are handled more carefully.  The only other mitigation technique is to disable hyperthreading entirely.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Cloudflare Leak</title>
      <link>https://tlseminar.github.io/cloudflare-leak/</link>
      <pubDate>Tue, 28 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://tlseminar.github.io/cloudflare-leak/</guid>
      <description>

&lt;h1 id=&#34;the-cloudflare-leak&#34;&gt;The Cloudflare Leak&lt;/h1&gt;

&lt;h3 id=&#34;how-the-incident-developed&#34;&gt;How the Incident Developed&lt;/h3&gt;

&lt;p&gt;Cloudflare is an Internet infrastructure company that provides security and performance services to millions of websites.  On February 17th, 2017, Travis Ormandy, a security researcher from &lt;a href=&#34;https://googleprojectzero.blogspot.com/&#34;&gt;Google&amp;rsquo;s Project Zero&lt;/a&gt;, noticed that some HTTP requests running through Cloudflare were returning corrupted web pages.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;https://tlseminar.github.io/images/timing-attacks/cloudflare/tweet.png&#34; alt=&#34;Travis Ormandy&#39;s Tweet&#34; style=&#34;width:500px;&#34;/&gt;&lt;br&gt;
&lt;sup&gt;&lt;a href=&#34;https://twitter.com/taviso/status/832744397800214528&#34;&gt;https://twitter.com/taviso/status/832744397800214528&lt;/a&gt;&lt;/sup&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;The problem that Travis noticed was that under certain circumstances, when the Cloudflare &amp;ldquo;edge servers&amp;rdquo; returned a web page, they were going past the end of a buffer and adding to the HTML dumps of memory that contained information such as auth tokens, HTTP POST bodies, HTTP cookies, and other private information &lt;a href=&#34;https://blog.cloudflare.com/incident-report-on-memory-leak-caused-by-cloudflare-parser-bug/&#34;&gt;[1]&lt;/a&gt;. To make matters worse, search engines both indexed and cached this data such that it was for a while searchable.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;https://tlseminar.github.io/images/timing-attacks/cloudflare/leak.png&#34; alt=&#34;Example Leaked Data&#34; style=&#34;width:500px;&#34;/&gt;&lt;br&gt;
&lt;sup&gt;&lt;a href=&#34;http://pastebin.com/AKEFci31&#34;&gt;http://pastebin.com/AKEFci31&lt;/a&gt;&lt;/sup&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;Since the discovery of the bug, Cloudflare worked with Google and other search engines to remove affected the cached pages.&lt;/p&gt;

&lt;h3 id=&#34;the-impact&#34;&gt;The Impact&lt;/h3&gt;

&lt;p&gt;Data could have been leaking &lt;a href=&#34;https://www.wired.com/2017/02/crazy-cloudflare-bug-jeopardized-millions-sites/&#34;&gt;as early as September 22nd&lt;/a&gt;, but Cloudflare reported that the period of highest impact was from February 13th through February 18th with around 1 in every 3,300,000 HTTP requests have a potential memory leakage &lt;a href=&#34;https://blog.cloudflare.com/incident-report-on-memory-leak-caused-by-cloudflare-parser-bug/&#34;&gt;[1]&lt;/a&gt;. It is difficult to assess how much data was leaked, especially since the corrupted results and their cached versions were quickly removed from search engines, but Wired &lt;a href=&#34;https://www.wired.com/2017/02/crazy-cloudflare-bug-jeopardized-millions-sites/&#34;&gt;reported that data from large companies such as Fitbit, Uber, and OKCupid was found in the corrupted pages of a set of affected web pages&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Cloudflare asserts that the leak did not reveal any private keys, and even though other sensitive information was leaked, it did not appear in the HTML content of particularly high-traffic sites, so the damage was mitigated.&lt;/p&gt;

&lt;p&gt;Overall, about 3000 customer&amp;rsquo;s sites triggered the bug, but, as previously noted, the data leaked could have come from any other Cloudflare customer. Cloudflare is aware of about 150 customers who were affected in that way.&lt;/p&gt;

&lt;h3 id=&#34;the-bug-itself&#34;&gt;The Bug Itself&lt;/h3&gt;

&lt;p&gt;As mentioned earlier, the problem resulted from a buffer being overrun and thus additional data from memory being written to the HTML of web pages. But how did this happen, and why did it happen now?&lt;/p&gt;

&lt;p&gt;Some of Cloudflare&amp;rsquo;s services rely on modifying, or &amp;ldquo;rewriting,&amp;rdquo; HTML pages as they are routed through the edge servers. In order to do this rewriting, Cloudflare reads and parses the HTML to find elements that require changing. Cloudflare used to use a HTML parser written using a project called &lt;a href=&#34;https://www.colm.net/open-source/ragel/&#34;&gt;Ragel&lt;/a&gt; that converts a description of a regular language into a finite state machine. However, about a year ago they decided that the Ragel-based parser was a source of technical debt and wrote a new parser called cf-html to replace it &lt;a href=&#34;https://blog.cloudflare.com/incident-report-on-memory-leak-caused-by-cloudflare-parser-bug/&#34;&gt;[1]&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Cloudflare first rolled this new parser our for their &lt;a href=&#34;https://blog.cloudflare.com/how-we-brought-https-everywhere-to-the-cloud-part-1/&#34;&gt;Automatic HTTP Rewrites&lt;/a&gt; service and have since been slowly migrating other services away from the Ragel-based parser. In order to use these parsers, Cloudflare adds them as a module to &lt;a href=&#34;https://www.nginx.com/resources/wiki/&#34;&gt;NGINX&lt;/a&gt;, a load-balancer &lt;a href=&#34;https://blog.cloudflare.com/incident-report-on-memory-leak-caused-by-cloudflare-parser-bug/&#34;&gt;[1]&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;As it turned out, the parser that was written with Ragel actually had a bug in it for several years, but there was no memory leak because of a certain configuration fo the internal NGINX buffers. When cf-html was adopted, the buffers slightly changed, enabling the leakage.&lt;/p&gt;

&lt;p&gt;The actual bug was caused by what you might expect: a pointer error in the C code generated by Ragel (but the bug was not the fault of Ragel).&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;https://tlseminar.github.io/images/timing-attacks/cloudflare/bug.png&#34; alt=&#34;C Code Bug&#34; style=&#34;width:500px;&#34;/&gt;&lt;br&gt;
&lt;sup&gt;&lt;a href=&#34;https://blog.cloudflare.com/incident-report-on-memory-leak-caused-by-cloudflare-parser-bug/&#34;&gt;https://blog.cloudflare.com/incident-report-on-memory-leak-caused-by-cloudflare-parser-bug/&lt;/a&gt;&lt;/sup&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;As can be guessed from this snippit, the cause of the bug was that the check for the end of the bugger was done using the equality operator, &lt;code&gt;==&lt;/code&gt;, instead of &lt;code&gt;&amp;gt;=&lt;/code&gt;, which would have caught the bug. That snippit is the generated code. Let&amp;rsquo;s look at the code that generated that.&lt;/p&gt;

&lt;p&gt;In order to check for a the end of the buffer when parsing a &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt; tag, this piece of code was used:&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;https://tlseminar.github.io/images/timing-attacks/cloudflare/bug2.png&#34; alt=&#34;Ragel Bug Code&#34; style=&#34;width:500px;&#34;/&gt;&lt;br&gt;
&lt;sup&gt;&lt;a href=&#34;https://blog.cloudflare.com/incident-report-on-memory-leak-caused-by-cloudflare-parser-bug/&#34;&gt;https://blog.cloudflare.com/incident-report-on-memory-leak-caused-by-cloudflare-parser-bug/&lt;/a&gt;&lt;/sup&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;What it means is that in order to parse the end of the tag, zero or more &lt;code&gt;unquoted_attr_char&lt;/code&gt; are parsed followed by whitespace, &lt;code&gt;/&lt;/code&gt;, or &lt;code&gt;&amp;gt;&lt;/code&gt; signifying the end of the tag. If there is nothing wrong with the script tag, the parser will move to the code in the &lt;code&gt;@{ }&lt;/code&gt;. If there is a problem, the parser will move to the &lt;code&gt;$lerr{ }&lt;/code&gt; section.&lt;/p&gt;

&lt;p&gt;The bug was caused if a web page &lt;strong&gt;ended&lt;/strong&gt; with a malformed HTML tag such as &lt;code&gt;&amp;lt;script type=&lt;/code&gt;. The parser would transition to &lt;code&gt;dd(&amp;quot;script consume_attr failed&amp;quot;)&lt;/code&gt; which is just print debug output, but then &lt;strong&gt;instead of failing, it transitions to &lt;code&gt;fgoto script_consume_attr;&lt;/code&gt;&lt;/strong&gt;, which means it tries to parse another attribute.&lt;/p&gt;

&lt;p&gt;Notice that the &lt;code&gt;@{ }&lt;/code&gt; block has a &lt;code&gt;fhold&lt;/code&gt; while the &lt;code&gt;$lerr{ }&lt;/code&gt; block does not. It was the lack of the &lt;code&gt;fhold&lt;/code&gt; in the second block that caused the leak. In the generated code, &lt;code&gt;fhold&lt;/code&gt; is equivalent to &lt;code&gt;p--&lt;/code&gt; and thus if the malformed tag error happens at the end of the buffer, then &lt;code&gt;p&lt;/code&gt; will actually be after the end of the document and the check for the end of the buffer will fail, causing &lt;code&gt;p&lt;/code&gt; to overrun the buffer.&lt;/p&gt;

&lt;h3 id=&#34;the-response-from-cloudflare&#34;&gt;The Response From Cloudflare&lt;/h3&gt;

&lt;p&gt;Cloudflare seems to have responded relatively well to this bug. After the bug was brought to their attention they performed an initial mitigation, which meant disabling all of the sevices that used &lt;code&gt;cf_html&lt;/code&gt;, in 47 minutes. Luckily, Cloudlfare uses a &amp;lsquo;global kill&amp;rsquo; &lt;a href=&#34;https://blog.cloudflare.com/incident-report-on-memory-leak-caused-by-cloudflare-parser-bug/&#34;&gt;[1]&lt;/a&gt; feature to enable the global disabling of any service. Since the Email Obfuscation was the main cause of the leak, it was disabled first, and then Automatic HTTPS rewrites were killed about 3 hours later. About 7 hours after the bug was detected, a fix was deployed globablly. As mentioned previously, Cloudflare also contacted search engines to get the affected pages and their cached versions removed from the web.&lt;/p&gt;

&lt;p&gt;What was not as good about Cloudflare&amp;rsquo;s response were the lessons they said they learned in their incident report. Essentially, their lessons learned amounted to saying the bug was a corner case in an &amp;ldquo;ancient piece of software&amp;rdquo; and that they will be looking to &amp;ldquo;fuzz older software&amp;rdquo; to look for other potential problems &lt;a href=&#34;https://blog.cloudflare.com/incident-report-on-memory-leak-caused-by-cloudflare-parser-bug/&#34;&gt;[1]&lt;/a&gt;.  We hope Cloudflare will take more time to look at this incident more seriously and consider systemic issues that could allow such a problem to occur and persist.&lt;/p&gt;

&lt;h3 id=&#34;further-thoughts&#34;&gt;Further Thoughts&lt;/h3&gt;

&lt;p&gt;Bugs like this expose the difficulty of ensuring software
correctness. It is quite unlikely that a corner case like this would
have been caught by human eyes, and even a fuzzer would have had to
have triggered some exceptional conditions in order to exposed the
bug. On the other hand, many tools and processes exist for detecting
these types of problems, and there is little excuse for not using them
on security-critical software.&lt;/p&gt;

&lt;h3 id=&#34;reference&#34;&gt;Reference&lt;/h3&gt;

&lt;p&gt;[1] &lt;a href=&#34;https://blog.cloudflare.com/incident-report-on-memory-leak-caused-by-cloudflare-parser-bug/&#34;&gt;https://blog.cloudflare.com/incident-report-on-memory-leak-caused-by-cloudflare-parser-bug/&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>SHA-1 Collisions</title>
      <link>https://tlseminar.github.io/sha1-collisions/</link>
      <pubDate>Tue, 28 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://tlseminar.github.io/sha1-collisions/</guid>
      <description>

&lt;h3 id=&#34;the-first-sha-1-collision&#34;&gt;The First SHA-1 Collision&lt;/h3&gt;

&lt;p&gt;On February 23rd, 2017, researchers from Google and &lt;a href=&#34;https://www.cwi.nl/&#34;&gt;CWI Institute in Amsterdam&lt;/a&gt;) announced &lt;a href=&#34;https://security.googleblog.com/2017/02/announcing-first-sha1-collision.html&#34;&gt;the first SHA-1 collision&lt;/a&gt;.  As proof of this claim, two PDFs were published that yield the same SHA-1 hash despite containing different content (&lt;a href=&#34;https://shattered.it/static/shattered-1.pdf&#34;&gt;PDF 1&lt;/a&gt;, &lt;a href=&#34;https://shattered.it/static/shattered-2.pdf&#34;&gt;PDF 2&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;https://tlseminar.github.io/images/timing-attacks/collision.png&#34; alt=&#34;PDF Collision&#34; style=&#34;width:600px;&#34;/&gt;&lt;br&gt;
&lt;sup&gt;&lt;a href=&#34;https://shattered.it/static/shattered.png&#34;&gt;https://shattered.it/static/shattered.png&lt;/a&gt;&lt;/sup&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;While weaknesses in SHA-1 had been &lt;a href=&#34;http://merlot.usc.edu/csac-f06/papers/Wang05a.pdf&#34;&gt;known since the work by Xiaoyun Wang and colleagues in 2004&lt;/a&gt;, this is the first known attack to find an actual SHA-1 collision. While SHA-1 was deprecated by NIST in 2011, many systems still extensively use SHA-1 (git, SVN, even some &lt;a href=&#34;https://www.riskiq.com/blog/labs/wosign-and-startcom-caught-red-handed/&#34;&gt;certificate authorities&lt;/a&gt;, etc.). The researchers argue that these findings should reinforce the need to more secure hashing algorithms:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;We hope that our practical attack against SHA-1 will finally convince the industry that it is urgent to move to safer alternatives such as SHA-256.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;attack-details&#34;&gt;Attack Details&lt;/h3&gt;

&lt;p&gt;SHA-1 takes an arbitrary length message and computes a 160-bit hash. It divides the (padded) input into \(k\) blocks \(M_1, M_2, &amp;hellip;, M_k\) of 512 bits. The 160-bit internal state \(CV_j\), called the chaining value, is initialized to some initial value \(CV_0 = IV\). Then, each block \(M_j\) is fed to a compression function \(h\) that updates the chaining value, \(CV_{j+1} = h(CV_j, M_{j+1})\). \(CV_k\) Is the output of the hash.&lt;/p&gt;

&lt;p&gt;The attack implements the best known theoretical collision attack outlined by &lt;a href=&#34;https://marc-stevens.nl/research/papers/EC13-S.pdf&#34;&gt;Stevens (2013)&lt;/a&gt; (one of the leaders of this effort). This attack is an &lt;em&gt;identical-prefix collision attack&lt;/em&gt;, where a given prefix \(P\) is extended with two distinct &lt;em&gt;near collision block pairs&lt;/em&gt; such that they collide for any suffix \(S\):&lt;/p&gt;

&lt;p&gt;$$ \text{SHA-1}(P||M_1^{(1)}||M_2^{(1)}||S) = \text{SHA-1}(P||M_1^{(2)}||M_2^{(2)}||S) $$&lt;/p&gt;

&lt;p&gt;Finding both the first and second near collision block pairs, (\(M_1^{(1)}, M_1^{(2)}\)) and (\(M_2^{(1)}, M_2^{(2)}\)), respectively, was completed using slightly modified algorithms from Stevens&amp;rsquo; work. Broadly speaking, differences in the first block pair cause a small difference in the output chaining value, which is &amp;ldquo;canceled&amp;rdquo; by the difference in the second block pair. The remaining identical suffixes ensure a collision. &lt;em&gt;Differential paths&lt;/em&gt; are leveraged as a precise description of the differences in block pairs and how these differences evolve through the hashing steps. This description is the foundation of a search over the possible block pairs.  Note that once the collision block pairs are found for a particular prefix, any number of colliding inputs can be found since &lt;em&gt;S&lt;/em&gt; can be anything.&lt;/p&gt;

&lt;p&gt;The PDF format is exploited by packaging the differing collision blocks into an embedded JPEG image. In the example collision, the differing blocks are aligned such that the background of the PDFs are different.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;https://tlseminar.github.io/images/timing-attacks/pdf-enc.png&#34; alt=&#34;PDF Encoding&#34; style=&#34;width:600px;&#34;/&gt;&lt;br&gt;
&lt;sup&gt;&lt;a href=&#34;https://shattered.it/static/pdf_format.png&#34;&gt;https://shattered.it/static/pdf_format.png&lt;/a&gt;&lt;/sup&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;A significant contribution of this work is to apply these algorithms at the scale necessary for practical execution. While the source code for these computations has not yet been released (the authors are allowing a grace period to move to modern hashing algorithms), the changes required to scale this attack are highly non-trivial. Combined, the computations required approximately 6500 CPU years and 100 GPU years. At the time of publishing, the authors estimate the total cost of their attack (via AWS) at $110,000, easily within the reach of criminals. This attack is estimated to be approximately 100,000 times faster than a brute force search.&lt;/p&gt;

&lt;p&gt;Full technical details of the attack are outlined in the released paper:
Marc Stevens, Elie Bursztein, Pierre Karpman, Ange Albertini, Yarik Markov. &lt;a href=&#34;https://shattered.it/static/shattered.pdf&#34;&gt;&lt;em&gt;The first collision for full SHA-1&lt;/em&gt;&lt;/a&gt;.  (Released 23 February, 2017)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Testing and Verification of TLS</title>
      <link>https://tlseminar.github.io/verification/</link>
      <pubDate>Fri, 24 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://tlseminar.github.io/verification/</guid>
      <description>

&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;TLS/SSL is the most widely adopted protocol for securing online communication. However, as we have seen in the past few weeks, creative attackers have found it riddled with &lt;a href=&#34;https://tlseminar.github.io/padding-oracle&#34;&gt;exploitable&lt;/a&gt; &lt;a href=&#34;https://tlseminar.github.io/downgrade-attacks&#34;&gt;weaknesses&lt;/a&gt;. Rather than just reacting to attacks as they are discovered, many projects instead proactively seek out potential security flaws to implement remedies before vulnerabilities are exploited. This is done primarily by testing and verification, the topic of this week&amp;rsquo;s blog post.&lt;/p&gt;

&lt;p&gt;First, we will examine some motivating attacks on TLS implementations, including the Heartbleed attack, CRIME attack, and the infamous “goto fail”, as well as their solutions. Next, we will discuss differential testing, a technique that creates well-formed but forged certificates, called &amp;ldquo;frankencerts&amp;rdquo;, and uses them to compare the responses of many popular implementations such as OpenSSL - and how they strengthened their defenses afterward (or didn’t). Finally, we introduce verification, which takes advantage of the relationship between computer systems and mathematics to rigorously prove properties about programs, either by type-checking existing programs or building a program from scratch starting with abstract refinement types.&lt;/p&gt;

&lt;h3 id=&#34;heartbleed&#34;&gt;Heartbleed&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;http://heartbleed.com/&#34;&gt;&lt;em&gt;Heartbleed&lt;/em&gt;&lt;/a&gt; by Codenomicon (2014)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;OpenSSL’s heartbleed bug exploits heartbeat requests between a client and a server. In the OpenSSL implementation, the client does not check the actual lengths of the message but trusts the length field in the request message. If the real message is shorter than the length specified in the length field, then the payload returned in the response heartbleed can also contain what happened to be in the allocated memory buffer. In this manner, secret keys, login credentials, sensitive data, and miscellaneous memory are all at risk of exposure.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://tlseminar.github.io/images/verification/heartbleed.png&#34; alt=&#34;Heartbleed&#34; width=&#34;75%&#34;&gt;&lt;Br&gt;
&lt;span class=&#34;caption&#34;&gt;&lt;em&gt;Source: &lt;/em&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Heartbleed#/media/File:Simplified_Heartbleed_explanation.svg&#34;&gt;Wikipedia&lt;/a&gt;&lt;/span&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;h3 id=&#34;compression-ratio-info-leak-mass-exploitation-crime&#34;&gt;Compression Ratio Info-Leak Mass Exploitation (CRIME)&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.google.com/presentation/d/11eBmGiHbYcHR9gL5nDyZChu_-lCa2GizeuOfaLU2HOU/edit#slide=id.g1e3070b2_0_10&#34;&gt;&lt;em&gt;The CRIME Attack&lt;/em&gt;&lt;/a&gt; by Juliano Rizzo and Thai Duong (2013)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;CRIME attacks were developed by Juliano Rizzo and Thai Duong in 2012 and exploited TLS Compression by injecting plaintext into victim’s web requests and observing the outcome length. Tampering with web requests is made possible by injecting malicious JavaScript code through a network attack. Through many trials, the attacker can steal user cookies and hijack the session.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://tlseminar.github.io/images/verification/crime.png&#34; alt=&#34;CRIME&#34;&gt;&lt;Br&gt;
&lt;span class=&#34;caption&#34;&gt;&lt;em&gt;Source: &lt;/em&gt;&lt;a href=&#34;http://2we26u4fam7n16rz3a44uhbe1bq2.wpengine.netdna-cdn.com/wp-content/uploads/101413_1347_BEASTvsCRIM4.png&#34;&gt;Infosec Institute&lt;/a&gt;&lt;/span&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;h3 id=&#34;goto-fail&#34;&gt;Goto Fail;&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://www.cigital.com/blog/understanding-apple-goto-fail-vulnerability-2/&#34;&gt;&lt;em&gt;Understanding Apple &amp;lsquo;goto fail&amp;rsquo; Vulnerability&lt;/em&gt;&lt;/a&gt; by Amit Sethi (2014)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In February 2014, Apple released a security update on many versions of its operating system that included the following vulnerability in the function SSLVerifySignedServerKeyExchange.
&lt;div style=&#34;padding-left: 100px&#34;&gt;
&lt;pre&gt;if ((err = SSLHashSHA1.update(&amp;amp;hashCtx, &amp;amp;signedParams)) != 0)
    goto fail;
    goto fail;
  &amp;hellip; other checks &amp;hellip;
  fail:
    &amp;hellip; buffer frees (cleanups) &amp;hellip;
    return err;
&lt;/pre&gt;
&lt;/div&gt;
&lt;center&gt;
&lt;span class=&#34;caption&#34;&gt;&lt;em&gt;Source: &lt;/em&gt;&lt;a href=&#34;https://www.dwheeler.com/essays/apple-goto-fail.html&#34;&gt;David A. Wheeler&lt;/a&gt;&lt;/span&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;The indentation on the second &lt;code&gt;goto fail;&lt;/code&gt; is misleading. The lack of curly brackets meant that the second &lt;code&gt;goto fail;&lt;/code&gt; will always be executed, skipping vital signature checking and accepting both good and bad signatures.&lt;/p&gt;

&lt;h1 id=&#34;differential-testing&#34;&gt;Differential Testing&lt;/h1&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.685.8677&#34;&gt;&lt;em&gt;Using Frankencerts for Automated Adversarial Testing of Certificate Validation&lt;/em&gt;&lt;/a&gt; by Chad Brubaker, Suman Jana, Baishakhi Ray, Sarfraz Khurshid, and Vitaly Shmatikov (2014)&lt;br /&gt;
&lt;a href=&#34;http://dl.acm.org/citation.cfm?doid=2786805.2786834&#34;&gt;&lt;em&gt;An empirical study of goto in C code from GitHub repositories&lt;/em&gt;&lt;/a&gt; by Meiyappan Nagappan, Romain Robbes, Yasutaka Kamei, Éric Tanter, Shane McIntosh, Audris Mockus, and Ahmed E. Hassan (2015)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Differential testing is the process of searching for bugs in software by running multiple programs on the same inputs.  If there is a discrepancy between one program’s results on a given input and another’s, it’s likely that one of the implementations is bugged.  A differential testing system will flag such results for human review.&lt;/p&gt;

&lt;p&gt;Brubaker et al. used this technique to test server authentication for many implementations of SSL/TLS as presented in their 2014 “Frankencerts” paper.  The researchers initially had to deal with the dual problems of generating test case certificates and successfully interpreting the results of acceptance and rejection.&lt;/p&gt;

&lt;p&gt;Generating certificates proved to be a challenge due to the nature of an SSL certificate.  Simply randomly fuzzing valid certificates is unlikely to produce data parsable as a certificate.  Manually creating test cases would take too long and potentially miss edge cases that a more statistically comprehensive generation method would find.  The researchers decided on creating frankencerts by scanning 243,246 current certificates from the internet and randomly permuting their parts.  This process guaranteed that the 8,127,600 frankencerts would be parsable as certificates and resulted in a wide variety of unusual combinations of extensions, key usage constraints, odd CAs, and other possible variations within a cert.&lt;/p&gt;

&lt;p&gt;The researchers then ran OpenSSL, NSS, GnuTLS, CyaSSL, PolarSSL, MatrixSSL, OpenJDK, and Bouncy Castle on the frankencerts, looking for discrepancies between results.  Because each of these libraries is intended to implement the same X.509 certificate validation logic, any discrepancy in certificate acceptance between them would indicate that SOMEONE was screwing up.  Thus the researchers dealt with the second issue, that of interpreting the results of their tests.&lt;/p&gt;

&lt;p&gt;Running the differential test on all 8 million frankencerts and the quarter-million real certificates  produced 208 discrepancies that, when manually investigated, uncovered many serious flaws in the various implementations (error results are bolded):&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://tlseminar.github.io/images/verification/diff-testing.png&#34; alt=&#34;Differential Testing Results&#34;&gt;&lt;Br&gt;
&lt;span class=&#34;caption&#34;&gt;&lt;em&gt;Source: &lt;/em&gt;&lt;a href=&#34;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.685.8677&#34;&gt;Chad Brubaker, Suman Jana, Baishakhi Ray, Sarfraz Khurshid, and Vitaly Shmatikov&lt;/a&gt;&lt;/span&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;Any of the invalid acceptances would allow for an in-the-middle attack to be crafted against the implementation in question.  The researchers contacted the developers of the various SSL/TLS implementations affected and reported their results before publishing, allowing the developers time to fix their bugs.&lt;/p&gt;

&lt;p&gt;Chen and Su’s mucert builds on the frankencert method.  Mucerts are randomly fuzzed test certificates generated from a seed set of certificates.  The fuzzing, or mutating, occurs in accordance with a number of guidelines that prevent mutations from generating unparseable certificates.  Chen and Su statistically evaluated mucerts and compared them to frankencerts, finding that mucerts attained drastically higher levels of corner case coverage.&lt;/p&gt;

&lt;h1 id=&#34;verification&#34;&gt;Verification&lt;/h1&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://galois.com/blog/2016/09/verifying-s2n-hmac-with-saw/&#34;&gt;&lt;em&gt;Verifying s2n HMAC with SAW&lt;/em&gt;&lt;/a&gt; by Joey Dodds (2016) &lt;br&gt;
&lt;a href=&#34;https://www.microsoft.com/en-us/research/publication/implementing-tls-with-verified-cryptographic-security/&#34;&gt;&lt;em&gt;Implementing TLS with Verified Cryptographic Security&lt;/em&gt;&lt;/a&gt; by Karthikeyan Bhargavan, Cédric Fournet, Markulf Kohlweiss, Alfredo Pironti,and Pierre-Yves Strub (2013) &lt;br&gt;
&lt;a href=&#34;http://www.cis.upenn.edu/~bcpierce/sf/current/Preface.html#lab2&#34;&gt;&lt;em&gt;Software Foundations&lt;/em&gt;&lt;/a&gt; by Benjamin C. Pierce, et al. (2017)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Software testing can only assert properties about program behaviors covered in the test suite. There will always be missed edge cases and odd bugs that will show up in code. This is where we turn to formal specifications to ‘prove’ the correctness of our code.&lt;/p&gt;

&lt;p&gt;But how do we go about ‘proving’ this correctness? Let’s look at what we’re trying to solve in the first case:&lt;/p&gt;

&lt;p&gt;For each behavior X in code, formally prove that X does what it should and nothing else. For those that are familiar with proofs and mathematical abstractions, this is known as a non-existence proof. In formal verification, we must prove that a program satisfies a formal specification of its behavior. By using the methods of mathematics, we can make strong statements regarding the correctness of our cryptographic implementations, for example, TLS.&lt;/p&gt;

&lt;p&gt;To get down to formal verification, we must first define the difference between &lt;em&gt;verification&lt;/em&gt; and &lt;em&gt;validation&lt;/em&gt;. Validation asks questions like &lt;em&gt;Does it meet the requirements?&lt;/em&gt;, &lt;em&gt;Is it the right product?&lt;/em&gt;, and &lt;em&gt;Does it function according to design?&lt;/em&gt;.  Whereas, verification asks the question &lt;em&gt;does this software meet a given specification under given assumptions?&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;One requirement for nearly any stronger property is to first show the code satisfied type safety. A program is considered type safe if and only if the only operations that can be performed on data are those sanctioned by the type of data. For example, we can look at the following program where integers, floats, and doubles are being implicitly cast amongst one another. In a type safe program, an integer could never be treated as a float (more importantly, a pointer type would never be treated as a non-pointer, and vice versa).&lt;/p&gt;

&lt;p&gt;While the below program is well-typed, it illustrates some of the
challenges faced when attempting to show type safety for typical C
code:&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://tlseminar.github.io/images/verification/type-safe.png&#34; alt=&#34;Type Safety of Code&#34; width=&#34;60%&#34;&gt;&lt;Br&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;There are a variety of formal concepts that are used in program verification including model checking, deductive verification, equivalence checking, theorem proving, and correctness by construction. The problem that arises, though, is that some of these rely on concepts that simply are not feasible in commercial-level programs. For example, model checking exhaustively checks whether a model of the program meets a given specification, but every behavior in the program must have proper transitions and states resulting in the state explosion problem. Put simply, as more behaviors are added to simple programs, the number of states in the model exponentially grows. Due to this, it is challenging to scale model checking to large systems, although extensive work has been done toward this goal and often complex programs can be abstracted in ways that enable useful model checking.&lt;/p&gt;

&lt;p&gt;One popular approach to verification is to use expressive type systems. Using the Curry-Howard isomorphism, we are able to directly relate programs with mathematical proofs and therefore have the ability to create refinement types which are types endowed with a predicate which is assumed to hold for any element of the refined type. What this means is that we can define our program using refinement types to encode the safety properties of the system which can be type-checked and proven to hold that safety property true.&lt;/p&gt;

&lt;p&gt;There’s a lot that can be done with formal verification and TLS is a great possible use for fixing errors created during implementation. There are actually a number of projects for verifying parts of TLS out there that are attempting to combine together to formally verify TLS as a whole. This joint project is known as &lt;a href=&#34;https://project-everest.github.io/&#34;&gt;Project Everest&lt;/a&gt;. Everest is a pretty lofty goal considering the difficulty of formally verifying even small-level programs and scripts, but has made considerable progress towards building a fully verified TLS implementation. The eventual goal of Everest is that when all the projects are combined together, they will generate a C library that not only implements TLS 1.3 but is also proven secure, essentially circumventing any possible flaws in the TLS protocol.&lt;/p&gt;

&lt;h3 id=&#34;coq&#34;&gt;Coq&lt;/h3&gt;

&lt;p&gt;Team Cinnamon displayed a formal verification software called Coq during class. Coq is an assistive tool for the verification of code. The software implements a variety of mathematical and computational strategies to work, in combination with the user, to formally verify code, functions, and theorems. In class we ran through a couple of sample proofs to display the functionality and potential of Coq as a verification software and to give an example of how a formal verification software works.&lt;/p&gt;

&lt;p&gt;A download for Coq is available at &lt;a href=&#34;https://coq.inria.fr/&#34;&gt;&lt;em&gt;https://coq.inria.fr/&lt;/em&gt;&lt;/a&gt; which offers different versions for different architectures. We used the CoqIDE which allows for editing Coq files with helpful syntax highlighting and is useful when trying to first learn Coq. For a good introduction to Coq, as well as number of exercises for what to do, a group at UPenn has a &lt;a href=&#34;http://www.cis.upenn.edu/~bcpierce/sf/current/Preface.html#lab2&#34;&gt;great lab focused on Coq&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://tlseminar.github.io/images/verification/coq.png&#34; alt=&#34;Sample Coq Code&#34;&gt;&lt;Br&gt;
&lt;span class=&#34;caption&#34;&gt;&lt;em&gt;Source: &lt;/em&gt;&lt;a href=&#34;https://coq.inria.fr/refman/Reference-Manual018.html&#34;&gt;The Coq Proof Assistant&lt;/a&gt;&lt;/span&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;Coq is extremely powerful software to help formally verify computer
programs, but it can be difficult to learn, requiring a change in
mentality for most programmers. For any problems or difficulties found
when using Coq, there is plenty of documentation available within
Coq’s &lt;a href=&#34;https://coq.inria.fr/distrib/current/refman/toc.html&#34;&gt;Reference Manual&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;Implementing cryptographic protocols correctly remains a huge
challenge.  There are tools available now that can prove interesting
properties about software, including even the absence of certain types
of side channels.  It is important to remember, though, that anything
we prove about a program is a proof about a property based on a model
of the execution environment, and assumptions about adversary
capabilities.  As verification and testing tools get more
sophisticated, those models can come increasingly close to the actual
environment and capabilities of real adversaries, but today, there
remains a large gap.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Certificates</title>
      <link>https://tlseminar.github.io/certificates/</link>
      <pubDate>Fri, 10 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://tlseminar.github.io/certificates/</guid>
      <description>

&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;So far, we have learned some real-world TLS attacks and how they bring potential vulnerabiliting in different situations. Since the core SSL/TLS technology has persisted as the basis for securing many aspects of today’s Internet for more than twenty years, including data transfer, user passwords, and site authentication, it is important to also consider issues beyond the protocol.&lt;/p&gt;

&lt;p&gt;This week, we’ll go on to discuss practical issues with TLS including
HTTPS, certificates, key management and an attack called SSLstripping.&lt;/p&gt;

&lt;h1 id=&#34;trust-issues-and-enhancements&#34;&gt;Trust Issues and Enhancements&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://tlseminar.github.io/docs/soktls.pdf&#34;&gt;&lt;em&gt;SoK: SSL and HTTPS: Revisiting past challenges and evaluating certificate trust model enhancements&lt;/em&gt;&lt;/a&gt;, Jeremy Clark and Paul C. van Oorschot, IEEE Symposium on Security and Privacy (&amp;ldquo;Oakland&amp;rdquo;), 2013.&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;certificates&#34;&gt;Certificates&lt;/h3&gt;

&lt;p&gt;The TLS protocol enables a client and a server to establish and communicate over a secure channel. Assuming such a secure channel can be created, authenticating the server still remains a challenge. HTTPS attempts to solve this problem using certificates, which bind public keys to servers. Web browsers trust certificates that are issued by certificate authorities (CAs).&lt;/p&gt;

&lt;p&gt;A certificate is bound to a server through its domain name. When requesting a certificate for a domain name from a CA, the requester is challenged to demonstrate control of the domain name. Upon successful validation, the CA will digitally sign a domain validated (DV) certificate for the entity.&lt;/p&gt;

&lt;p&gt;Stronger verification techniques are available due to security issues with hostname validation. A common verification technique used by CAs is to send an email to an email address associated with the domain. This becomes an issue when an attacker is able to spoof DNS records, such as through a DNS cache poisoning attack. Issues may also arise when an attacker is able to register an email address at the domain. For example, an attacker was able to convince a CA that owned &lt;code&gt;login.live.com&lt;/code&gt; by registering &lt;code&gt;sslcertificates@live.com&lt;/code&gt;. In response, CAs offer extended validation (EV) certificates to entities willing to pay a premium and undergo more stringent validation.&lt;/p&gt;

&lt;h3 id=&#34;anchoring-trust&#34;&gt;Anchoring Trust&lt;/h3&gt;

&lt;p&gt;Although anyone can create a certificate for any site they want, clients should only trust a certificate if it has been signed by a CA they already trust. Browsers com pre-configured with a default list of CAs known as trust anchors. Mozilla&amp;rsquo;s Firefox 15 browser includes approximately 150 trust anchors.&lt;/p&gt;

&lt;p&gt;Users may also add additional trust anchors to their system. This is commonly done by organizations in order to MITM their users HTTPS connections to perform content inspection, or by users who want to inspect the contents of their own HTTPS requests.&lt;/p&gt;

&lt;p&gt;Because any trust anchor is able to issue trusted certificates for a website, an adversary need only target the weakest CA in order to obtain a fraudulent certificate. Furthermore, governments are in a position to compel CAs to create valid certificates to be used in MITM attacks.&lt;/p&gt;

&lt;p&gt;To prevent misuse of fraudulent certificates, webservers may use HTTP Public Key Pinning (HPKP) to remember a presented certificate, and warn the user if a different certificate is ever presented for the same domain in the future. This way, even if an adversary has obtained a certificate that is trusted by a browser, they will be unable to perform a MITM attack. However, this technique requires a user to blindly trust the first certificate that the webserver pins. An effective alternative is for browser vendors to include a list of certificates to pin within the browser.&lt;/p&gt;

&lt;h3 id=&#34;transitivity-of-trust&#34;&gt;Transitivity of Trust&lt;/h3&gt;

&lt;p&gt;In addition to signing certificates for webservers, trust anchors can issue certificates allowing other organizations to also act as CAs. While Firefox includes nearly 150 trust anchors from approximately 50 organizations, hundreds of organizations, including the US Department of Homeland Security, are trusted intermediate CAs.&lt;/p&gt;

&lt;p&gt;Client software does not generally maintain a list of intermediate CAs. Rather, they use a chain discovery mechanism to trace a server&amp;rsquo;s certificate back to a trust anchor. Such a chain must be carefully validated to check that each intermediate CA occurring in the chain has actually been granted authority to sign further certificates. This check was previously skipped by Microsoft&amp;rsquo;s CryptoAPI and Apple&amp;rsquo;s iOS.&lt;/p&gt;

&lt;p&gt;One way to ensure that every intermediate CA is visible to users is to publish a list of every valid certificate. This way, clients are able to know about intermediate CAs before their certificate is encountered. This is important because intermediate CAs can have just as much power as the trust anchors.&lt;/p&gt;

&lt;h3 id=&#34;maintenance-of-trust-revocation&#34;&gt;Maintenance of Trust (Revocation)&lt;/h3&gt;

&lt;p&gt;Sometimes a certificate needs to be revoked, such as when a site is compromised or abandoned, the domain name is exchanged, or the CA becomes aware of mistaken issuance. This revocation status must be readily available through the CA, either through a certificate revocation list (CRL) or an online certificate status checking protocol (OCSP).&lt;/p&gt;

&lt;p&gt;Because this revocation information may be unavailable, browsers choose to accept certificates when the information cannot be located. Thus an adversary who is able to prevent a browser from obtaining revocation information may be able to cause a revoked certificate to be accepted.&lt;/p&gt;

&lt;p&gt;Besides the list of all valid certificates described above, one way to combat unreliable revocation is for webservers to provide timestamped OCSP status reports, a technique known as Certificate Status Stapling. Alternatively, if certificates were issued to be valid for a shorter time, the impact of missing a revocation is lessened. Currently, certificates are often valid for years, but a 2012 proposal calls for certificates that remain valid for only four days, eliminating the need for a revocation mechanism (&lt;a href=&#34;http://www.w2spconf.com/2012/papers/w2sp12-final9.pdf&#34;&gt;Topalovic et al.&lt;/a&gt;).&lt;/p&gt;

&lt;h3 id=&#34;indication-and-interpretation-of-trust&#34;&gt;Indication and Interpretation of Trust&lt;/h3&gt;

&lt;p&gt;When a user browses to a website, they are expected to verify that they are connecting over HTTPS. This is indicated to the users through the &lt;code&gt;https://&lt;/code&gt; at the beginning of the URL in the address bar, and the green lock icon displayed by the browser. This icon may typically be clicked on to display more information about the website&amp;rsquo;s certificate. However, studies have shown that many users do not look for these indicators, and may even assume a page is secure based on the type of information being displayed.&lt;/p&gt;

&lt;p&gt;Even when a browser displays a warning for a failed HTTPS connection, many users will click through and still log into the site. This may be due to users not understanding the certificate warning, not understanding the risks of visiting a site with an invalid certificate, or making a decision to visit the site anyway despite understanding and weighing the rists. Another common warning is the mixed scripting warnings, indicating that Javascript is being loaded over plain HTTP but being run within the HTTPS site&amp;rsquo;s privileges.&lt;/p&gt;

&lt;p&gt;If an adversary expects a user to look for HTTPS indicators, they may be able to spoof common security cues. Some users believe an image of a lock on the website is a sign of a successful HTTPS connections. A more involved example is shown in the image below, where an attacker has simulated a browser address bar, complete with the HTTPS indicators that come with a valid EV certificate.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img width=594 alt=&#34;Security Indicators&#34; src=&#34;https://tlseminar.github.io/images/TSS2.png&#34;&gt;&lt;Br&gt;
Fake Address Bar (Image from &lt;a href=&#34;https://blog.malwarebytes.com/cybercrime/social-engineering-cybercrime/2016/08/tech-support-scams-and-google-chrome-tricks/&#34;&gt;Malwarebytes&lt;/a&gt;)
&lt;/center&gt;&lt;/p&gt;

&lt;h1 id=&#34;coniks-and-certificate-transparency&#34;&gt;CONIKS and Certificate Transparency&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://eprint.iacr.org/2014/1004.pdf&#34;&gt;CONIKS: Bringing Key Transparency to End Users&lt;/a&gt;&lt;/strong&gt;, Marcela S. Melara, Aaron Blankstein, Joseph Bonneau, Edward W. Felten, Michael J. Freedman, USENIX Security &amp;lsquo;15&lt;/p&gt;

&lt;p&gt;CONIKS is a key management system intended to reduce the workload on clients to verify keys for secure communications. It&amp;rsquo;s an extension of the existing certificate transparency logs for webservers to end users. CONIKS simultaneously helps address the issue of service providers tampering with keys and of trust establishment that would otherwise be done out-of-band manually. The system is intended to prevent equivocation of keys, prevent the addition of unauthorized keys, and allow for transparent and public verification all while being efficient for users.&lt;/p&gt;

&lt;p&gt;CONIKS is motivated by a desire to increase the use of end-to-end encryption, which has traditionally struggled with key management. Systems like WhatsApp and Apple&amp;rsquo;s iMessage use centralized storage of public keys which is vulnerable to key removal, key changing, or server takeover. Furthermore, many systems have no way (beyond clunky manual steps) to verify contacts are who they claim to be.&lt;/p&gt;

&lt;h3 id=&#34;design&#34;&gt;Design&lt;/h3&gt;

&lt;p&gt;The design of CONIKS involves several non-distinct participants: service providers, end users, and auditors. &lt;em&gt;Service providers&lt;/em&gt; manage their own individual namespace of name (e.g., &lt;code&gt;alice@host.com&lt;/code&gt;) to key bindings. While not assumed to be trustworthy, service providers are expected to have a reputation to uphold. &lt;em&gt;End-users&lt;/em&gt; are the clients and intend to communicate with each other securely. Clients require only a relatively accurate clock and a usable network connection. They are also responsible for serving as &lt;em&gt;auditors&lt;/em&gt; who track the key log for forgeries, invalid updates, and new unsolicited keys.&lt;/p&gt;

&lt;p&gt;Each service provider constructs its directory of &lt;em&gt;name&lt;/em&gt; &amp;rarr; &lt;em&gt;key&lt;/em&gt; mappings as a Merkle binary prefix tree, with each tree node representing a unique prefix.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://tlseminar.github.io/images/merkle.png&#34; width=500 alt=&#34;Merkle Tree&#34;&gt;&lt;/img&gt;&lt;br&gt;
Merkle Prefix tree (image from CONIKS paper
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;As in other Merkle trees, interior nodes represent hashes of their left and right children. Leaf nodes are hashed over a nonce (&lt;em&gt;k&lt;sub&gt;n&lt;/em&gt;&lt;/sub&gt;), a node index, the tree depth, and a cryptographic commitment of the user&amp;rsquo;s name and public key. Empty or placeholder nodes are hashed similarly, but instead include a different constant, &lt;em&gt;k&lt;sub&gt;empty&lt;/sub&gt;&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://tlseminar.github.io/images/strchain.png&#34; width=&#34;650&#34; alg=&#34;STR Chain&#34;&gt;&lt;br&gt;
Signed STR chain (Image from CONIKS paper)
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;At regular intervals, or epochs, the service provider signs the merkle root of the previous tree and a sequentially increasing number to indicate the order of the blocks. This helps ensure that service providers cannot change the historical record easily, and also must maintain a changed STR chain indefinitely.&lt;/p&gt;

&lt;h3 id=&#34;common-operations&#34;&gt;Common Operations&lt;/h3&gt;

&lt;p&gt;Registration in a CONIKS system occurs when the user sends their name and public key to the service provider. Since the server only published a signed record every epoch, it will issue a &amp;ldquo;temporary binding&amp;rdquo; in the mean-time to validate the key, signing the user key, name, and eventual index.&lt;/p&gt;

&lt;p&gt;To look up a key, clients will consult the server for a given name and receive the matching public key and a STS proof of inclusion, consisting of all the hashes from the position of the key on the way up the tree. Since interior nodes consist only of hashes of the left and right nodes, the client can verify that the key is at the position the server claims, or that the key is truly missing if the server claims it is.&lt;/p&gt;

&lt;p&gt;A general flow for secure communications therefore looks something like this:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Alice contacts the service provider (Carol) and requests the public key for &lt;code&gt;bob@host.com&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Carol returns the public key and the proof of inclusion hash chain.&lt;/li&gt;
&lt;li&gt;Alice computes the merkle root of the tree and compares to her last known root from the STR chain.&lt;/li&gt;
&lt;li&gt;After proving Carol gave the correct key, Alice encrypts her message with Bob&amp;rsquo;s public key and sends it.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;auditing&#34;&gt;Auditing&lt;/h3&gt;

&lt;p&gt;One of the most important features of CONIKS is the ability for anyone to audit the &lt;em&gt;name&lt;/em&gt; &amp;rarr; &lt;em&gt;key&lt;/em&gt; mappings. Indeed, clients are encouraged to regularly audit their own keys to ensure they have not been compromised. Auditing works much like key lookup &amp;mdash; the server is consulted for the key mapping to the given name. Clients who are also auditing will confirm that the returned private key matches the saved one they possess, and that the keys have not changed in an authorized way between epochs.&lt;/p&gt;

&lt;h3 id=&#34;considerations-for-deploying-coniks&#34;&gt;Considerations for deploying CONIKS&lt;/h3&gt;

&lt;h4 id=&#34;initial-key-submission-window&#34;&gt;Initial key submission window&lt;/h4&gt;

&lt;p&gt;It&amp;rsquo;s important to note that until the next STR is published, clients won&amp;rsquo;t be able to communicate using their public key, as nobody else will have seen it. However, clients can audit their own keys to prevent any malicious actors from changing their initial key upload.&lt;/p&gt;

&lt;h4 id=&#34;whistleblowing&#34;&gt;&amp;lsquo;Whistleblowing&amp;rsquo;&lt;/h4&gt;

&lt;p&gt;The CONIKS protocol currently doesn&amp;rsquo;t provide any way for clients to contact each other if they detect malicious activity either in general or on the part of the service provider. If their keys are hijacked, they are responsible for communicating that information to others on their own, which could be over an unsafe channel.&lt;/p&gt;

&lt;h4 id=&#34;key-change-or-revocation&#34;&gt;Key Change or Revocation&lt;/h4&gt;

&lt;p&gt;CONIKS doesn&amp;rsquo;t currently provide any way for users to update or revoke their keys directly. One easy path would be for users to sign some message indicating they wish to remove the previous key. However, if a user lost their key they would be unable to revoke their old one.&lt;/p&gt;

&lt;h1 id=&#34;ssl-stripping&#34;&gt;SSL Stripping&lt;/h1&gt;

&lt;h5 id=&#34;defeating-ssl-using-sslstrip-https-www-youtube-com-watch-v-mfol6imbz7y-2009-black-hat-dc-presentation-by-moxie-marlinspike&#34;&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=MFol6IMbZ7Y&#34;&gt;Defeating SSL Using sslstrip&lt;/a&gt; 2009 Black Hat DC presentation by Moxie Marlinspike&lt;/h5&gt;

&lt;p&gt;In this part of the blog post we further explore the sslstrip attack, presented to the class by Team Sesame on February 10th, 2017.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img width=&#34;500&#34; alt=&#34;MITM Framework&#34; src=&#34;https://tlseminar.github.io/images/sslstrip.png&#34;&gt;&lt;br&gt;
In-the-Middle Attack Setup (Image from avicoder)
&lt;/center&gt;&lt;/p&gt;

&lt;h3 id=&#34;overview&#34;&gt;Overview&lt;/h3&gt;

&lt;p&gt;The sslstrip attack is both an in-the-middle attack and protocol downgrade attack that relies on websites not implementing HSTS and also browsers&amp;rsquo; inability to prevent users from POST&amp;rsquo;ing sensitive data to HTTP websites.&lt;/p&gt;

&lt;p&gt;The sslstrip python module, when used in conjunction with an MITM framework, replies to the victim&amp;rsquo;s HTTPS requests with HTTP versions of the same page silently stripping the &lt;code&gt;S&lt;/code&gt;. On modern browsers the only visual cue is the lack of HTTPS:&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://tlseminar.github.io/images/sslstripindicator.png&#34; width=&#34;400&#34;&gt;&lt;br&gt;
Screenshot of Chrome on iPhone 7
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;This differs from other HTTPS MITM attacks whereby an attacker forces the victim to connect to a fake access point where tools like mitmproxy can be then used to sign forged certificates for websites on the fly.&lt;/p&gt;

&lt;p&gt;However, most browsers have mechanisms to protect against this like HTTP Public Key Pinning (HPKP) and browser warnings:&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://tlseminar.github.io/images/chromenotprivate.png&#34; width=&#34;400&#34; alt=&#34;Chrome: Not Private&#34;&gt;&lt;br&gt;
Self signed SSL certificate warning in Google Chrome, image courtesy of &lt;a href=&#34;http://www.inmotionhosting.com/support/website/ssl/self-signed-ssl-certificate-warning&#34;&gt;Inmotionhosting&lt;/a&gt;.
&lt;/center&gt;&lt;/p&gt;

&lt;h3 id=&#34;necessary-requirements&#34;&gt;Necessary Requirements&lt;/h3&gt;

&lt;p&gt;In order for an attacker to obtain victim credentials for a given HTTPS website using sslstrip&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;The attacker must be on the same LAN as the victim (necessary to obtain MITM status)&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;The HTTPS website the victim accesses must have initiated the connection first via HTTP&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;The given website must not be on victim&amp;rsquo;s browsers HSTS Preloads (supported by all modern browsers, this list includes the Google domains and ~7500 other sites)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Sslstrip works by listening for HTTP 301 “Moved Permanently&amp;rdquo; (i.e., Redirect to HTTPS). So unless the victim explicitly types in https:// (HTTPS to begin with) or the website is on the browser&amp;rsquo;s HSTS Preloads, or the website is HTTPS only, the 301 will be issued and at that point sslstrip will intercept this response and instead relay back to the victim a HTTP version of the HTTPS site.&lt;/p&gt;

&lt;p&gt;So, Requirement 2 is necessary for sslstrip to work. In the case of the website being on the browser list of HSTS preloads, then the first request over HTTPS is is never dispatched but rather internally redirected by the browser to the HTTPS version which is why Requirement 3 states the given website must not be on the &lt;a href=&#34;https://chromium.googlesource.com/chromium/src/+/master/net/http/transport_security_state_static.json&#34;&gt;HSTS Preload list&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;countermeasures&#34;&gt;Countermeasures&lt;/h3&gt;

&lt;p&gt;The most obvious countermeasures include:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Browser Indications, SSLight, other addons?&lt;/li&gt;
&lt;li&gt;Server: HSTS (HTTP Strict Transport Security) Preloads&lt;/li&gt;
&lt;li&gt;Server: HTTPS only&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;While improvements have been made to sslstrip such as using different domains like &lt;code&gt;wwww&lt;/code&gt; (and various countermeasures like key pinning and browser displays), in present day the original sslstrip (2009) does not work against sites with HSTS enabled like &lt;code&gt;facebook.com&lt;/code&gt; and &lt;code&gt;gmail.com&lt;/code&gt;. Surprisingly though, a &lt;a href=&#34;https://news.netcraft.com/archives/2016/03/17/95-of-https-servers-vulnerable-to-trivial-mitm-attacks.html&#34;&gt;2016 article&lt;/a&gt; claimed only 1 in 20 HTTPS servers implemented HSTS correctly!&lt;/p&gt;

&lt;p&gt;Sslstrip is an easily-deployable and effective attack &amp;ldquo;in the wild&amp;rdquo; because of but not limited to session hijacking and the fact most browsers do not alert users they are submitting over http (or conversely most users do not notice &lt;code&gt;http://&lt;/code&gt; when submitting sensitive info). In addition, password reuse is widespread and if credentials were obtained from say apple.com or a bank they could be tried against more sensitive websites which do support HSTS (enable two factor authentication!!).&lt;/p&gt;

&lt;h3 id=&#34;further-reading&#34;&gt;Further Reading:&lt;/h3&gt;

&lt;p&gt;Writeup describing modern browser and website protections against MITM attacks:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.troyhunt.com/understanding-http-strict-transport/&#34;&gt;https://www.troyhunt.com/understanding-http-strict-transport/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Try it out yourself! This blog post describes how an attacker on Mac OS X could use sslstrip to gather credentials over network. I learned both my online banking website and apple.com were vulnerable to sslstrip (i.e. the domains of these sites were not on my browsers HSTS preload list).&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://techjots.blogspot.com/2012/11/sslstrip-on-mac-os-x-mountain-lion.html&#34;&gt;http://techjots.blogspot.com/2012/11/sslstrip-on-mac-os-x-mountain-lion.html&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Downgrade Attacks</title>
      <link>https://tlseminar.github.io/downgrade-attacks/</link>
      <pubDate>Fri, 03 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://tlseminar.github.io/downgrade-attacks/</guid>
      <description>

&lt;p&gt;Last week we learned about &lt;a href=&#34;https://tlseminar.github.io/padding-oracle/&#34;&gt;Padding Oracle Attacks&lt;/a&gt; which use side-channel information related to ciphertext message padding in order to deduce the underlying plaintext message in a TLS communication. This week we will learn about &lt;a href=&#34;https://en.wikipedia.org/wiki/Downgrade_attack&#34;&gt;Downgrade Attacks&lt;/a&gt; that force a TLS server to choose weaker encryption and protocol suit thereby making it vulnerable to attacks like man-in-the-middle.&lt;/p&gt;

&lt;p&gt;We begin with a brief introduction of Diffie-Hellman Key Exchange protocol commonly used in TLS and then describe the Logjam attack on Diffie-Hellman protocol which relies on pre-computation of discrete-logs of a 512-bit prime used in the protocol. Next we discuss about &lt;a href=&#34;#state-level-threats-to-diffie-hellman&#34;&gt;State-level Threats to Diffie-Hellman&lt;/a&gt;, where we show that the pre-computation of discrete-logs is in the reach of current academic computation power. The practical consequence is that 8% of the top 1 million websites that use HTTPS can be broken in real time.&lt;/p&gt;

&lt;p&gt;In the remainder of the article, we discuss about &lt;a href=&#34;#bleichenbacher-attack&#34;&gt;Bleichenbacher Attack&lt;/a&gt; which is a padding oracle attack on PKCS#1 v1.5 padding used in SSLv2. We conclude with &lt;a href=&#34;#drown-attack&#34;&gt;Drown Attack&lt;/a&gt; that uses Bleichenbacker attack to gain access to RSA key of a TLS communication.&lt;/p&gt;

&lt;h1 id=&#34;diffie-hellman-cryptanalysis&#34;&gt;Diffie-Hellman Cryptanalysis&lt;/h1&gt;

&lt;p&gt;Diffie-Hellman is a cryptologic method used to confidentially generate a shared secret (encryption key) between two parties in a conversation.  Because the shared secret is used to encrypt message traffic, the integrity of Diffie-Hellman is crucial to the security of TLS, where the confidentiality of communication depends heavily on the process of securely generating a shared encryption key.&lt;/p&gt;

&lt;h2 id=&#34;background-diffie-hellman-key-exchange&#34;&gt;Background: Diffie-Hellman Key Exchange&lt;/h2&gt;

&lt;p&gt;The genius of Diffie-Hellman lies in its adherence to the principle of perfect forward secrecy.  The asymmetric keys used to perform the key exchange can be deleted after the key exchange is completed, so there is no risk of a later compromise enabling an attacker to break previous traffic.  The agreed shared key is never transmitted, saved, or otherwise made observable across a communication channel, even if the adversary were to collect all encrypted data in transit and recover all material stored at the endpoints, it would still not be able to break the encryption.&lt;/p&gt;

&lt;p&gt;The mathematical underpinnings of Diffie-Hellman are relatively simple.  See the following image for an illustration of the exchange that occurs when generating a shared secret.  Note that the secret values, &lt;em&gt;a&lt;/em&gt; and &lt;em&gt;b&lt;/em&gt;, are never transmitted nor shared between Alice and Bob.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;https://i.stack.imgur.com/uYqQe.png&#34; alt=&#34;Alt&#34; /&gt;&lt;/center&gt;
&lt;center&gt;&lt;sup&gt;Image Source:  &lt;a href=&#34;https://i.stack.imgur.com/uYqQe.png&#34;&gt;https://i.stack.imgur.com/uYqQe.png&lt;/a&gt; &lt;/sup&gt;&lt;/center&gt;&lt;/p&gt;

&lt;h2 id=&#34;the-diffie-hellman-problem&#34;&gt;The Diffie-Hellman Problem&lt;/h2&gt;

&lt;p&gt;The Diffie-Hellman problem (DHP) is as follows:  Given an element \(g\) and the values \(g^x, g^y\) what is the value of \(g^{xy}\)?&lt;/p&gt;

&lt;p&gt;Clearly, if this problem were easy to solve, Diffie-Hellman would be useless, since any eavesdropping adversary could then collect both \(g^x\) and \(g^y\), compute \(g^{xy}\), and subsequently decrypt all of Alice and Bob’s communication.  The Discrete Logarithm Problem (DLP) is thus by far the most efficient means to solve DHP and requires that the eavesdropping adversary compute \(x\) given \(g\) and \(g^x\) – still believed to be a hard problem in general.  But, if \(p\) is a weak prime (as explained below), it can solved in a reasonable amount of time with available computing resources.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://delivery.acm.org/10.1145/2820000/2813707/p5-adrian.pdf?ip=128.143.136.161&amp;amp;id=2813707&amp;amp;acc=OA&amp;amp;key=B33240AC40EC9E30%2E95F2ACB8D94EAE2C%2E4D4702B0C3E38B35%2E595DDC89FD3F921D&amp;amp;CFID=905546373&amp;amp;CFTOKEN=37431812&amp;amp;__acm__=1488219223_8a00d679a8028704e982e7dce1863988&#34;&gt;Adrian et al.&lt;/a&gt; published a paper in 2015 that demonstrated a weakness in Diffie-Hellman key exchange in the Handshake Protocol of TLS. In order to perform cryptanalysis in such a situation, an attacker must solve DLP by computing arbitrary discrete log values in real-time. While it is not known how to calculate discrete logs efficiently (and believed to be hard), the attack can be accelerated using precomputation.&lt;/p&gt;

&lt;h2 id=&#34;index-calculus&#34;&gt;Index Calculus&lt;/h2&gt;

&lt;p&gt;While the logic behind the precomputation cryptanalysis is based on the General Number Field Sieve, we examine Index Calculus, a simplified version of the same concept. Index Calculus involves two steps: sieving and linear algebra. In the sieving step, the cryptanalyst chooses a multiplicative group of numbers and attempts to find numbers that factor completely over this group. We can then express these numbers as linear combinations of logs of the multiplicative group elements. By finding many such numbers, we obtain equations in terms of logs of multiplicative group elements. In the linear algebra step, we can use these equations to solve for values of the logs. This allows us to generate a database of precomputed logs.&lt;/p&gt;

&lt;h2 id=&#34;active-downgrade&#34;&gt;Active Downgrade&lt;/h2&gt;

&lt;p&gt;Using precomputed discrete logs, an attacker can perform an active downgrade attack on a TLS connection. Operating as an in-the-middle attacker, the attacker intercepts a Client Hello message and alters it to instruct the server to use export-grade Diffie-Hellman, which uses 512-bit keys rather than 1024-bit or higher, which allows the attacker to use the precomputed logs. During the Handshake Protocol, the attacker is able to solve the discrete log problem and recover the master secret of that connection. This allows the attacker to communicate directly with the client over an encrypted channel, while the client still thinks he/she is communicating with their intended server.&lt;/p&gt;

&lt;h2 id=&#34;the-logjam-attack-step-by-step&#34;&gt;The Logjam Attack: Step-by-Step&lt;/h2&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;https://cryptologie.net/upload/logjam.png&#34; alt=&#34;Alt&#34; /&gt;&lt;/center&gt;
&lt;center&gt;&lt;sup&gt;&lt;a href=&#34;https://cryptologie.net/upload/logjam.png&#34;&gt;https://cryptologie.net/upload/logjam.png&lt;/a&gt;&lt;/sup&gt;&lt;/center&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;The Client sends a &lt;code&gt;Client Hello&lt;/code&gt; message to the Server.  This includes a list of all supported ciphersuites that can be used to generate the shared secret and requests that one be selected by the Server to begin the Diffie-Hellman exchange.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The adversary intercepts the &lt;code&gt;Client Hello&lt;/code&gt; messages and alters the available ciphersuites to only include 512-bit Diffie-Hellman, then forwards the altered Client Hello to the Server.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The Server receives the &lt;code&gt;Client Hello&lt;/code&gt;.  Since only one ciphersuite is shown to be supported by the Client, the Server agrees to 512-bit Diffie-Hellman and generates a 512-bit prime \(p\) to be used in the key exchange.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The adversary intercepts the ciphersuite confirmation message from the Server and alters it to reflect the client’s original ciphersuite preference, selecting full-strength DHE.  It also eavesdrops on the Server’s Diffie-Hellman communication to discern \(g\) and \(gb\).&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The Client thinks it has received the proper Diffie-Hellman information from the Server and begins its half of the Diffie-Hellman exchange.  Note that the 512-bit prime \(p\) is still considered a valid prime for 1024-bit DHE. Meanwhile, the adversary is hard at work calculating the discrete log of \(g^b \mod p_{512}\). Multiple factors can contribute to reduce the time-complexity of this process.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Once the adversary has determined the value of \(b\), the Client and adversary begin communicating as though the adversary is the Server.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The time-complexity of precomputation using the number field sieve is entirely dependent on the prime number used; as a result, any connections using the same prime can be quickly broken.  The researchers behind Logjam detected that millions of HTTPS, SSH, and VPN servers use the same prime numbers for Diffie-Hellman key exchange, rendering supposedly-secure communications vulnerable to Logjam.&lt;/p&gt;

&lt;h2 id=&#34;weak-primes&#34;&gt;Weak Primes&lt;/h2&gt;

&lt;p&gt;Consider a prime number \(p\).  In 1978, Pohlig and Hellman demonstrated that if all factors of \(p-1\) are less than \(\log^c p\), the problem of solving the discrete logarithm \(\mod p\) is in \(P\).  In general terms, this means an attacker can greatly reduce the complexity of the discrete logarithm problem and thus conduct the Logjam attack in a shorter period of time.  We&amp;rsquo;ll demonstrate with an example using a small prime.&lt;/p&gt;

&lt;p&gt;Let \(p = 31\) and \(g = 3\).  \(g\) has order 30 → \(g^{30} = 1 \mod p\)&lt;/p&gt;

&lt;p&gt;The factors of \(30 = 2 * 3 * 5\) are too small for the prime \(p\) to be secure, allowing an attacker to convert the discrete logarithm problem \(\mod 31\) into problems \(\mod 2, 3, 5\).  With the help of the Chinese Remainder Theorem, an attacker can easily find \(x\) given \(g\) and \(g^x\).&lt;/p&gt;

&lt;p&gt;A strong prime \(p = 2q + 1\) (\(q\) is prime) avoids this problem of reducibility by ensuring that \((p-1)\div 2\) cannot be composite (and, by extension, that Pohlig-Hellman cannot obtain information from \(p\)).&lt;/p&gt;

&lt;p&gt;This puts a server that supports export-grade DH and reuses weak primes at severe risk to a motivated attack.&lt;/p&gt;

&lt;h1 id=&#34;state-level-threats-to-diffie-hellman&#34;&gt;State-Level Threats to Diffie-Hellman&lt;/h1&gt;

&lt;h2 id=&#34;current-situation&#34;&gt;Current Situation&lt;/h2&gt;

&lt;p&gt;In recent years, the general bar for internet security has raised substantially. HTTPS is now the norm for most heavily trafficked websites and is spreading through services such as Let’s Encrypt, that allow for domain owners to easily get SSL certificates for a website at no cost. In general, this trend looks positive: for key exchange protocols, stronger 768 and 1024-bit groups are now the norm rather than the exception. Individual users and institutions have also begun to better understand the need for security and IPSec Virtual Private Networks (VPNs) and SSH connects are being more broadly practiced.&lt;/p&gt;

&lt;h2 id=&#34;academic-power&#34;&gt;Academic Power&lt;/h2&gt;

&lt;p&gt;While standards have advanced and security has increased in general, cryptanalysis techniques and computational power have also increased. Although ideas such as Moore’s Law, that computing power at a certain price level effectively doubles every 18 months, the practical implications are not as often taken into account. These days, DH-512 is easily within the reach of “academic power,” that is to say, within the reach of institutions with access to midsize computing facilities or individuals who can afford a few hundred thousand dollars of computing.&lt;/p&gt;

&lt;p&gt;With recent hardware, to “crack” DH-512 takes 2.5 core-years in the sieving phase, 7.7 core-years in the linear algebra phase, but only 10 core-minutes in the descent phase. So, given a 2000-3000 core cluster, all of the phases combined except the descent phase takes about 140 hours.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;https://tlseminar.github.io/images/downgrade-attacks/dh512.png&#34; alt=&#34;DH-512 Computational Cost&#34; style=&#34;width:500px;&#34;/&gt;
&lt;br&gt;
&lt;sup&gt;&lt;a href=&#34;https://weakdh.org/weakdh-ccs-slides.pdf&#34;&gt;https://weakdh.org/weakdh-ccs-slides.pdf&lt;/a&gt;&amp;gt;&lt;/sup&gt;
&lt;br&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;However, the descent phase only takes about 70 seconds. What does this mean? That after 1 week of pre-computation, an individual calculation can be completed in about 70s. If this is combined with something called a “downgrade attack,” which will be described below, connections to about &lt;strong&gt;8%&lt;/strong&gt; of top 1 million sites that use HTTPS can be broken in real time.&lt;/p&gt;

&lt;blockquote&gt;
&lt;h3 id=&#34;sidebar-what-s-a-core-year&#34;&gt;Sidebar: What’s a Core Year?&lt;/h3&gt;

&lt;p&gt;A “core-year” is a measure of the amount of work that an average computer core can complete in a year. To give a point of reference in terms of concrete cost, a single-core Amazon EC2 instance costs about $0.02 / hours. To run that core for a year would cost about $0.02 * (24 *365) = $175. A core-day and a core-minute are defined similarly.&lt;/p&gt;

&lt;p&gt;Although it may seem like this isn’t as serious of a problem, since current practice is usually to use DH-768 or DH-1024 &amp;ndash;for example, 91.0% of IKEv2 servers support a 1024-bit connection&amp;ndash; in actuality even those are vulnerable to attack. In 2009, a new record was achieved for integer factorization with a 768 bit integer factorization completed with academic resources over the span of 2 years. This would imply that breaking DH-768 takes about 36,500 core-years in pre-computation and 2 core-days in decent. As much as this sounds, it is only a few million dollars worth, which is well within reach of both moderately-funded academics and moderately-motivated adversaries (and peanuts for an organization like the NSA).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;structural-costs&#34;&gt;Structural Costs&lt;/h2&gt;

&lt;p&gt;Ok, so a DH-768 connection can probably be broken by a non-state-level actor, but what about a DH-1024 connection? Surely that is ok? Let’s take a look at the costliness of DH-1024 in comparison to 768-bit DH. The algorithmic time complexity increases by a factor of about 1220, the space complexity by a factor of 95, leaving us with this:&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;https://tlseminar.github.io/images/downgrade-attacks/dhall.png&#34; alt=&#34;Computational cost of different DH group sizes&#34; style=&#34;width:500px;&#34;/&gt;
&lt;br&gt;
&lt;sup&gt;&lt;a href=&#34;https://weakdh.org/weakdh-ccs-slides.pdf&#34;&gt;https://weakdh.org/weakdh-ccs-slides.pdf&lt;/a&gt;&lt;/sup&gt;
&lt;br&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;Although the costs seem astronomically high, they are actually within the reach of a state-level actor. If we assume that some special purpose ASICs are developed to help speed up the sieving pre-computation such that it can be completed in one year (this would cost around $8 million), and we get access to, say, a Titan supercomputer for one year (at a cost of $122 million) to complete the linear algebra phase in one year, we find that we can complete all of our pre-computation for the small cost of $130 million dollars.  Compare this cost to the budget of a state-level actor such as the NSA: their 2012 budget was $10.5 billion, making this computation just 1% of that budget.&lt;/p&gt;

&lt;h2 id=&#34;what-s-so-good-about-breaking-one-group&#34;&gt;What’s so Good About Breaking One Group?&lt;/h2&gt;

&lt;p&gt;But, you might object, what is the value in doing this pre-computation and breaking one group? Doesn’t this just mean that the NSA can only break a couple connections per year? Unfortunately, no. As Edward Snowden said, “If performing number field sieve pre-computations for at least a small number of 1024-bit Diffie-Hellman groups is possible, breaking any key exchanges made with those groups in close to real time is no difficulty.” This is because once the pre-computations are completed for a single group, that work can then be used to crack numerous connections.&lt;/p&gt;

&lt;h2 id=&#34;ike-ipsec-vpns&#34;&gt;IKE (IPsec VPNs)&lt;/h2&gt;

&lt;p&gt;Let’s now take a step back and look at IKE, the Internet Key Exchange, which perhaps is the most vulnerable to these kinds of attacks. IKE is a protocol used, in the IPsec protocol, to create a “Security Association (SA),” which is just a set of shared security attributes between two network parties such as cryptographic algorithm being used, the algorithm mode, credentials, etc. In order to establish the SA, two parties go through a process like this:&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;https://tlseminar.github.io/images/downgrade-attacks/ike.png&#34; alt=&#34;IKE Protocol Description&#34; style=&#34;width:600px;&#34;/&gt;
&lt;br&gt;
&lt;sup&gt;&lt;a href=&#34;https://weakdh.org/weakdh-ccs-slides.pdf&#34;&gt;https://weakdh.org/weakdh-ccs-slides.pdf&lt;/a&gt;&lt;/sup&gt;
&lt;br&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;While the exact details of how the protocol works are not important, it is important to note that to perform IKE passive decryption, an adversary would have to have access to a known pre-shared key, both sides of the IKE handshake, and both the handshake traffic and ESP traffic.&lt;/p&gt;

&lt;p&gt;Also important to note is that the vast majority of IKE systems use one particular 1024-bit DH group, the Oakley Group 2, for the protocol. We find that 86.1% of IKEv1 servers and 91.0% of IKEv2 servers support Oakley Group 2, and 66.1% of IKEv1 servers and 63.9% of IKEv2 servers chose Oakley Group 2 for the protocol. This means that a state-level actor with access to the pre-shared key, both sides of the IKE handshake, and both the handshake traffic and ESP traffic would be able to &lt;strong&gt;passively decrypt 66%&lt;/strong&gt; of VPN server traffic&amp;hellip;in near real-time.&lt;/p&gt;

&lt;h2 id=&#34;show-me-the-adversary&#34;&gt;Show me the Adversary&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;Is this all hypothetical? Does any such adversary actually exist?&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;A 2012 Wired article revealed information that the NSA, several years before 2012, made an “enormous breakthrough” in its ability to cryptanalyze current public encryption. While the exact details are not known, it may be reasonable to assume that the NSA completed the pre-computation for a 1024-bit DH group, such as the Oakley Group 2, allowing them passive decrypted access to a swath of internet traffic.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;https://tlseminar.github.io/images/downgrade-attacks/impact.png&#34; alt=&#34;Impact of a break&#34;/&gt;
&lt;sup&gt;&lt;a href=&#34;https://weakdh.org/weakdh-ccs-slides.pdf&#34;&gt;https://weakdh.org/weakdh-ccs-slides.pdf&lt;/a&gt;&lt;/sup&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;The impact of such a break to IKE has already been noted. Other protocols would also be vulnerable to the break. SSH, for example, supports Oakley Group 2, Oakley Group 14, or a server-defined group that is negotiated through a DH-GEX handshake. According to recent data, 21.8% of servers prefer Oakley Group 2, and 37.4% prefer the server-defined group. However, of that 37.4%, almost all of them just provided Oakley Group 2 rather than a real custom group. Thus, a state-level attacker that performed the break could passively eavesdrop on connections to 25.7% of all publicly accessible SSH servers.&lt;/p&gt;

&lt;p&gt;Unfortunately, HTTPS connections are similarly affected. Of the top 1 million site that support DHE, 84% use a 1024-bit or smaller group, and 94% of those use one of five common groups. Thus, 17.9% of connections to the top 1 million sites could be passively eavesdropped with the pre-computation for a single 1024-bit prime.&lt;/p&gt;

&lt;h2 id=&#34;mitigations&#34;&gt;Mitigations&lt;/h2&gt;

&lt;p&gt;Is there any hope that a connection can really be secure given this information? Luckily, some mitigations can be put into place. First, servers can move to using elliptic curve cryptography (ECC). A transition to a elliptic curve Diffe-Hellman key exchange (ECDH) with appropriate parameters would thwart all known feasible cryptanalytic attacks as ECC discrete log algorithms don&amp;rsquo;t gain too much advantage from precomputation. When ECC is not an option, it is recommended that primes at least 2048 bits in length be used. It would be ideal if browser vendors and clients raise the minimum accepted size for DH groups to at least 1024 bits. If large primes are not supported, then always use a fresh 1024-bit group to mitigate the efficacy of precomputation-based attacks. It is parameter reuse that allows state-level attackers to easily perform wide-scale passive decryption.&lt;/p&gt;

&lt;h1 id=&#34;bleichenbacher-s-padding-oracle-attack&#34;&gt;Bleichenbacher’s Padding Oracle Attack&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://archiv.infsec.ethz.ch/education/fs08/secsem/Bleichenbacher98.pdf&#34;&gt;Bleichenbacher’s padding oracle attack&lt;/a&gt;  is an adaptive chosen ciphertext attack against PKCS#1 v1.5, the RSA padding standard used in SSL and TLS. It enables decryption of RSA ciphertexts if a server distinguishes between correctly and incorrectly padded RSA plaintexts, and was termed the “million-message attack” upon its introduction in 1998, after the number of decryption queries needed to deduce a plaintext. All widely used SSL/TLS servers include countermeasures against Bleichenbacher attacks.&lt;/p&gt;

&lt;h2 id=&#34;pkcs-1-v1-5-encryption-padding&#34;&gt;PKCS#1 v1.5 encryption padding&lt;/h2&gt;

&lt;p&gt;Bleichenbacher’s padding oracle attack relies on the structure of &lt;a href=&#34;https://tools.ietf.org/html/rfc2313&#34;&gt;RSA PKCS#1 v1.5 padding&lt;/a&gt;. Although RSA PKCS#1 v2.0 implements OAEP, SSL/TLS still uses PKCS#1 v1.5. The PKCS#1 v1.5 encryption padding scheme randomizes encryptions by prepending a random padding string PS to a message &lt;em&gt;k&lt;/em&gt; (here, a symmetric session key) before RSA encryption:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;The plaintext message is &lt;em&gt;k&lt;/em&gt;, \(l_k = |k|\).
The encrypter generates a random byte string PS,
where |PS| ≥ 8, \(|PS| = l_m − 3 − l_k \) and &lt;code&gt;0x00&lt;/code&gt; \( \notin{PS[1],&amp;hellip;,PS[|PS|]}\)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The encryption block is \(m =\) &lt;code&gt;00&lt;/code&gt; || &lt;code&gt;02&lt;/code&gt; || \(PS\) || &lt;code&gt;00&lt;/code&gt; || \(k\)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The ciphertext is computed as \(c = m^e\mod{N}\).
To decrypt such a ciphertext, the decrypter first computes \(m = c^d \mod{N}\). Then it checks whether the decrypted message m is correctly formatted as a PKCS#1 v1.5-encoded message. We say that the ciphertext c and the decrypted message bytes \(m[1]||m[2]||&amp;hellip;||m[l_m]\) are PKCS#1 v1.5 conformant if:&lt;/p&gt;

&lt;p&gt;\( \qquad m[1] || m[2] = \) &lt;code&gt;0x00&lt;/code&gt; || &lt;code&gt;0x02&lt;/code&gt; and &lt;code&gt;0x00&lt;/code&gt; \(\notin {m[3],&amp;hellip;,m[10]} \)&lt;/p&gt;

&lt;p&gt;If this condition holds, the decrypter searches for the first value &lt;em&gt;i&lt;/em&gt; &amp;gt; 10 such that \(m[i] =\) &lt;code&gt;0x00&lt;/code&gt;. Then, it extracts \(k = m[i+1]||&amp;hellip;||m[l_m]\). Otherwise, the ciphertext is rejected.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;In SSLv3 and TLS, RSA PKCS#1 v1.5 is used to encapsulate the premaster secret exchanged during the handshake. Thus, &lt;em&gt;k&lt;/em&gt; is interpreted as the premaster secret. In SSLv2, RSA PKCS#1 v1.5 is used for encapsulation of an equivalent key denoted the &lt;em&gt;master_key&lt;/em&gt;.&lt;/p&gt;

&lt;h2 id=&#34;bleichenbacher-attack&#34;&gt;Bleichenbacher attack&lt;/h2&gt;

&lt;p&gt;Bleichenbacher’s attack is a padding oracle attack; it exploits the fact that RSA ciphertexts should decrypt to PKCS#1 v1.5-compliant plaintexts. If an implementation receives an RSA ciphertext that decrypts to an invalid PKCS#1 v1.5 plaintext, it might naturally leak this information via an error message, by closing the connection, or by taking longer to process the error condition. This behavior can leak information about the plaintext that can be modeled as a cryptographic oracle for the decryption process. Bleichenbacher demonstrated how such an oracle could be exploited to decrypt RSA ciphertexts.&lt;/p&gt;

&lt;h2 id=&#34;algorithm&#34;&gt;Algorithm&lt;/h2&gt;

&lt;p&gt;In the simplest attack scenario, the attacker has a valid PKCS#1 v1.5 ciphertext \(c_0\) that they wish to decrypt to discover the message m0. They have no access to the private RSA key, but instead have access to an oracle, \(\delta\), that will decrypt a ciphertext &lt;em&gt;c&lt;/em&gt; and inform the attacker whether the most significant two bytes match the required value for a correct PKCS#1 v1.5 padding:&lt;br /&gt;
&lt;center&gt;
\( \delta (c) = 1 \) if  \(m = c^d \mod{N} \) starts with &lt;code&gt;0x00~02 0&lt;/code&gt;
$$ \delta (c) = 0 \textrm{ otherwise}.$$
&lt;/center&gt;
If the oracle answers with 1, the attacker knows that \(2B ≤ m ≤ 3B−1\), where \(B = 2^{8(l_m−2)}\).&lt;/p&gt;

&lt;p&gt;The attacker can take advantage of RSA malleability to generate new candidate
ciphertexts for any s:&lt;/p&gt;

&lt;p&gt;$$c = (c_0 · s_e)\mod{N} = {m_0 ·s}^e \mod{N}$$&lt;/p&gt;

&lt;p&gt;The attacker queries the oracle with &lt;em&gt;c&lt;/em&gt;. If the oracle responds with 0, the attacker increments &lt;em&gt;s&lt;/em&gt; and repeats the previous step. Otherwise, the attacker learns that for some &lt;em&gt;r&lt;/em&gt;, \(2B ≤ m_{0}s−rN &amp;lt; 3B\). This allows the attacker to reduce the range of possible solutions to:&lt;/p&gt;

&lt;p&gt;$$ \frac{2B+rN}{s} ≤ m_0 &amp;lt; \frac{3B+rN}{s} $$&lt;/p&gt;

&lt;p&gt;The attacker proceeds by refining guesses for &lt;em&gt;s&lt;/em&gt; and &lt;em&gt;r&lt;/em&gt; values and successively decreasing the size of the interval containing \(m_0\). At some point the interval will contain a single valid value, \(m_0\). &lt;a href=&#34;http://archiv.infsec.ethz.ch/education/fs08/secsem/bleichenbacher98.pdf&#34;&gt;Bleichenbacher’s original paper&lt;/a&gt; describes this process in further detail.&lt;/p&gt;

&lt;p&gt;It is worth noting that the author implemented a proof-of-concept of this attack on a custom padding oracle implementation. Over a test set of various 512-bit and 1024-bit keys, between 300,000 and 2 million ciphertexts were required to find the message. While the details of the custom oracle are not known, it is reasonable to assume that this attack is feasible in more realistic scenarios.&lt;/p&gt;

&lt;h2 id=&#34;countermeasures&#34;&gt;Countermeasures&lt;/h2&gt;

&lt;p&gt;In order to protect against this attack, the reciever must not leak information about the PKCS#1 v1.5 validity of the ciphertext. The ciphertext does not decrypt to a valid message, so the decrypter generates a fake plaintext and continues the protocol with this decoy. The attacker should not be able to distinguish the resulting computation from a correctly decrypted ciphertext.  In the case of SSL/TLS, the server generates a random premaster secret to continue the handshake if the decrypted ciphertext is invalid. The client will not possess the session key to send a valid ClientFinished message and the connection will terminate.&lt;/p&gt;

&lt;p&gt;In addition, newer versions of &lt;a href=&#34;https://tools.ietf.org/html/rfc3447&#34;&gt;PKSC#1&lt;/a&gt; describe a new padding type, called OAEP, which uses hash function to add more internal redundancy. This greatly decreases the probability that random strings will result in valid padding, effectively preventing the attack.&lt;/p&gt;

&lt;h2 id=&#34;sources-of-further-reading&#34;&gt;Sources of Further Reading&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://secgroup.dais.unive.it/wp-content/uploads/2012/11/Practical-Padding-Oracle-Attacks-on-RSA.html&#34;&gt;Padding Oracle Attacks on RSA&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://cryptopals.com/sets/6/challenges/47&#34;&gt;Cryptopals Crypto Challenge&lt;/a&gt;: A Do-It-Yourself excercise on Bleichenbacher attack.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://hal.inria.fr/hal-00691958/document&#34;&gt;Efficient padding oracle attacks on cryptographic hardware&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;drown-breaking-tls-using-sslv2&#34;&gt;DROWN: Breaking TLS using SSLv2&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://tlseminar.github.io/docs/drown.pdf&#34;&gt;Paper Link&lt;/a&gt;
| &lt;a href=&#34;https://drownattack.com/&#34;&gt;Website&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;DROWN attack is inspired by &lt;a href=&#34;#bleichenbacher-attack&#34;&gt;Bleichenbacher’s padding oracle attack&lt;/a&gt; over SSLv2 which could decrypt an SSLv2 RSA ciphertext. The attack was possible due to a flaw in SSLv2 protocol which revealed if the decrypted message was conformant with PKCS#1 v1.5 padding or not, thus acting as a &lt;a href=&#34;https://tlseminar.github.io/padding-oracle/&#34;&gt;padding oracle&lt;/a&gt;. The padding scheme is shown below where first two bytes are fixed &lt;code&gt;0x00 0x02&lt;/code&gt; followed by 8 bytes of random padding string succeeded by a &lt;code&gt;0x00&lt;/code&gt; byte. The remaining part of the message is the plaintext which may contain the key to be recovered. The padding scheme is shown below:&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;https://tlseminar.github.io/images/downgrade-attacks/pkcs1padding.png&#34; alt=&#34;PKCSPadding&#34; style=&#34;width:500px;&#34;/&gt;&lt;br&gt;
&lt;sup&gt;PKCS#1 v1.5 Padding Scheme &lt;/sup&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;The client in SSLv2 protocol sends ClientMasterKey message to SSLv2 server which the server decrypts and responds with ServerVerify message which tells whether the ClientMasterKey message was conformant with the padding scheme.&lt;/p&gt;

&lt;p&gt;The figure below depicts the SSLv2 protocol. The attacker can modify the original ClientMasterKey message and if the SSLv2 server confirms the padding, the attacker would immediately get to know that the first two bytes of the modified message is ‘0x00 0x02’. This way, the attacker can repeatedly modify the original message and query the oracle. After multiple successful guesses for modified message, the attacker can narrow down the guesses for the original message and recover the &lt;em&gt;master_key&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;https://tlseminar.github.io/images/downgrade-attacks/sslv2flaw.png&#34; alt=&#34;SSLv2Flaw&#34; style=&#34;width:500px;&#34;/&gt;&lt;br&gt;
&lt;sup&gt;Flaw in SSLv2 protocol where the server reveals the correctness of padding &lt;br&gt;
Source: &lt;a href=&#34;https://tlseminar.github.io/docs/drown.pdf&#34;&gt;https://tlseminar.github.io/docs/drown.pdf&lt;/a&gt;&lt;/sup&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;Moreover, SSLv2 allowed export-grade ciphersuites which supported 40-bit key. A Bleichenbacher attacker could brute-force the key by repeatedly querying the SSLv2 server.&lt;/p&gt;

&lt;p&gt;TLS patched the above flaws and (most) servers made the SSLv2 protocol obsolete. However, it was not uncommon for TLS servers to share same RSA keys with SSLv2 servers. This made the TLS servers vulnerable to a modified form of Bleichenbacher attack which uses a SSLv2 server as padding oracle to decrypt the shared RSA key. DROWN instantiated this protocol-level attack and decrypted a TLS 1.2 handshake using 2048-bit RSA in 8 hours at a cost of $440 on Amazon EC2. As if this wasn&amp;rsquo;t devastating enough, the authors of DROWN pointed out some implementation bugs in OpenSSL which lead to another attack called Special DROWN that could decrypt a TLS ciphertext in under 1 minute using a single CPU. Both the attacks are described below.&lt;/p&gt;

&lt;h2 id=&#34;drown-attack&#34;&gt;DROWN Attack&lt;/h2&gt;

&lt;p&gt;DROWN attack requires that a TLS server and a SSLv2 server share an RSA key. The attacker records multiple TLS handshake messages between a client and the TLS server. The aim of the attacker is to decrypt the RSA key of the TLS handshake. To do so, the attacker forces the client to establish a connection with an SSLv2 server having the same RSA key so that the attacker can initiate the Bleichenbacher attack to recover the RSA key.&lt;/p&gt;

&lt;p&gt;Now the main hurdle for the attacker is that the format of TLS handshake message may not comply with PKCS#1 v1.5 padding scheme of SSLv2. The attacker converts the TLS ciphertext to SSLv2 ciphertext using the concept of trimmers introduced by &lt;a href=&#34;https://hal.inria.fr/hal-00691958/document&#34;&gt;Bardou et al.&lt;/a&gt; which reduces the size of the TLS message. The use of trimmers require repeated querying to SSLv2 server by shifting the message bytes. The recovered SSLv2 plaintext is then converted back to TLS plaintext which reveals the RSA key of TLS handshake.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;https://tlseminar.github.io/images/downgrade-attacks/drownattack.png&#34; alt=&#34;DROWN&#34; style=&#34;width:500px;&#34;/&gt;&lt;br&gt;
&lt;sup&gt;SSLv2-based Bleichenbacher attack on TLS &lt;br&gt;
Source: &lt;a href=&#34;https://tlseminar.github.io/docs/drown.pdf&#34;&gt;https://tlseminar.github.io/docs/drown.pdf&lt;/a&gt;&lt;/sup&gt;&lt;/center&gt;&lt;/p&gt;

&lt;h2 id=&#34;special-drown-attack&#34;&gt;Special DROWN Attack&lt;/h2&gt;

&lt;p&gt;The OpenSSL implementation had two bugs which led to a more efficient Bleichenbacher attack on an OpenSSL implementation of SSLv2 server.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;OpenSSL extra clear oracle:&lt;/b&gt; OpenSSL implementation allowed non-export cipher messages to contain &lt;em&gt;clear_key_data&lt;/em&gt; which lead to potential overwriting of key bytes with null bytes. An attacker could vary the number of null bytes to decrypt the whole key one byte at a time.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;OpenSSL leaky export oracle:&lt;/b&gt; OpenSSL in export cipher mode allowed valid oracle response for correctly padded message of ‘any’ length.&lt;/p&gt;

&lt;p&gt;These bugs remained in OpenSSL implementation from 1998 up until its patch in 2015, when the authors of DROWN contacted the OpenSSL developers.&lt;/p&gt;

&lt;h2 id=&#34;prevention-of-drown&#34;&gt;Prevention of DROWN&lt;/h2&gt;

&lt;p&gt;The attack is successful mainly because of the reliance on obsolete cryptographic practices. Export-grade ciphers only support 40-bit keys which are vulnerable to brute-force attack and hence it is crucial to disable export-grade ciphers and use safer ciphers (like &lt;a href=&#34;https://tools.ietf.org/html/rfc5288&#34;&gt;AES_GCM&lt;/a&gt;) with longer key lengths (256-bits). PKCS#1 v1.5 padding leaks significant byte patterns and hence a better padding technique should be used. SSLv2 protocol includes the above obsolete cryptos and hence it should be scrapped and replaced with TLS 1.3. Lastly, the RSA public keys should not be shared among multiple servers or connections in order to deter the attack.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Padding Oracle Attacks</title>
      <link>https://tlseminar.github.io/padding-oracle/</link>
      <pubDate>Tue, 31 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://tlseminar.github.io/padding-oracle/</guid>
      <description>

&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://tlseminar.github.io/https://tlseminar.github.io/first-few-milliseconds/&#34;&gt;Last week&lt;/a&gt;, we
examined how the Transport Layer Security (TLS) protocol provides a
private channel between two devices by following the handshake and
record layers protocols. The handshake layer establishes a symmetric
key that both the client and the server could use in the record layer
to encrypt and decrypt messages.&lt;/p&gt;

&lt;p&gt;This week, we&amp;rsquo;ll discuss a real-world TLS attack, the Padding Oracle
Attack, that takes advantage of our need for each message to be a
particular set length. If the original message is not long enough,
then we have to add padding for the &lt;a href=&#34;https://tlseminar.github.io/docs/analysisssl3.pdf&#34;&gt;CBC Mode
Encryption&lt;/a&gt; to
work. Because the padding is present, an attacker can chip away
information on the
&lt;a href=&#34;https://tlseminar.github.io/docs/beast.pdf&#34;&gt;ciphertext&lt;/a&gt;, one byte at
a time, through analyzing the receiver’s error messages for the
sender, &lt;a href=&#34;http://www.isg.rhul.ac.uk/tls/TLStiming.pdf&#34;&gt;response time&lt;/a&gt;,
and general behavior.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll start out by learning about how &lt;a href=&#34;https://tlseminar.github.io/docs/analysisssl3.pdf&#34;&gt;CBC Mode
Encryption&lt;/a&gt; works.&lt;/p&gt;

&lt;h1 id=&#34;padding-and-cbc-mode&#34;&gt;Padding and CBC Mode&lt;/h1&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://tlseminar.github.io/docs/analysisssl3.pdf&#34;&gt;&lt;em&gt;Analysis of the SSL 3.0 Protocol&lt;/em&gt;&lt;/a&gt; by David Wagner and Bruce Schneider (1997)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;When AES-128 encryption is performed in cipher block chaining mode
(CBC mode), the plaintext message is first split up into 16-byte
(128-bit) blocks. It is often the case, however, that the length of
the message is not perfectly divisible by 16. To account for varying
message sizes, extra bytes, called padding, are concatenated after the
end of the message to fill up the remaining quota for the final block.&lt;/p&gt;

&lt;p&gt;These bytes are not chosen at random, however, and different cipher
modes prescribe different padding methods. In order to clearly mark
for the recipient where the message ends and the padding begins, the
padding follows a strict formatting pattern. With PKCS #5 padding as
used in TLS, if there are &lt;em&gt;n&lt;/em&gt; bytes of padding, then each padding byte
contains the value &lt;em&gt;n&lt;/em&gt;. For instance, if the last block contains 15
message bytes, the 1-byte padding contains &lt;code&gt;0x01&lt;/code&gt;; if the last block
contains 14 message bytes, the 2-byte padding contains &lt;code&gt;0x0202&lt;/code&gt;;
3-byte padding contains &lt;code&gt;0x030303&lt;/code&gt;; and so on.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;https://tlseminar.github.io/images/paddingoracle/padding.png&#34; alt=&#34;Padding&#34;&gt;&lt;Br&gt;
&lt;span class=&#34;caption&#34;&gt;&lt;em&gt;Source: &lt;/em&gt;&lt;a href=&#34;https://blog.gdssecurity.com/labs/2010/9/14/automated-padding-oracle-attacks-with-padbuster.html&#34;&gt;Gotham Digital Science&lt;/a&gt;&lt;/span&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;In CBC mode, the bytes of each plaintext block n are first XOR’ed with
the encrypted bytes of the block before it, and their result is then
encrypted. Block 1 is the obvious exception, which is XOR’ed with a
fixed, random, or secret initialization vector (IV). Thus, for any
block &lt;em&gt;n&lt;/em&gt; &amp;gt; 1, where E&lt;sub&gt;&lt;em&gt;k&lt;/em&gt;&lt;/sub&gt; is the encryption function,
&lt;em&gt;c&lt;/em&gt;&lt;sub&gt;&lt;em&gt;n&lt;/em&gt;&lt;/sub&gt; is the encrypted block &lt;em&gt;n&lt;/em&gt;, &lt;em&gt;p&lt;/em&gt;&lt;sub&gt;&lt;em&gt;n&lt;/em&gt;&lt;/sub&gt; is the plaintext
block &lt;em&gt;n&lt;/em&gt;, and &lt;em&gt;c&lt;/em&gt;&lt;sub&gt;&lt;em&gt;n&lt;/em&gt;-1&lt;/sub&gt; is the encrypted block &lt;em&gt;n&lt;/em&gt;-1:
&lt;center&gt;
&lt;em&gt;c&lt;/em&gt;&lt;sub&gt;&lt;em&gt;n&lt;/em&gt;&lt;/sub&gt; = E&lt;sub&gt;&lt;em&gt;k&lt;/em&gt;&lt;/sub&gt; (&lt;em&gt;p&lt;/em&gt;&lt;sub&gt;&lt;em&gt;n&lt;/em&gt;&lt;/sub&gt;⊕ &lt;em&gt;c&lt;/em&gt;&lt;sub&gt;&lt;em&gt;n&lt;/em&gt;-1&lt;/sub&gt;)
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;https://tlseminar.github.io/images/paddingoracle/cbc.png&#34; alt=&#34;cbc-mode&#34; /&gt;&lt;br&gt;
&lt;span class=&#34;caption&#34;&gt;&lt;em&gt;Source: &lt;/em&gt;&lt;a href=&#34;https://www.cs.rit.edu/~ark/fall2012/482/module05/CbcEncrypt.png&#34;&gt;Alan Kaminsky&lt;/a&gt;&lt;/span&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;However, the predictability of the padding format can turn out to be
an extremely exploitable weakness for an active attacker. Under
SSL/TLS protocol, when servers receive an encrypted message, their
first step upon decryption is to check the validity of the padding;
that is, determine if the numbers at the end of the last block
represent the number of padding bytes. As soon as this step is
completed, the server will return to the sender either an error code
or an acknowledgment that the padding is valid. In this way, the
server acts as an oracle to an active attacker, providing them with
confirmations/rejections to inform their guesses.&lt;/p&gt;

&lt;h1 id=&#34;padding-oracle-attack&#34;&gt;Padding Oracle Attack&lt;/h1&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;http://www.iacr.org/cryptodb/archive/2002/EUROCRYPT/2850/2850.pdf&#34;&gt;&lt;em&gt;Security Flaws Induced by CBC Padding Applications to SSL, ISPEC, WTLS&amp;hellip;&lt;/em&gt;&lt;/a&gt; by Serge Vaudenay&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;To begin, the attacker creates a Last Word Oracle. This first assumes
a 1-byte padding, so the format that the oracle would return as valid
is &lt;code&gt;0x01&lt;/code&gt; XOR’ed with some particular value in the corresponding last
position in the &lt;em&gt;n&lt;/em&gt;-1th block. Since the last byte, or word, can have
256 distinct values, the attacker can simply manipulate the &lt;em&gt;n&lt;/em&gt;-1th
block, easily testing all values, until either the possibilities are
exhausted or the padding is returned as valid. If the possibilities
are exhausted, then the attacker instead tries &lt;code&gt;0x02&lt;/code&gt;, then &lt;code&gt;0x03&lt;/code&gt;,
and on until the padding returned is valid.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;https://tlseminar.github.io/images/paddingoracle/last-word.png&#34; alt=&#34;LastWordOracle&#34; /&gt;&lt;br&gt;
&lt;span class=&#34;caption&#34;&gt;&lt;em&gt;Source: &lt;/em&gt;&lt;a href=&#34;https://www.rsaconference.com/writable/presentations/file_upload/asec-403.pdf&#34;&gt;Brian Holyfield, Gotham Digital Science&lt;/a&gt;&lt;/span&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;Once the attacker has learned the padding, a Block Decryption Oracle
is constructed, using the values of the encrypted &lt;em&gt;n&lt;/em&gt;-1th block to,
byte by byte, guess the preceding byte, using the oracle’s pass/fail
responses to confirm correct guesses. This method is then extended to
decrypt all other blocks, as it is called on pairs containing a random
block and a ciphertext block. (Again, the logical exception is the
first block, assuming an independent initialization vector.) This is a
terrifyingly efficient attack; to implement it, the attacker only
needs (&lt;em&gt;b&lt;/em&gt; * &lt;em&gt;W&lt;/em&gt; * &lt;em&gt;N&lt;/em&gt;)/2 trials, where &lt;em&gt;b&lt;/em&gt; is the number of bytes per block,
&lt;em&gt;W&lt;/em&gt; is the number of possible bytes, and &lt;em&gt;N&lt;/em&gt; is the number of blocks.&lt;/p&gt;

&lt;p&gt;With the CBC Padding now added to the original ciphered message,
attackers can alter this new message with blockwise operations in
order to draw information out of the originally unreadable
ciphertext. This information could potentially end up being
authentication tokens, such as cookies, granting attackers personally
identifiable information or the potential to hijack previous sessions.&lt;/p&gt;

&lt;h1 id=&#34;beast-plaintext-attacks-against-ssl&#34;&gt;BEAST: Plaintext Attacks Against SSL&lt;/h1&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://tlseminar.github.io/docs/beast.pdf&#34;&gt;&lt;em&gt;Here Come The \(\oplus\) Ninjas&lt;/em&gt;&lt;/a&gt; by Thai Duong and Juliano Rizzo (2011)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In CBC block encryption, each plaintext block is XORed with the
ciphertext of the previous block before being encrypted. An attempted
guess at a plaintext block can be evaluated by encrypting the
ciphertext prior to the block in question XORed with the ciphertext
prior to the current block XORed with the guess; if the new ciphertext
matches that of the block in question, then the guess is
correct:
&lt;center&gt;
C&lt;sub&gt;&lt;em&gt;j&lt;/em&gt;&lt;/sub&gt; = E&lt;sub&gt;&lt;em&gt;k&lt;/em&gt;&lt;/sub&gt;(P&lt;sub&gt;&lt;em&gt;j&lt;/em&gt;&lt;/sub&gt; ⊕ C&lt;sub&gt;&lt;em&gt;j&lt;/em&gt;-1&lt;/sub&gt;), so, C&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sub&gt;==C&lt;sub&gt;&lt;em&gt;j&lt;/em&gt;&lt;/sub&gt; iff P&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sub&gt; == P&lt;sub&gt;&lt;em&gt;j&lt;/em&gt;&lt;/sub&gt; ⊕ C&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;-1&lt;/sub&gt; ⊕ C&lt;sub&gt;&lt;em&gt;j&lt;/em&gt;-1&lt;/sub&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;Guess G can be evaluated as equal to or unequal to plaintext
P&lt;sub&gt;j&lt;/sub&gt; by setting P&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sub&gt;=G ⊕ C&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;-1&lt;/sub&gt; ⊕
C&lt;sub&gt;&lt;em&gt;j&lt;/em&gt;-1&lt;/sub&gt; and checking whether or not C&lt;sub&gt;&lt;em&gt;j&lt;/em&gt;&lt;/sub&gt; ==
C&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sub&gt;. An attacker would need to be able to view the
encrypted messages and query the underlying CBC encryption system to
be able to mount an attack based on this exploit.&lt;/p&gt;

&lt;p&gt;Cryptographic systems are limited in their size and ability to store
large plaintext messages, for this reason, most cryptographic systems
encrypt messages block by block as they are sent. In the case where an
attacker can append padding to a message before it is encrypted, an
attacker can mount a blockwise chosen-boundary attack, in which the
first byte of an unknown message is isolated by padding, enabling the
attacker to guess at single bytes of a message rather than block-sized
chunks.&lt;/p&gt;

&lt;p&gt;The natural extension of this is to repeat the process such that once
a byte of message has been guessed by the attacker, the padding is
changed such that a single unknown byte of message is encrypted with
padding and bytes known to the attacker, allowing them to continue
guessing at single bytes of information.&lt;/p&gt;

&lt;p&gt;Duong and Rizzo go on to describe the process whereby this attack
could be mounted on HTTPS to obtain a user’s HTTP cookie. The attack
only requires that an attacker can view encrypted messages, can cause
the client to make arbitrary encrypted requests, and that arbitrary
plaintext can be added to out-going requests. In the described attack,
the user is made to request a package with a padded end such that the
first byte of unknown information in the request is isolated in an
encryption with only public information. The attacker then makes
guesses at that byte of information, appending plaintext to the
request and watching the encrypted channel for a message block that
matches the block containing the unknown byte of information. At that
point, the guess that resulted in that message block is identified as
the correct guess. The process is then repeated with a smaller padding
until the user’s request header (including their HTTPS cookies) is
revealed to the attacker.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;https://tlseminar.github.io/images/paddingoracle/beast.png&#34; alt=&#34;beast&#34; /&gt;&lt;br&gt;
&lt;span class=&#34;caption&#34;&gt;&lt;em&gt;Figure: &lt;/em&gt;Attacker (Mallory) is able to sniff encrypted traffic, force Alice to send cookie-bearing HTTP requests, and insert forged plaintexts in the conversation.&lt;/span&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;There are a few issues mentioned associated with this attack, but by
using one of a variety of plugins, an attacker could make the user
open bi-directional communication with the server. On this
communication channel, the privileges required by the attacker to
mount the attack would be easier to gain.&lt;/p&gt;

&lt;h1 id=&#34;lucky-13-plaintext-recovery-from-injected-ciphertext&#34;&gt;Lucky 13: Plaintext Recovery from Injected Ciphertext&lt;/h1&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;http://www.isg.rhul.ac.uk/tls/TLStiming.pdf&#34;&gt;&lt;em&gt;Lucky Thirteen: Breaking the TLS and DTLS Record Protocols&lt;/em&gt;&lt;/a&gt; by Nadhem J. Alfardan and Kenneth G. Paterson (2013)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Similar in the vein of the BEAST attack using bitwise XOR operations
to glean useful plaintext information, Lucky Thirteen offers yet
another alternative means to get partial or even full plaintext
recovery with just a simple man-in-the-middle injecting ciphertext
into the original ciphertext. Based on analyzing how TLS and DTLS
decrypt a given ciphertext, these attacks also rely on CBC-mode
weaknesses.&lt;/p&gt;

&lt;p&gt;The Lucky 13 attack relies on a timing channel introduced by the
difference in processing time between TLS records with correct and
incorrect padding, requiring only a standard in-the-middle attacker
for execution and providing recovered plaintext in the most severe
case.  This would indicate a major security flaw, even in comparison
to the aforementioned BEAST attack. BEAST required capabilities beyond
simple MITM on the part of the attacker.  As a result, the authors of
the paper disclosed their results to all major vendors to allow for
patching before publishing.&lt;/p&gt;

&lt;p&gt;The name “Lucky 13” is a reference to a specific breakpoint in the
size of the padding on a given message.  Both TLS and DTLS use the
HMAC algorithm to compute MAC tags for messages.  HMAC operates using
a compression function on messages with lengths equal to multiples of
64 bytes, so TLS and DTLS pad out messages with remaining space.&lt;/p&gt;

&lt;p&gt;After subtracting 8 bytes for the length field and 1 byte of mandatory
padding, we are left with a maximum message length of 55 bytes that
can be encoded within one block.  This means that messages less than
55 bytes can be processed with only four compression function
evaluations, and that in general the number of compressions is equal
to&lt;/p&gt;

&lt;p&gt;$$\left\lceil\frac{L-55}{64}\right\rceil+4$$&lt;/p&gt;

&lt;p&gt;for messages of &lt;em&gt;L&lt;/em&gt; bytes.  The compression function is relatively expensive, so the difference between 4 and 5 iterations is distinguishable in good conditions.  It is also possible to submit multiple requests as described below to amplify the differences if necessary.&lt;/p&gt;

&lt;p&gt;The authors detail first a distinguishing attack, and then a variation allowing for full plaintext recovery.  All attacks rely on the timing channel.  Specifically, the authors describe in detail how it is possible to place a target ciphertext block at the end of an encrypted record, causing the decryption function to interpret the plaintext block corresponding to the ciphertext block as padding.  Thus the amount of time required to process that block depends on plaintext bytes, leaking information.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;https://tlseminar.github.io/images/paddingoracle/timing.png&#34; alt=&#34;lucky-thirteen&#34; /&gt;&lt;Br&gt;
&lt;span class=&#34;caption&#34;&gt;&lt;em&gt;Figure:&lt;/em&gt; Graph showing the differences in timing due to the number of compressions necessary for varying lengths of bytes.&lt;br&gt;&lt;em&gt;Source: &lt;/em&gt;&lt;a href=&#34;http://www.isg.rhul.ac.uk/tls/TLStiming.pdf&#34;&gt;http://www.isg.rhul.ac.uk/tls/TLStiming.pdf&lt;/a&gt;
&lt;/span&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;h1 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;Through these readings and their respective explanations, we see that
cryptographic protocols are often broken and need to be patched. There
is always some threat model out there looking to exploit the first
sign of weakness to decrypt and listen in on what should be a secure,
encrypted channel. Through this last week, we focused on looking at
padding oracle attacks which take advantage of the padding on the
respective blocks in a CBC chain as they are passed from operation to
operation. With the last word oracle and the BEAST attack, we saw how
important this padding was to the security of the whole
operation. With our look at Lucky 13, we were able to see that people
were able to exploit the fact that one extra compression had to be
done in certain situations to glean information about the message. As
such, we see just from the padding, we have so many attacks.&lt;/p&gt;

&lt;p&gt;There are so many aspects to SSL/TLS protocols that so many more
exploits exist. So, what are ways that we can prevent these attacks?
With the padding attacks, we saw that they tried standardizing error
messages (but, why not just encrypt the message and send it
back?). Should our strategy just be to move as quickly to the newest
version of the security protocols? Should we add the MAC to the
messages after encryption?&lt;/p&gt;

&lt;p&gt;TLS 1.3 (the most recent release) has been drafted (and in the process
of release) and has resolved many of these issues that have exploited
weaknesses present in older versions of the protocol. However, its
adoption rate has been very low and so it is important to bring this
up as more and more operations should be moved over to TLS 1.3, as
this seems to be the most secure system we have available right now
and thus should be adopted.&lt;/p&gt;

&lt;h1 id=&#34;sources&#34;&gt;Sources&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://tlseminar.github.io/docs/analysisssl3.pdf&#34;&gt;https://tlseminar.github.io/docs/analysisssl3.pdf&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.iacr.org/cryptodb/archive/2002/EUROCRYPT/2850/2850.pdf&#34;&gt;http://www.iacr.org/cryptodb/archive/2002/EUROCRYPT/2850/2850.pdf&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://tlseminar.github.io/docs/beast.pdf&#34;&gt;https://tlseminar.github.io/docs/beast.pdf&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.isg.rhul.ac.uk/tls/TLStiming.pdf&#34;&gt;http://www.isg.rhul.ac.uk/tls/TLStiming.pdf&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The First Few Milliseconds of an TLS 1.2 Connection</title>
      <link>https://tlseminar.github.io/first-few-milliseconds/</link>
      <pubDate>Thu, 26 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://tlseminar.github.io/first-few-milliseconds/</guid>
      <description>

&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;

&lt;p&gt;In 2009, Jeff Moser published &lt;a href=&#34;http://www.moserware.com/2009/06/first-few-milliseconds-of-https.html&#34;&gt;an excellent article&lt;/a&gt; on the first few milliseconds of an HTTP request. It described in detail how TLS 1.0 connections are established, including a great description of RSA. We&amp;rsquo;ve attempted to build and adapt upon that article here by describing how the process works for a TLS 1.2 connection. As of January 2nd 2017, TLS 1.2 has roughly &lt;a href=&#34;https://www.trustworthyinternet.org/ssl-pulse/&#34;&gt;83.2% adoption&lt;/a&gt; among top websites, so now is a great time to dive in.&lt;/p&gt;

&lt;p&gt;The process of conecting via TLS 1.2 begins when the user attempts to navigate to a website. For this description, we are attempting to navigate to &lt;a href=&#34;https://example.com/&#34;&gt;https://example.com/&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;tls-layers&#34;&gt;TLS Layers&lt;/h2&gt;

&lt;p&gt;The TLS protocol is composed of several layers, which come together to form each request. Here are descriptions of the common layers&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tlseminar.github.io/images/firstfew/gnutls-layers.png&#34; alt=&#34;tls layers&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Transport Layer&lt;/strong&gt; - The protocol over which TLS data is distributed. For HTTPS, this will be TCP. Needs only to be reliable (packet loss must be handled). Not a direct part of TLS.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Record Layer&lt;/strong&gt; - The record layer handles sending/receiving TLS messages, including data fragmentation for packets, (optional and bad) compression, and encryption.&lt;/p&gt;

&lt;p&gt;The next three are common protocols that operate within the body of the Record Layer. TLS extensions can specify additional protocols.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Handshake Protocol&lt;/strong&gt; - Responsible for choosing a cipher suite, connection parameters, and coordinating a shared secret.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Alert Procotol&lt;/strong&gt; - Used to communicate warnings and errors. The most common alerts are for an invalid server certificate or to signal the end of a TLS connection when the client exits.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Application Protocol&lt;/strong&gt; - Raw higher-level application data transmitted by TLS. For us, this is HTTP.&lt;/p&gt;

&lt;p&gt;Now, onto the first few milliseconds of a TLSv1.2 request!&lt;/p&gt;

&lt;h2 id=&#34;part-0-the-record-layer&#34;&gt;Part 0: The Record Layer&lt;/h2&gt;

&lt;p&gt;Since the following packets will be wrapped in a Record Layer struct, it&amp;rsquo;s worth describing that here.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tlseminar.github.io/images/firstfew/record-layer.png&#34; alt=&#34;record layer struct&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The record packet specifies the Content Type of the request, the TLS version, data length, and then the content data (in this image, a handshake clienthello).&lt;/p&gt;

&lt;p&gt;Note that the version specified in the record layer is often different from that specified in the handshake. This is for compatibility with some old TLS/SSL servers. You will often see the version here specified as TLS 1.0 (0x0103, or SSL 3.0)&lt;/p&gt;

&lt;h2 id=&#34;part-1-client-hello&#34;&gt;Part 1: Client Hello&lt;/h2&gt;

&lt;p&gt;Our web browser (Microsoft Edge 38.14393.0.0 on Windows 10) will begin the TLS 1.2 handshake with a ClientHello record.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tlseminar.github.io/images/firstfew/client-hello.png&#34; alt=&#34;clienthello record&#34; /&gt;&lt;/p&gt;

&lt;p&gt;We can see several important fields here worth mentioning. First, the &lt;strong&gt;time&lt;/strong&gt; (GMT seconds since midnight Jan 1, 1970) and &lt;strong&gt;random&lt;/strong&gt; bytes are included. This will be used later in the protocol to generate our symmetric encryption key.&lt;/p&gt;

&lt;p&gt;The client can send an optional &lt;strong&gt;session ID&lt;/strong&gt; (not sent in this case) to quickly resume a previous TLS connection and skip portions of the TLS handshake.&lt;/p&gt;

&lt;p&gt;Arguably the most important part of the ClientHello message is the list of &lt;strong&gt;cipher suites&lt;/strong&gt;, which dictate the key exchange algorithm, bulk encryption algorithm (with key length), MAC, and a psuedo-random function. The list should be ordered by client preference. The collection of these choices is a &amp;ldquo;cipher suite&amp;rdquo;, and the server is responsible for choosing a secure one it supports, or return an error if it doesn&amp;rsquo;t support any.&lt;/p&gt;

&lt;p&gt;The final field specified in the specification is for &lt;strong&gt;compression methods&lt;/strong&gt;. However, secure clients will advertise that they do not support compression (by passing &amp;ldquo;null&amp;rdquo; as the only algorithm) to avoid the &lt;a href=&#34;https://en.wikipedia.org/wiki/CRIME_(security_exploit)&#34;&gt;CRIME attack&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Finally, the ClientHello can have a number of different extensions. A common one is &lt;strong&gt;server_name&lt;/strong&gt;, which specifies the hostname the connection is meant for, so webservers hosting multiple sites can present the correct certificate.&lt;/p&gt;

&lt;h2 id=&#34;server-hello&#34;&gt;Server Hello&lt;/h2&gt;

&lt;p&gt;Once the server has processed our ClientHello, it will respond with a TLSv1.2 ServerHello message&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tlseminar.github.io/images/firstfew/server-hello.png&#34; alt=&#34;serverhello message&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This message returns several important fields, beginning with the TLS &lt;strong&gt;version&lt;/strong&gt; to be used, usually the highest version supported by both client and server. It also includes the server &lt;strong&gt;time&lt;/strong&gt; (not sure why example.com is so off!) and 28 &lt;strong&gt;random bytes&lt;/strong&gt; for use later.&lt;/p&gt;

&lt;p&gt;The server also makes a &lt;strong&gt;cipher suite selection&lt;/strong&gt; from the list chosen by the client. This should be the strongest suite supported by both. In our case, the server has chosen TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256, indicating the following:
* Key Exchange: Elliptic curve diffie-hellman, signed with RSA
* Encryption: AES in GCM mode with 128 bit keys
* MAC: SHA256&lt;/p&gt;

&lt;h2 id=&#34;certificate&#34;&gt;Certificate&lt;/h2&gt;

&lt;p&gt;After the ServerHello, the server will send a certificate chain to the client if applicable.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tlseminar.github.io/images/firstfew/server-certificate.png&#34; alt=&#34;server certificate message&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Each certificate comes with information about domains it supports, who it was issued by, and the time period (start and end) of its validity.&lt;/p&gt;

&lt;p&gt;The certificate chain is a list of certificates beginning with the TLS certificate for the current domain, and ending in a root certificate that is built-in to the web browser. Each certificate is signed by the certificate above it in the chain, and it is this chain that the client validates to verify the server.&lt;/p&gt;

&lt;p&gt;In our case, example.com has a certificate issued by &amp;ldquo;DigiCert SHA2 High Assurance&amp;rdquo;, which in turn is issued by the root certificate &amp;ldquo;DigiCert High Assurance EV Root CA.&amp;rdquo; On Windows, you can view the list of root certificates on your system with &lt;code&gt;certmgr.msc&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tlseminar.github.io/images/firstfew/certmgr.png&#34; alt=&#34;certmgr&#34; /&gt;&lt;/p&gt;

&lt;p&gt;We can see the DigiCert High Assurance EV Root CA in our store, along with several other DigiCert certificates. OSX allows you to see root certificates using the &amp;ldquo;Keychain Access&amp;rdquo; program, where they are listed under &amp;ldquo;System Roots&amp;rdquo;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tlseminar.github.io/images/firstfew/keychain-access.png&#34; alt=&#34;osx keychain access&#34; /&gt;&lt;/p&gt;

&lt;p&gt;In general, browsers will defer to the operating system root certificates as the central store for their validation. One notable exception is Firefox, which uses its own certificate store and ignores system root certificates by default.&lt;/p&gt;

&lt;p&gt;Root CA certificates are implicitly trusted by every system they&amp;rsquo;re included on. An attacker who manages to control their private key could impersonate any website without raising any red flags, so it&amp;rsquo;s important that the certificate authorities keep them safe (&lt;a href=&#34;https://www.mail-archive.com/dev-security-policy@lists.mozilla.org/msg05455.html&#34;&gt;but that doesn&amp;rsquo;t always happen&lt;/a&gt;).&lt;/p&gt;

&lt;h2 id=&#34;optional-certificate-status-ocsp&#34;&gt;Optional: Certificate Status (OCSP)&lt;/h2&gt;

&lt;p&gt;One increasingly common extension is the Online Certificate Status Protocol (OCSP), used for certificate revocations. OCSP servers can be consulted by clients to check if the server certificate has been revoked, which helps solve a critical problem with TLS certificates. Servers response to certificate requests by issuing a signed response from the CA with a status code indicating whether or not the certificate is valid.&lt;/p&gt;

&lt;p&gt;Prior to wide deployment of OCSP, TLS vendors shipped certificate revocation lists (CRLs) that contained serial numbers of revoked certificates.&lt;/p&gt;

&lt;p&gt;To reduce load, servers often cache the OCSP response and send it as a Certificate Status TLS message (OCSP stapling). This helps reduce load on the OCSP system and protects attackers from analyzing OCSP requests to determine client browsing habits. The server will send this cached message in response to a &lt;strong&gt;status_request&lt;/strong&gt; extension in the ClientHello message.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tlseminar.github.io/images/firstfew/ocsp-stapling.png&#34; alt=&#34;ocsp stapling&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Each OCSP ticket is signed by a trusted OCSP server. The response itself consists of a &lt;strong&gt;responseStatus&lt;/strong&gt; and optional &lt;strong&gt;responseBytes&lt;/strong&gt; with additional information.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tlseminar.github.io/images/firstfew/ocsp-response.png&#34; alt=&#34;ocsp response info&#34; /&gt;&lt;/p&gt;

&lt;p&gt;In our case, the OCSP ticket is valid and cached for 7 days (1/20 to 1/27). The server itself is responsible for refreshing its OCSP ticket at that time.&lt;/p&gt;

&lt;h2 id=&#34;serverkeyexchange&#34;&gt;ServerKeyExchange&lt;/h2&gt;

&lt;p&gt;For DHE key-exchanges (DHE_DSS, DHE_RSA, and DH_anon), the server will use a ServerKeyExchange message to specify the parameters for the algorithm.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tlseminar.github.io/images/firstfew/dhe-params.png&#34; alt=&#34;dhe parameters&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The server has specified a &lt;strong&gt;named_curve&lt;/strong&gt; curve type using the &lt;strong&gt;secp256r1&lt;/strong&gt; elliptic curve (also known as &lt;strong&gt;P-256&lt;/strong&gt; or &lt;strong&gt;prime256v1&lt;/strong&gt;). This is a public &lt;a href=&#34;http://www.secg.org/sec2-v2.pdf&#34;&gt;NIST standard curve&lt;/a&gt;. With knowledge of the curve to be used, both the server and client will know the crucial $p$ and $G$ values for ECDHE. For secp256r1, these are defined by NIST as:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;p = FFFFFFFF 00000001 00000000 00000000 00000000 FFFFFFFF FFFFFFFF FFFFFFFF

G = 03 6B17D1F2 E12C4247 F8BCE6E5 63A440F2 77037D81 2DEB33A0 F4A13945 D898C296
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The server will choose a random private key and compute $a*G$ as its &lt;strong&gt;public key&lt;/strong&gt;. In addition to this it also signs the data with its private key - signing &lt;code&gt;SHA256(client_random + server_random + server_params)&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;server-hello-done&#34;&gt;Server Hello Done&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;https://tlseminar.github.io/images/firstfew/server-hello-done.png&#34; alt=&#34;serverhellodone&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This short message from the server tells the client it&amp;rsquo;s done sending information. Nothing more.&lt;/p&gt;

&lt;h2 id=&#34;clientkeyexchange&#34;&gt;ClientKeyExchange&lt;/h2&gt;

&lt;p&gt;Now, the client must  send its own ephemeral public key (for DH).&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tlseminar.github.io/images/firstfew/client-dhe-key.png&#34; alt=&#34;client dhe key&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This is calculated by generating a random private key $b$ and from there calculating $b*G$ as its public key.&lt;/p&gt;

&lt;h2 id=&#34;completing-the-key-exchange&#34;&gt;Completing the Key Exchange&lt;/h2&gt;

&lt;p&gt;Now that the client has $a*G$ and the server $b*G$, both can calculate the final secret value $a*b*G$ with their own private keys. This is known as the &lt;strong&gt;pre-master secret&lt;/strong&gt;. The key detail here is that calculating $a*b*G$ from $a*G$ and $b*G$ alone is computationally difficult.&lt;/p&gt;

&lt;p&gt;We just have one final step to convert our pre-master secret into the final &lt;strong&gt;master secret&lt;/strong&gt;. We will use the random bytes generated by the client and server earlier along with our chosen psuedo-random function. For us, that was SHA-256.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;master_secret = PRF(pre_master_secret, &amp;quot;master secret&amp;quot;, client_random + server_random)[0..47]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The TLS 1.2 spec defines the PRF as &lt;code&gt;PRF(secret, label, seed)&lt;/code&gt; which expands to &lt;code&gt;P_SHA256(secret, label + seed)&lt;/code&gt;. The label is the literal ASCII string &amp;ldquo;master secret&amp;rdquo; without any null terminator. This expands to the following definition:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;P_sha256(secret, seed) = HMAC_sha256(secret, A(1) + seed) +
                         HMAC_sha256(secret, A(2) + seed) +
                         HMAC_sha256(secret, A(3) + seed) +
                         ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;where &lt;code&gt;A(x)&lt;/code&gt; is defined recursively as&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A(0) = seed
A(x) = HMAC_sha256(secret, A(x-1))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The result of the PRF is the final key that will be used for the bulk of the crypto in our application. We only want 48 bytes here, so we would need 2 rounds of SHA-256 and would discard the extra data.&lt;/p&gt;

&lt;h2 id=&#34;client-changecipherspec&#34;&gt;Client ChangeCipherSpec&lt;/h2&gt;

&lt;p&gt;The final unencrypted message sent by the client will be a ChangeCipherSpec message, which indicates that all following messages will be encrypted.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tlseminar.github.io/images/firstfew/change-cipher-spec.png&#34; alt=&#34;changecipherspec message&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;client-finished-server-changecipherspec-and-server-finished&#34;&gt;Client Finished, Server ChangeCipherSpec, and Server Finished&lt;/h2&gt;

&lt;p&gt;Immediately after sending a ChangeCipherSpec message, the client will send an encrypted Handshake Finished message to ensure the server is able to understand the agreed-upon encryption. The message will contain a &lt;strong&gt;hash of all previous handshake messages&lt;/strong&gt;, along with the string &amp;ldquo;client finished&amp;rdquo;. This is very important because it verifies that no part of the handshake has been tampered with by an attacker. It also includes the random bytes that were sent by the client and server, protecting it from replay attacks where the attacker pretends to be one of the parties.&lt;/p&gt;

&lt;p&gt;Once received by the server, the server will acknowledge with its own ChangeCipherSpec message, followed immediately by its own Finished message verifying the contents of the handshake.&lt;/p&gt;

&lt;p&gt;Note: if you have been following along in Wireshark, there appears to be a bug with Client/Server Finish messages when using AES_GCM that mislabels them.&lt;/p&gt;

&lt;h2 id=&#34;application-data&#34;&gt;Application Data&lt;/h2&gt;

&lt;p&gt;Finally, we can begin to transmit encrypted data! It may seem like a lot of work, but that is soon to pay off. The only remaining step is to discuss how the data is encrypted with AES_GCM, an &lt;a href=&#34;https://en.wikipedia.org/wiki/Authenticated_encryption&#34;&gt;AEAD&lt;/a&gt; cipher.&lt;/p&gt;

&lt;p&gt;First, we generate a MAC, key, and IV for both the client and the server using our master secret and the PRF definition from earlier.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;key_data = PRF(master_secret, &amp;quot;key expansion&amp;quot;, server_random + client_random);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Since we are using 128-bit AES with SHA-256, we&amp;rsquo;ll pull out the following key data:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// client_write_MAC_key = key_data[0..31]
// server_write_MAC_key = key_data[32..63]
client_write_key = key_data[64..79]
server_write_key = key_data[80..95]
client_write_IV = key_data[96..99]
server_write_IV = key_data[100..103]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For AEAD ciphers like GCM, we don&amp;rsquo;t need the MAC keys, but we offset them anyways. The client and server also get different keys to prevent a replay attack where a client message it looped back to it.&lt;/p&gt;

&lt;p&gt;We also construct &lt;code&gt;additional_data&lt;/code&gt; and an 8-byte &lt;code&gt;nonce&lt;/code&gt;, both of which are sent with the encrypted data. In the past, it was thought that the nonce could be either random or just a simple session counter. However, &lt;a href=&#34;https://github.com/nonce-disrespect/nonce-disrespect&#34;&gt;recent research&lt;/a&gt; found many sites using random nonces for AES_GCM were vulnerable to nonce reuse attacks, so it&amp;rsquo;s best to just use an incrementing counter tied to the session.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;additional_data = sequence_num + record_type + tls_version + length
nonce = &amp;lt;random_8_bytes&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Finally, we can encrypt our data with AES GCM!&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;encrypted = AES_GCM(client_write_key, client_write_IV+nonce, &amp;lt;DATA&amp;gt;, additional_data)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and the server can read it with&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;DATA&amp;gt; = AES_GCM(client_write_key, client_write_IV+nonce, encrypted, additional_data)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;https://tlseminar.github.io/images/firstfew/tls-hs-ecdhe.png&#34; alt=&#34;tls 1.2 ecdhe handshake&#34; /&gt;
(source: &lt;a href=&#34;https://timtaubert.de/blog/2015/11/more-privacy-less-latency-improved-handshakes-in-tls-13/&#34;&gt;More Privacy, Less Latency: Improved Handshakes in TLS version 1.3&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;That&amp;rsquo;s all it takes to make a TLS 1.2 connection! Over the course of ~103ms, we established a bidirectional encrypted tunnel and sent a full HTTP request and response in only 2 round trips. Although we didn&amp;rsquo;t cover nearly everything in the &lt;a href=&#34;https://tools.ietf.org/html/rfc5246&#34;&gt;full TLS 1.2 RFC&lt;/a&gt;, we hope you have a pretty good overview of how process functions - and how much work goes in behind the scenes to secure web traffic!&lt;/p&gt;

&lt;h2 id=&#34;sources&#34;&gt;Sources&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://www.moserware.com/2009/06/first-few-milliseconds-of-https.html&#34;&gt;http://www.moserware.com/2009/06/first-few-milliseconds-of-https.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://security.stackexchange.com/questions/131724/the-first-few-milliseconds-of-an-https-connection-tls-1-2-tls-echde-rsa-with&#34;&gt;https://security.stackexchange.com/questions/131724/the-first-few-milliseconds-of-an-https-connection-tls-1-2-tls-echde-rsa-with&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://tools.ietf.org/html/rfc5246&#34;&gt;https://tools.ietf.org/html/rfc5246&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://tools.ietf.org/html/rfc5288&#34;&gt;https://tools.ietf.org/html/rfc5288&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.secg.org/sec2-v2.pdf&#34;&gt;http://www.secg.org/sec2-v2.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://vincent.bernat.im/en/blog/2011-ssl-perfect-forward-secrecy.html&#34;&gt;https://vincent.bernat.im/en/blog/2011-ssl-perfect-forward-secrecy.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/nonce-disrespect/nonce-disrespect&#34;&gt;https://github.com/nonce-disrespect/nonce-disrespect&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.trustworthyinternet.org/ssl-pulse/&#34;&gt;https://www.trustworthyinternet.org/ssl-pulse/&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Blogging Mechanics</title>
      <link>https://tlseminar.github.io/blogging/</link>
      <pubDate>Sun, 22 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://tlseminar.github.io/blogging/</guid>
      <description>&lt;p&gt;Here are some suggestions for how to create the class blog posts for
your assigned classes.  I believe each team has at least a few members
with enough experience using git and web contruction tools that
following these instructions won&amp;rsquo;t be a big burden, but if you have
other ways you want to build your blog page for a topic let me know
and we can discuss alternative options.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Install &lt;a href=&#34;https://gohugo.io/&#34;&gt;Hugo&lt;/a&gt;.  Hugo is a static website
generator that builds a site from Markdown pages.  (With homebrew on
Mac OS X, this is easy: &lt;code&gt;brew update &amp;amp;&amp;amp; brew install hugo&lt;/code&gt;.)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Clone the github repository,
&lt;a href=&#34;https://github.com/tlseminar/tlseminar.github.io&#34;&gt;&lt;em&gt;https://github.com/tlseminar/tlseminar.github.io&lt;/em&gt;&lt;/a&gt;.
This is what is used to build the
&lt;a href=&#34;https://tlseminar.github.io&#34;&gt;tlseminar.github.io&lt;/a&gt; site.  If you are
working with multiple teammates on the blog post (which you probably
should be), you can add write permissions for everyone to the cloned
repository.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;You should create your page in the &lt;code&gt;web/content/post/&lt;/code&gt;
subdirectory. You can start by copying an earlier file in that
directory (e.g., &lt;code&gt;class1.md&lt;/code&gt;) and updating the header section
(between the &lt;code&gt;+++&lt;/code&gt; marks) and replacing everything after that with
your content.  Don&amp;rsquo;t forget to update the date so your page will
appear in the right order.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;You can use multiple files (but probably only one in
the &lt;code&gt;post/&lt;/code&gt; directory (this will show up as pages on the front
list).  Use the &lt;code&gt;web/content/images&lt;/code&gt; directory for images and the
&lt;code&gt;web/content/docs&lt;/code&gt; directory for papers.  Using images and other
resources to make your post interesting and visually compelling is
highly encouraged!&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Write the blog page using Markdown.  Markdown is a simple markup
language that can be used to easily generate both HTML and other
output document formats.  You can probably figure out everything you
need by looking at previous posts, but for a summary of Markdown,
see &lt;a href=&#34;https://daringfireball.net/projects/markdown/syntax&#34;&gt;Markdown: Syntax&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;To test the post, run &lt;code&gt;make develop&lt;/code&gt; (in the &lt;code&gt;web/&lt;/code&gt; subdirectory of
your repository).  This starts the Hugo development server, usually
on port 1313 (unless that port is already in use).  Then, you can
view the site with a browser at &lt;code&gt;localhost:1313&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;When you are ready, submit a pull request to incorporate your
changes into the main repository (and public course website).  At
this stage, I will probably make things visible on the public site,
although it can still be edited and improved with subsequent
comments.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>